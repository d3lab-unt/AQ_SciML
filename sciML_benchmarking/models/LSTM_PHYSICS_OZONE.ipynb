{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-09T06:03:32.845188Z",
     "start_time": "2026-01-09T05:57:54.810935Z"
    }
   },
   "source": [
    "import random\n",
    "from copy import deepcopy as dc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "CSV_PATH = \"datasets/final/datasets_lagwise/Ozone_Combined_AQI_2022_2024.csv\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "EPOCHS = 200\n",
    "PATIENCE = 20\n",
    "FEATURE_RANGE = (-1, 1)\n",
    "\n",
    "lag_list = [1, 7, 14, 30]\n",
    "lambda_configs = [\n",
    "    (0.0, 1.0),\n",
    "    (0.3, 0.7),\n",
    "    (0.5, 0.5),\n",
    "    (0.7, 0.3),\n",
    "    (1.0, 0.0),\n",
    "]\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"Date\"], format=\"%d-%m-%y\", dayfirst=True, errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"DATE\", \"Daily_Mean_Ozone\", \"Daily_AQI_Value\"]).reset_index(drop=True)\n",
    "\n",
    "data = df[[\"DATE\", \"Daily_Mean_Ozone\", \"Daily_AQI_Value\"]].copy()\n",
    "data = data.sort_values(\"DATE\").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Base Data Frame (Head) ---\")\n",
    "print(data.head())\n",
    "print(\"-\" * 50)\n",
    "print(\"Shape:\", data.shape)\n",
    "\n",
    "\n",
    "def build_supervised_table(df_in: pd.DataFrame, LAG: int) -> pd.DataFrame:\n",
    "    lag_col = f\"AQI_Targeted_Value_LAG_{LAG}\"\n",
    "    pm_lag_col = f\"OZONE_Targeted_Value_LAG_{LAG}\"\n",
    "    df_local = dc(df_in[[\"DATE\", \"Daily_Mean_Ozone\", \"Daily_AQI_Value\", lag_col, pm_lag_col]]).set_index(\"DATE\")\n",
    "    cols = [\"Daily_Mean_Ozone\", \"Daily_AQI_Value\", lag_col, pm_lag_col]\n",
    "    return df_local[cols].dropna()\n",
    "\n",
    "\n",
    "def epa_aqi_from_pm25(pm25_real: torch.Tensor) -> torch.Tensor:\n",
    "    breakpoints = [\n",
    "        ((0.000, 0.054), (0, 50)),\n",
    "        ((0.05400001, 0.070), (51, 100)),\n",
    "        ((0.07000001, 0.085), (101, 150)),\n",
    "        ((0.08500001, 0.105), (151, 200)),\n",
    "        ((0.10500001, 0.200), (201, 300)),\n",
    "    ]\n",
    "    aqi = torch.zeros_like(pm25_real)\n",
    "    for (bp_lo, bp_hi), (i_lo, i_hi) in breakpoints:\n",
    "        mask = (pm25_real >= bp_lo) & (pm25_real <= bp_hi)\n",
    "        aqi[mask] = ((i_hi - i_lo) / (bp_hi - bp_lo)) * (pm25_real[mask] - bp_lo) + i_lo\n",
    "    aqi[pm25_real > 500.4] = 500.0\n",
    "    return aqi\n",
    "\n",
    "\n",
    "def scale_as_first_column(col_real: torch.Tensor, full_scaler: MinMaxScaler) -> torch.Tensor:\n",
    "    col_np = col_real.detach().cpu().numpy()\n",
    "    B = col_np.shape[0]\n",
    "    dummy = np.zeros((B, full_scaler.n_features_in_), dtype=col_np.dtype)\n",
    "    dummy[:, 0] = col_np[:, 0]\n",
    "    scaled = full_scaler.transform(dummy)[:, [0]]\n",
    "    return torch.tensor(scaled, dtype=col_real.dtype, device=col_real.device)\n",
    "\n",
    "\n",
    "def inverse_first_column(series_scaled_1d: np.ndarray, n_features_total: int, full_scaler: MinMaxScaler) -> np.ndarray:\n",
    "    d = np.zeros((series_scaled_1d.shape[0], n_features_total))\n",
    "    d[:, 0] = series_scaled_1d\n",
    "    return full_scaler.inverse_transform(d)[:, 0]\n",
    "\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y, pm_t_real):\n",
    "        self.X, self.y, self.pm = X, y, pm_t_real\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.pm[idx]\n",
    "\n",
    "\n",
    "class LSTMRegressorDeepCustom(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 2,\n",
    "        lstm_hidden_size_1: int = 32,\n",
    "        lstm_hidden_size_2: int = 32,\n",
    "        bidirectional: bool = False,\n",
    "        mlp_hidden_sizes: tuple = (128, 64, 32),\n",
    "        mlp_dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=lstm_hidden_size_1,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        lstm2_input_size = lstm_hidden_size_1 * (2 if bidirectional else 1)\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=lstm2_input_size,\n",
    "            hidden_size=lstm_hidden_size_2,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        lstm_out_dim = lstm_hidden_size_2 * (2 if bidirectional else 1)\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = lstm_out_dim\n",
    "        for h in mlp_hidden_sizes:\n",
    "            layers += [\n",
    "                nn.Linear(prev_dim, h),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=mlp_dropout),\n",
    "            ]\n",
    "            prev_dim = h\n",
    "        layers += [nn.Linear(prev_dim, 1)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.mlp(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "def compute_data_loss(model, xb, yb):\n",
    "    preds = model(xb)\n",
    "    return criterion(preds, yb)\n",
    "\n",
    "\n",
    "def compute_physics_loss_t(model, xb, pm_t_real, scaler):\n",
    "    preds_scaled = model(xb)\n",
    "    aqi_phys_real = epa_aqi_from_pm25(pm_t_real)\n",
    "    aqi_phys_scaled = scale_as_first_column(aqi_phys_real, scaler)\n",
    "    return criterion(preds_scaled, aqi_phys_scaled)\n",
    "\n",
    "\n",
    "def train_and_validate(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    scaler,\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    patience=PATIENCE,\n",
    "    lambda_data=0.7,\n",
    "    lambda_phys=0.3,\n",
    "):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode=\"min\", factor=0.5, patience=5, min_lr=1e-3)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "    tr_hist, va_hist = [], []\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        tr_total = tr_data = tr_phys = 0.0\n",
    "        for xb, yb, pm in train_loader:\n",
    "            xb, yb, pm = xb.to(device), yb.to(device), pm.to(device)\n",
    "            optim.zero_grad()\n",
    "            loss_d = compute_data_loss(model, xb, yb)\n",
    "            loss_p = compute_physics_loss_t(model, xb, pm, scaler)\n",
    "            loss = lambda_data * loss_d + lambda_phys * loss_p\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            tr_total += loss.item()\n",
    "            tr_data += loss_d.item()\n",
    "            tr_phys += loss_p.item()\n",
    "\n",
    "        tr_total /= max(1, len(train_loader))\n",
    "        tr_data /= max(1, len(train_loader))\n",
    "        tr_phys /= max(1, len(train_loader))\n",
    "        tr_hist.append(tr_total)\n",
    "\n",
    "        model.eval()\n",
    "        va_total = va_data = va_phys = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, pm in val_loader:\n",
    "                xb, yb, pm = xb.to(device), yb.to(device), pm.to(device)\n",
    "                preds = model(xb)\n",
    "                loss_d = criterion(preds, yb)\n",
    "                loss_p = compute_physics_loss_t(model, xb, pm, scaler)\n",
    "                loss = lambda_data * loss_d + lambda_phys * loss_p\n",
    "                va_total += loss.item()\n",
    "                va_data += loss_d.item()\n",
    "                va_phys += loss_p.item()\n",
    "\n",
    "        va_total /= max(1, len(val_loader))\n",
    "        va_data /= max(1, len(val_loader))\n",
    "        va_phys /= max(1, len(val_loader))\n",
    "        va_hist.append(va_total)\n",
    "\n",
    "        sched.step(va_total)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {ep:03d} | \"\n",
    "            f\"Train {tr_total:.6f} (data {tr_data:.6f}, phys {tr_phys:.6f}) | \"\n",
    "            f\"Val {va_total:.6f} (data {va_data:.6f}, phys {va_phys:.6f})\"\n",
    "        )\n",
    "\n",
    "        if va_total < best_val - 1e-6:\n",
    "            best_val = va_total\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"Early stopping at epoch {ep} (best val = {best_val:.6f})\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return tr_hist, va_hist\n",
    "\n",
    "\n",
    "results = {\n",
    "    \"LAG\": [],\n",
    "    \"Model\": [],\n",
    "    \"lambda_data\": [],\n",
    "    \"lambda_phys\": [],\n",
    "    \"MAE\": [],\n",
    "    \"RMSE\": [],\n",
    "    \"NMSE\": [],\n",
    "}\n",
    "\n",
    "\n",
    "for LAG in lag_list:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Preparing and training LSTM+Physics for LAG = {LAG}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    tmp = data.copy()\n",
    "    tmp[f\"AQI_Targeted_Value_LAG_{LAG}\"] = tmp[\"Daily_AQI_Value\"].shift(-LAG)\n",
    "    tmp[f\"OZONE_Targeted_Value_LAG_{LAG}\"] = tmp[\"Daily_Mean_Ozone\"].shift(-LAG)\n",
    "\n",
    "    supervised = build_supervised_table(tmp, LAG)\n",
    "    print(\"\\n--- Supervised Data (Head) ---\")\n",
    "    print(supervised.head())\n",
    "    print(\"Shape:\", supervised.shape)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    arr = supervised.to_numpy()\n",
    "    y_real = arr[:, 2:3]\n",
    "    pm_t = arr[:, 3:4]\n",
    "    X_feats = arr[:, 0:2]\n",
    "\n",
    "    N = arr.shape[0]\n",
    "    split_idx = int(N * 0.80)\n",
    "\n",
    "    tr_y, te_y = y_real[:split_idx], y_real[split_idx:]\n",
    "    tr_pm, te_pm = pm_t[:split_idx], pm_t[split_idx:]\n",
    "    tr_X, te_X = X_feats[:split_idx], X_feats[split_idx:]\n",
    "\n",
    "    train_stack = np.concatenate([tr_y, tr_X], axis=1)\n",
    "    test_stack = np.concatenate([te_y, te_X], axis=1)\n",
    "\n",
    "    full_scaler = MinMaxScaler(feature_range=FEATURE_RANGE)\n",
    "    train_scaled = full_scaler.fit_transform(train_stack)\n",
    "    test_scaled = full_scaler.transform(test_stack)\n",
    "\n",
    "    feature_dim = train_scaled.shape[1] - 1\n",
    "    X_train = torch.tensor(train_scaled[:, 1:].reshape(-1, 1, feature_dim), dtype=torch.float32)\n",
    "    y_train = torch.tensor(train_scaled[:, :1], dtype=torch.float32)\n",
    "    X_test = torch.tensor(test_scaled[:, 1:].reshape(-1, 1, feature_dim), dtype=torch.float32)\n",
    "    y_test = torch.tensor(test_scaled[:, :1], dtype=torch.float32)\n",
    "\n",
    "    pm_t_train_real = torch.tensor(tr_pm, dtype=torch.float32)\n",
    "    pm_t_test_real = torch.tensor(te_pm, dtype=torch.float32)\n",
    "\n",
    "    train_loader = DataLoader(SeqDataset(X_train, y_train, pm_t_train_real), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(SeqDataset(X_test, y_test, pm_t_test_real), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    tr_y_tensor = torch.tensor(tr_y, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        aqi_phys_train = epa_aqi_from_pm25(pm_t_train_real.to(device))\n",
    "        abs_diff = torch.abs(aqi_phys_train - tr_y_tensor)\n",
    "        print(\"\\n--- First 10 Samples: True vs Physics AQI (Target Day) ---\")\n",
    "        for i in range(min(10, len(tr_y_tensor))):\n",
    "            true_val = float(tr_y_tensor[i].cpu().item())\n",
    "            phys_val = float(aqi_phys_train[i].cpu().item())\n",
    "            diff_val = float(abs_diff[i].cpu().item())\n",
    "            print(f\"Sample {i+1:02d}: True={true_val:.3f}, Physics={phys_val:.3f}, Diff={diff_val:.3f}\")\n",
    "\n",
    "    for lambda_data, lambda_phys in lambda_configs:\n",
    "        print(\"\\n\" + \"-\" * 60)\n",
    "        print(\n",
    "            f\"Training LSTM+Physics | LAG = {LAG}, \"\n",
    "            f\"lambda_data = {lambda_data}, lambda_phys = {lambda_phys}\"\n",
    "        )\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        random.seed(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        torch.manual_seed(SEED)\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "        model = LSTMRegressorDeepCustom(\n",
    "            input_size=feature_dim,\n",
    "            lstm_hidden_size_1=32,\n",
    "            lstm_hidden_size_2=32,\n",
    "            bidirectional=False,\n",
    "            mlp_hidden_sizes=(128, 64, 32),\n",
    "            mlp_dropout=0.1,\n",
    "        ).to(device)\n",
    "\n",
    "        train_losses, val_losses = train_and_validate(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            scaler=full_scaler,\n",
    "            epochs=EPOCHS,\n",
    "            lr=LR,\n",
    "            patience=PATIENCE,\n",
    "            lambda_data=lambda_data,\n",
    "            lambda_phys=lambda_phys,\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            te_pred_s = model(X_test.to(device)).cpu().numpy().ravel()\n",
    "\n",
    "        n_features_total = full_scaler.n_features_in_\n",
    "        te_pred = inverse_first_column(te_pred_s, n_features_total, full_scaler)\n",
    "        y_te = inverse_first_column(y_test.cpu().numpy().ravel(), n_features_total, full_scaler)\n",
    "\n",
    "        mae_te = mean_absolute_error(y_te, te_pred)\n",
    "        rmse_te = np.sqrt(mean_squared_error(y_te, te_pred))\n",
    "\n",
    "        mse_te = mean_squared_error(y_te, te_pred)\n",
    "        denom = np.mean((y_te - np.mean(y_te)) ** 2)\n",
    "        eps = 1e-12\n",
    "        nmse_te = mse_te / (denom + eps)\n",
    "\n",
    "        print(\"\\n--- Test Evaluation (Real AQI Units) ---\")\n",
    "        print(f\"LAG = {LAG}, λ_data = {lambda_data}, λ_phys = {lambda_phys}\")\n",
    "        print(f\"MAE:  {mae_te:.4f}\")\n",
    "        print(f\"RMSE: {rmse_te:.4f}\")\n",
    "        print(f\"NMSE: {nmse_te:.4f}\")\n",
    "\n",
    "        results[\"LAG\"].append(LAG)\n",
    "        results[\"Model\"].append(\"LSTM+Physics\")\n",
    "        results[\"lambda_data\"].append(lambda_data)\n",
    "        results[\"lambda_phys\"].append(lambda_phys)\n",
    "        results[\"MAE\"].append(mae_te)\n",
    "        results[\"RMSE\"].append(rmse_te)\n",
    "        results[\"NMSE\"].append(nmse_te)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"OZONE_LSTM_Physics_LambdaSweep_Results.csv\", index=False)\n",
    "\n",
    "print(\"\\n===== Final OZONE LSTM+Physics Lambda Sweep Results =====\")\n",
    "print(results_df)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "--- Base Data Frame (Head) ---\n",
      "        DATE  Daily_Mean_Ozone  Daily_AQI_Value\n",
      "0 2022-01-01          0.025000        23.000000\n",
      "1 2022-01-02          0.032333        30.333333\n",
      "2 2022-01-03          0.029667        27.666667\n",
      "3 2022-01-04          0.036000        33.333333\n",
      "4 2022-01-05          0.033000        30.666667\n",
      "--------------------------------------------------\n",
      "Shape: (1091, 3)\n",
      "\n",
      "============================================================\n",
      "Preparing and training LSTM+Physics for LAG = 1\n",
      "============================================================\n",
      "\n",
      "--- Supervised Data (Head) ---\n",
      "            Daily_Mean_Ozone  Daily_AQI_Value  AQI_Targeted_Value_LAG_1  \\\n",
      "DATE                                                                      \n",
      "2022-01-01          0.025000        23.000000                 30.333333   \n",
      "2022-01-02          0.032333        30.333333                 27.666667   \n",
      "2022-01-03          0.029667        27.666667                 33.333333   \n",
      "2022-01-04          0.036000        33.333333                 30.666667   \n",
      "2022-01-05          0.033000        30.666667                 23.000000   \n",
      "\n",
      "            OZONE_Targeted_Value_LAG_1  \n",
      "DATE                                    \n",
      "2022-01-01                    0.032333  \n",
      "2022-01-02                    0.029667  \n",
      "2022-01-03                    0.036000  \n",
      "2022-01-04                    0.033000  \n",
      "2022-01-05                    0.025000  \n",
      "Shape: (1090, 4)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- First 10 Samples: True vs Physics AQI (Target Day) ---\n",
      "Sample 01: True=30.333, Physics=29.938, Diff=0.395\n",
      "Sample 02: True=27.667, Physics=27.469, Diff=0.198\n",
      "Sample 03: True=33.333, Physics=33.333, Diff=0.000\n",
      "Sample 04: True=30.667, Physics=30.556, Diff=0.111\n",
      "Sample 05: True=23.000, Physics=23.148, Diff=0.148\n",
      "Sample 06: True=23.333, Physics=23.457, Diff=0.123\n",
      "Sample 07: True=15.667, Physics=15.432, Diff=0.235\n",
      "Sample 08: True=24.333, Physics=24.383, Diff=0.049\n",
      "Sample 09: True=22.000, Physics=21.914, Diff=0.086\n",
      "Sample 10: True=26.667, Physics=26.852, Diff=0.185\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 1, lambda_data = 0.0, lambda_phys = 1.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.150604 (data 0.148372, phys 0.150604) | Val 0.114975 (data 0.110797, phys 0.114975)\n",
      "Epoch 002 | Train 0.078214 (data 0.075345, phys 0.078214) | Val 0.114413 (data 0.110219, phys 0.114413)\n",
      "Epoch 003 | Train 0.072824 (data 0.070939, phys 0.072824) | Val 0.114476 (data 0.110217, phys 0.114476)\n",
      "Epoch 004 | Train 0.071735 (data 0.068558, phys 0.071735) | Val 0.110911 (data 0.106720, phys 0.110911)\n",
      "Epoch 005 | Train 0.068508 (data 0.063630, phys 0.068508) | Val 0.102627 (data 0.098610, phys 0.102627)\n",
      "Epoch 006 | Train 0.058864 (data 0.055398, phys 0.058864) | Val 0.087701 (data 0.084072, phys 0.087701)\n",
      "Epoch 007 | Train 0.047686 (data 0.043785, phys 0.047686) | Val 0.074986 (data 0.071912, phys 0.074986)\n",
      "Epoch 008 | Train 0.042880 (data 0.040690, phys 0.042880) | Val 0.072522 (data 0.069727, phys 0.072522)\n",
      "Epoch 009 | Train 0.040915 (data 0.039598, phys 0.040915) | Val 0.071241 (data 0.068505, phys 0.071241)\n",
      "Epoch 010 | Train 0.040906 (data 0.039813, phys 0.040906) | Val 0.071523 (data 0.068869, phys 0.071523)\n",
      "Epoch 011 | Train 0.041215 (data 0.040043, phys 0.041215) | Val 0.070152 (data 0.067490, phys 0.070152)\n",
      "Epoch 012 | Train 0.041216 (data 0.039533, phys 0.041216) | Val 0.069893 (data 0.067286, phys 0.069893)\n",
      "Epoch 013 | Train 0.040565 (data 0.040033, phys 0.040565) | Val 0.068973 (data 0.066404, phys 0.068973)\n",
      "Epoch 014 | Train 0.041358 (data 0.038278, phys 0.041358) | Val 0.068666 (data 0.066141, phys 0.068666)\n",
      "Epoch 015 | Train 0.040210 (data 0.038589, phys 0.040210) | Val 0.069164 (data 0.066624, phys 0.069164)\n",
      "Epoch 016 | Train 0.040848 (data 0.039883, phys 0.040848) | Val 0.068446 (data 0.065914, phys 0.068446)\n",
      "Epoch 017 | Train 0.040416 (data 0.039704, phys 0.040416) | Val 0.068544 (data 0.066008, phys 0.068544)\n",
      "Epoch 018 | Train 0.040043 (data 0.038118, phys 0.040043) | Val 0.068629 (data 0.066092, phys 0.068629)\n",
      "Epoch 019 | Train 0.039815 (data 0.039036, phys 0.039815) | Val 0.068144 (data 0.065624, phys 0.068144)\n",
      "Epoch 020 | Train 0.039098 (data 0.038186, phys 0.039098) | Val 0.068193 (data 0.065673, phys 0.068193)\n",
      "Epoch 021 | Train 0.038664 (data 0.038360, phys 0.038664) | Val 0.068252 (data 0.065762, phys 0.068252)\n",
      "Epoch 022 | Train 0.040066 (data 0.038131, phys 0.040066) | Val 0.067458 (data 0.065028, phys 0.067458)\n",
      "Epoch 023 | Train 0.038728 (data 0.038419, phys 0.038728) | Val 0.068239 (data 0.065754, phys 0.068239)\n",
      "Epoch 024 | Train 0.039159 (data 0.038756, phys 0.039159) | Val 0.068260 (data 0.065807, phys 0.068260)\n",
      "Epoch 025 | Train 0.039973 (data 0.038434, phys 0.039973) | Val 0.068124 (data 0.065613, phys 0.068124)\n",
      "Epoch 026 | Train 0.038557 (data 0.037679, phys 0.038557) | Val 0.068161 (data 0.065685, phys 0.068161)\n",
      "Epoch 027 | Train 0.039059 (data 0.037580, phys 0.039059) | Val 0.068194 (data 0.065731, phys 0.068194)\n",
      "Epoch 028 | Train 0.039731 (data 0.037200, phys 0.039731) | Val 0.068398 (data 0.065945, phys 0.068398)\n",
      "Epoch 029 | Train 0.038990 (data 0.037764, phys 0.038990) | Val 0.068048 (data 0.065597, phys 0.068048)\n",
      "Epoch 030 | Train 0.039447 (data 0.037534, phys 0.039447) | Val 0.068584 (data 0.066116, phys 0.068584)\n",
      "Epoch 031 | Train 0.039365 (data 0.037926, phys 0.039365) | Val 0.067189 (data 0.064797, phys 0.067189)\n",
      "Epoch 032 | Train 0.038870 (data 0.037567, phys 0.038870) | Val 0.068036 (data 0.065650, phys 0.068036)\n",
      "Epoch 033 | Train 0.038942 (data 0.037443, phys 0.038942) | Val 0.068029 (data 0.065569, phys 0.068029)\n",
      "Epoch 034 | Train 0.039937 (data 0.037550, phys 0.039937) | Val 0.068097 (data 0.065649, phys 0.068097)\n",
      "Epoch 035 | Train 0.039061 (data 0.037822, phys 0.039061) | Val 0.067779 (data 0.065322, phys 0.067779)\n",
      "Epoch 036 | Train 0.037979 (data 0.037056, phys 0.037979) | Val 0.067815 (data 0.065379, phys 0.067815)\n",
      "Epoch 037 | Train 0.039210 (data 0.037400, phys 0.039210) | Val 0.068219 (data 0.065788, phys 0.068219)\n",
      "Epoch 038 | Train 0.039044 (data 0.037208, phys 0.039044) | Val 0.067996 (data 0.065559, phys 0.067996)\n",
      "Epoch 039 | Train 0.038361 (data 0.038352, phys 0.038361) | Val 0.067478 (data 0.065061, phys 0.067478)\n",
      "Epoch 040 | Train 0.038571 (data 0.037758, phys 0.038571) | Val 0.067700 (data 0.065277, phys 0.067700)\n",
      "Epoch 041 | Train 0.037426 (data 0.036651, phys 0.037426) | Val 0.067906 (data 0.065464, phys 0.067906)\n",
      "Epoch 042 | Train 0.038358 (data 0.037229, phys 0.038358) | Val 0.067575 (data 0.065155, phys 0.067575)\n",
      "Epoch 043 | Train 0.038319 (data 0.036432, phys 0.038319) | Val 0.068836 (data 0.066403, phys 0.068836)\n",
      "Epoch 044 | Train 0.038119 (data 0.037429, phys 0.038119) | Val 0.068129 (data 0.065661, phys 0.068129)\n",
      "Epoch 045 | Train 0.038461 (data 0.036614, phys 0.038461) | Val 0.067506 (data 0.065081, phys 0.067506)\n",
      "Epoch 046 | Train 0.038491 (data 0.036544, phys 0.038491) | Val 0.068117 (data 0.065689, phys 0.068117)\n",
      "Epoch 047 | Train 0.038108 (data 0.036397, phys 0.038108) | Val 0.069093 (data 0.066575, phys 0.069093)\n",
      "Epoch 048 | Train 0.038591 (data 0.036698, phys 0.038591) | Val 0.067698 (data 0.065279, phys 0.067698)\n",
      "Epoch 049 | Train 0.038734 (data 0.036883, phys 0.038734) | Val 0.067795 (data 0.065336, phys 0.067795)\n",
      "Epoch 050 | Train 0.038799 (data 0.037109, phys 0.038799) | Val 0.068217 (data 0.065748, phys 0.068217)\n",
      "Epoch 051 | Train 0.038291 (data 0.037905, phys 0.038291) | Val 0.067570 (data 0.065146, phys 0.067570)\n",
      "Early stopping at epoch 51 (best val = 0.067189)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 1, λ_data = 0.0, λ_phys = 1.0\n",
      "MAE:  12.7986\n",
      "RMSE: 19.4895\n",
      "NMSE: 0.5954\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 1, lambda_data = 0.3, lambda_phys = 0.7\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.150085 (data 0.148537, phys 0.150749) | Val 0.113680 (data 0.110759, phys 0.114932)\n",
      "Epoch 002 | Train 0.077308 (data 0.075367, phys 0.078140) | Val 0.113136 (data 0.110199, phys 0.114394)\n",
      "Epoch 003 | Train 0.072159 (data 0.070852, phys 0.072719) | Val 0.113145 (data 0.110163, phys 0.114423)\n",
      "Epoch 004 | Train 0.070588 (data 0.068286, phys 0.071574) | Val 0.109171 (data 0.106245, phys 0.110425)\n",
      "Epoch 005 | Train 0.066574 (data 0.063142, phys 0.068045) | Val 0.100865 (data 0.098059, phys 0.102067)\n",
      "Epoch 006 | Train 0.057209 (data 0.054781, phys 0.058250) | Val 0.086532 (data 0.083993, phys 0.087620)\n",
      "Epoch 007 | Train 0.046375 (data 0.043735, phys 0.047507) | Val 0.073923 (data 0.071777, phys 0.074843)\n",
      "Epoch 008 | Train 0.042369 (data 0.040793, phys 0.043045) | Val 0.071569 (data 0.069617, phys 0.072406)\n",
      "Epoch 009 | Train 0.040425 (data 0.039454, phys 0.040842) | Val 0.070605 (data 0.068686, phys 0.071428)\n",
      "Epoch 010 | Train 0.040406 (data 0.039770, phys 0.040679) | Val 0.070208 (data 0.068339, phys 0.071009)\n",
      "Epoch 011 | Train 0.040756 (data 0.040043, phys 0.041061) | Val 0.069356 (data 0.067497, phys 0.070152)\n",
      "Epoch 012 | Train 0.040883 (data 0.039544, phys 0.041456) | Val 0.068798 (data 0.066964, phys 0.069584)\n",
      "Epoch 013 | Train 0.040242 (data 0.039687, phys 0.040479) | Val 0.068256 (data 0.066454, phys 0.069029)\n",
      "Epoch 014 | Train 0.040331 (data 0.038170, phys 0.041257) | Val 0.067923 (data 0.066162, phys 0.068678)\n",
      "Epoch 015 | Train 0.039874 (data 0.038813, phys 0.040329) | Val 0.068049 (data 0.066283, phys 0.068807)\n",
      "Epoch 016 | Train 0.040297 (data 0.039901, phys 0.040467) | Val 0.067408 (data 0.065656, phys 0.068158)\n",
      "Epoch 017 | Train 0.040023 (data 0.039301, phys 0.040332) | Val 0.067776 (data 0.066027, phys 0.068525)\n",
      "Epoch 018 | Train 0.039351 (data 0.038013, phys 0.039924) | Val 0.067568 (data 0.065810, phys 0.068321)\n",
      "Epoch 019 | Train 0.039375 (data 0.038611, phys 0.039702) | Val 0.067283 (data 0.065534, phys 0.068033)\n",
      "Epoch 020 | Train 0.038811 (data 0.038168, phys 0.039087) | Val 0.067401 (data 0.065653, phys 0.068151)\n",
      "Epoch 021 | Train 0.038366 (data 0.038439, phys 0.038335) | Val 0.067371 (data 0.065634, phys 0.068115)\n",
      "Epoch 022 | Train 0.039034 (data 0.037740, phys 0.039589) | Val 0.066972 (data 0.065246, phys 0.067712)\n",
      "Epoch 023 | Train 0.038409 (data 0.038444, phys 0.038393) | Val 0.067432 (data 0.065687, phys 0.068180)\n",
      "Epoch 024 | Train 0.038819 (data 0.038494, phys 0.038958) | Val 0.067435 (data 0.065712, phys 0.068173)\n",
      "Epoch 025 | Train 0.039364 (data 0.038177, phys 0.039872) | Val 0.067359 (data 0.065606, phys 0.068111)\n",
      "Epoch 026 | Train 0.038222 (data 0.037652, phys 0.038466) | Val 0.067410 (data 0.065675, phys 0.068153)\n",
      "Epoch 027 | Train 0.038434 (data 0.037473, phys 0.038845) | Val 0.067231 (data 0.065521, phys 0.067964)\n",
      "Epoch 028 | Train 0.038792 (data 0.037509, phys 0.039342) | Val 0.067545 (data 0.065826, phys 0.068282)\n",
      "Epoch 029 | Train 0.038690 (data 0.038004, phys 0.038984) | Val 0.067031 (data 0.065332, phys 0.067760)\n",
      "Epoch 030 | Train 0.038714 (data 0.037539, phys 0.039217) | Val 0.067678 (data 0.065959, phys 0.068414)\n",
      "Epoch 031 | Train 0.038864 (data 0.037851, phys 0.039298) | Val 0.066649 (data 0.064962, phys 0.067372)\n",
      "Epoch 032 | Train 0.038752 (data 0.037742, phys 0.039184) | Val 0.066935 (data 0.065242, phys 0.067660)\n",
      "Epoch 033 | Train 0.038228 (data 0.037090, phys 0.038715) | Val 0.067558 (data 0.065826, phys 0.068300)\n",
      "Epoch 034 | Train 0.039540 (data 0.038214, phys 0.040108) | Val 0.066790 (data 0.065090, phys 0.067518)\n",
      "Epoch 035 | Train 0.038428 (data 0.037477, phys 0.038836) | Val 0.067283 (data 0.065553, phys 0.068025)\n",
      "Epoch 036 | Train 0.037645 (data 0.037239, phys 0.037819) | Val 0.067031 (data 0.065321, phys 0.067764)\n",
      "Epoch 037 | Train 0.038477 (data 0.037350, phys 0.038960) | Val 0.067313 (data 0.065584, phys 0.068054)\n",
      "Epoch 038 | Train 0.038158 (data 0.037050, phys 0.038633) | Val 0.067208 (data 0.065489, phys 0.067944)\n",
      "Epoch 039 | Train 0.038286 (data 0.038181, phys 0.038330) | Val 0.067008 (data 0.065304, phys 0.067738)\n",
      "Epoch 040 | Train 0.038103 (data 0.037542, phys 0.038343) | Val 0.067138 (data 0.065425, phys 0.067872)\n",
      "Epoch 041 | Train 0.037260 (data 0.036763, phys 0.037473) | Val 0.067072 (data 0.065364, phys 0.067804)\n",
      "Epoch 042 | Train 0.038203 (data 0.037188, phys 0.038638) | Val 0.066881 (data 0.065171, phys 0.067614)\n",
      "Epoch 043 | Train 0.037833 (data 0.036463, phys 0.038419) | Val 0.067683 (data 0.065948, phys 0.068427)\n",
      "Epoch 044 | Train 0.037723 (data 0.037081, phys 0.037999) | Val 0.067190 (data 0.065460, phys 0.067931)\n",
      "Epoch 045 | Train 0.037902 (data 0.036610, phys 0.038456) | Val 0.066920 (data 0.065221, phys 0.067648)\n",
      "Epoch 046 | Train 0.038061 (data 0.036661, phys 0.038662) | Val 0.067011 (data 0.065318, phys 0.067737)\n",
      "Epoch 047 | Train 0.037313 (data 0.036159, phys 0.037807) | Val 0.067768 (data 0.066035, phys 0.068511)\n",
      "Epoch 048 | Train 0.037927 (data 0.036802, phys 0.038409) | Val 0.066934 (data 0.065233, phys 0.067663)\n",
      "Epoch 049 | Train 0.038374 (data 0.036837, phys 0.039033) | Val 0.067129 (data 0.065394, phys 0.067872)\n",
      "Epoch 050 | Train 0.038284 (data 0.036895, phys 0.038879) | Val 0.067349 (data 0.065631, phys 0.068085)\n",
      "Epoch 051 | Train 0.038045 (data 0.037693, phys 0.038195) | Val 0.066927 (data 0.065202, phys 0.067666)\n",
      "Early stopping at epoch 51 (best val = 0.066649)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 1, λ_data = 0.3, λ_phys = 0.7\n",
      "MAE:  12.7856\n",
      "RMSE: 19.5148\n",
      "NMSE: 0.5970\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 1, lambda_data = 0.5, lambda_phys = 0.5\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149494 (data 0.148397, phys 0.150592) | Val 0.112876 (data 0.110786, phys 0.114966)\n",
      "Epoch 002 | Train 0.076739 (data 0.075338, phys 0.078140) | Val 0.112284 (data 0.110188, phys 0.114379)\n",
      "Epoch 003 | Train 0.071821 (data 0.070889, phys 0.072753) | Val 0.112450 (data 0.110317, phys 0.114583)\n",
      "Epoch 004 | Train 0.070012 (data 0.068383, phys 0.071642) | Val 0.108507 (data 0.106417, phys 0.110597)\n",
      "Epoch 005 | Train 0.065925 (data 0.063476, phys 0.068373) | Val 0.100856 (data 0.098841, phys 0.102870)\n",
      "Epoch 006 | Train 0.057228 (data 0.055497, phys 0.058958) | Val 0.086986 (data 0.085153, phys 0.088819)\n",
      "Epoch 007 | Train 0.046284 (data 0.044379, phys 0.048189) | Val 0.074157 (data 0.072601, phys 0.075714)\n",
      "Epoch 008 | Train 0.042115 (data 0.040855, phys 0.043376) | Val 0.070915 (data 0.069507, phys 0.072323)\n",
      "Epoch 009 | Train 0.040079 (data 0.039319, phys 0.040838) | Val 0.070403 (data 0.069026, phys 0.071780)\n",
      "Epoch 010 | Train 0.040374 (data 0.039958, phys 0.040790) | Val 0.069646 (data 0.068298, phys 0.070995)\n",
      "Epoch 011 | Train 0.040518 (data 0.039894, phys 0.041142) | Val 0.068991 (data 0.067653, phys 0.070329)\n",
      "Epoch 012 | Train 0.040546 (data 0.039849, phys 0.041244) | Val 0.068626 (data 0.067310, phys 0.069942)\n",
      "Epoch 013 | Train 0.040130 (data 0.039846, phys 0.040415) | Val 0.068116 (data 0.066818, phys 0.069414)\n",
      "Epoch 014 | Train 0.039693 (data 0.038350, phys 0.041035) | Val 0.067816 (data 0.066538, phys 0.069094)\n",
      "Epoch 015 | Train 0.039422 (data 0.038377, phys 0.040468) | Val 0.067686 (data 0.066413, phys 0.068960)\n",
      "Epoch 016 | Train 0.040200 (data 0.039843, phys 0.040557) | Val 0.066988 (data 0.065726, phys 0.068250)\n",
      "Epoch 017 | Train 0.039462 (data 0.038864, phys 0.040060) | Val 0.067512 (data 0.066261, phys 0.068763)\n",
      "Epoch 018 | Train 0.039163 (data 0.038350, phys 0.039976) | Val 0.066935 (data 0.065670, phys 0.068201)\n",
      "Epoch 019 | Train 0.039043 (data 0.038617, phys 0.039468) | Val 0.066873 (data 0.065621, phys 0.068125)\n",
      "Epoch 020 | Train 0.038591 (data 0.038172, phys 0.039010) | Val 0.067116 (data 0.065868, phys 0.068364)\n",
      "Epoch 021 | Train 0.038551 (data 0.038619, phys 0.038484) | Val 0.067113 (data 0.065865, phys 0.068361)\n",
      "Epoch 022 | Train 0.038530 (data 0.037476, phys 0.039584) | Val 0.066634 (data 0.065394, phys 0.067873)\n",
      "Epoch 023 | Train 0.038430 (data 0.038562, phys 0.038298) | Val 0.067084 (data 0.065841, phys 0.068327)\n",
      "Epoch 024 | Train 0.038577 (data 0.038436, phys 0.038718) | Val 0.066912 (data 0.065675, phys 0.068148)\n",
      "Epoch 025 | Train 0.038707 (data 0.037950, phys 0.039464) | Val 0.066896 (data 0.065657, phys 0.068136)\n",
      "Epoch 026 | Train 0.038092 (data 0.037613, phys 0.038571) | Val 0.066879 (data 0.065643, phys 0.068115)\n",
      "Epoch 027 | Train 0.038453 (data 0.037752, phys 0.039154) | Val 0.066862 (data 0.065635, phys 0.068089)\n",
      "Epoch 028 | Train 0.038477 (data 0.037550, phys 0.039404) | Val 0.066993 (data 0.065767, phys 0.068220)\n",
      "Epoch 029 | Train 0.038518 (data 0.038074, phys 0.038961) | Val 0.066507 (data 0.065292, phys 0.067722)\n",
      "Epoch 030 | Train 0.038380 (data 0.037464, phys 0.039296) | Val 0.067047 (data 0.065819, phys 0.068274)\n",
      "Epoch 031 | Train 0.038601 (data 0.038015, phys 0.039187) | Val 0.066535 (data 0.065311, phys 0.067758)\n",
      "Epoch 032 | Train 0.038357 (data 0.037713, phys 0.039000) | Val 0.066636 (data 0.065424, phys 0.067849)\n",
      "Epoch 033 | Train 0.038010 (data 0.037296, phys 0.038724) | Val 0.067270 (data 0.066023, phys 0.068517)\n",
      "Epoch 034 | Train 0.038945 (data 0.037944, phys 0.039946) | Val 0.066624 (data 0.065402, phys 0.067845)\n",
      "Epoch 035 | Train 0.038272 (data 0.037624, phys 0.038920) | Val 0.066986 (data 0.065745, phys 0.068228)\n",
      "Epoch 036 | Train 0.037674 (data 0.037281, phys 0.038067) | Val 0.066658 (data 0.065431, phys 0.067885)\n",
      "Epoch 037 | Train 0.038263 (data 0.037154, phys 0.039371) | Val 0.066803 (data 0.065567, phys 0.068039)\n",
      "Epoch 038 | Train 0.037984 (data 0.037049, phys 0.038919) | Val 0.066779 (data 0.065550, phys 0.068008)\n",
      "Epoch 039 | Train 0.038342 (data 0.038211, phys 0.038472) | Val 0.067057 (data 0.065837, phys 0.068277)\n",
      "Epoch 040 | Train 0.038022 (data 0.037521, phys 0.038523) | Val 0.066919 (data 0.065692, phys 0.068145)\n",
      "Epoch 041 | Train 0.037251 (data 0.036789, phys 0.037712) | Val 0.066672 (data 0.065451, phys 0.067893)\n",
      "Epoch 042 | Train 0.037622 (data 0.036924, phys 0.038320) | Val 0.066829 (data 0.065592, phys 0.068066)\n",
      "Epoch 043 | Train 0.037674 (data 0.036516, phys 0.038832) | Val 0.067366 (data 0.066129, phys 0.068603)\n",
      "Epoch 044 | Train 0.037510 (data 0.036980, phys 0.038039) | Val 0.066698 (data 0.065466, phys 0.067930)\n",
      "Epoch 045 | Train 0.037182 (data 0.036234, phys 0.038130) | Val 0.066733 (data 0.065514, phys 0.067952)\n",
      "Epoch 046 | Train 0.038066 (data 0.037263, phys 0.038870) | Val 0.066505 (data 0.065290, phys 0.067721)\n",
      "Epoch 047 | Train 0.036962 (data 0.036048, phys 0.037877) | Val 0.067328 (data 0.066106, phys 0.068550)\n",
      "Epoch 048 | Train 0.037850 (data 0.036902, phys 0.038797) | Val 0.066630 (data 0.065405, phys 0.067854)\n",
      "Epoch 049 | Train 0.037810 (data 0.036870, phys 0.038751) | Val 0.066878 (data 0.065632, phys 0.068124)\n",
      "Epoch 050 | Train 0.037789 (data 0.036915, phys 0.038664) | Val 0.067003 (data 0.065771, phys 0.068236)\n",
      "Epoch 051 | Train 0.038015 (data 0.037810, phys 0.038221) | Val 0.066521 (data 0.065291, phys 0.067751)\n",
      "Epoch 052 | Train 0.037689 (data 0.037492, phys 0.037885) | Val 0.066886 (data 0.065660, phys 0.068113)\n",
      "Epoch 053 | Train 0.037704 (data 0.037539, phys 0.037869) | Val 0.067080 (data 0.065839, phys 0.068322)\n",
      "Epoch 054 | Train 0.038139 (data 0.037774, phys 0.038504) | Val 0.066487 (data 0.065251, phys 0.067723)\n",
      "Epoch 055 | Train 0.037876 (data 0.037135, phys 0.038617) | Val 0.067130 (data 0.065890, phys 0.068370)\n",
      "Epoch 056 | Train 0.038709 (data 0.037787, phys 0.039632) | Val 0.066974 (data 0.065726, phys 0.068221)\n",
      "Epoch 057 | Train 0.037167 (data 0.035709, phys 0.038624) | Val 0.066200 (data 0.064985, phys 0.067414)\n",
      "Epoch 058 | Train 0.037823 (data 0.037763, phys 0.037883) | Val 0.066295 (data 0.065069, phys 0.067521)\n",
      "Epoch 059 | Train 0.037767 (data 0.037251, phys 0.038283) | Val 0.066688 (data 0.065434, phys 0.067941)\n",
      "Epoch 060 | Train 0.037304 (data 0.036317, phys 0.038290) | Val 0.067024 (data 0.065785, phys 0.068263)\n",
      "Epoch 061 | Train 0.036897 (data 0.036498, phys 0.037297) | Val 0.067061 (data 0.065820, phys 0.068302)\n",
      "Epoch 062 | Train 0.037996 (data 0.037457, phys 0.038535) | Val 0.066808 (data 0.065557, phys 0.068059)\n",
      "Epoch 063 | Train 0.037387 (data 0.036878, phys 0.037896) | Val 0.066496 (data 0.065251, phys 0.067742)\n",
      "Epoch 064 | Train 0.036911 (data 0.036058, phys 0.037764) | Val 0.066782 (data 0.065544, phys 0.068020)\n",
      "Epoch 065 | Train 0.037765 (data 0.037920, phys 0.037610) | Val 0.065890 (data 0.064669, phys 0.067110)\n",
      "Epoch 066 | Train 0.037519 (data 0.036847, phys 0.038190) | Val 0.066232 (data 0.065014, phys 0.067450)\n",
      "Epoch 067 | Train 0.037576 (data 0.037265, phys 0.037888) | Val 0.066246 (data 0.065012, phys 0.067480)\n",
      "Epoch 068 | Train 0.037563 (data 0.036947, phys 0.038178) | Val 0.066383 (data 0.065154, phys 0.067612)\n",
      "Epoch 069 | Train 0.036398 (data 0.036069, phys 0.036727) | Val 0.066605 (data 0.065371, phys 0.067838)\n",
      "Epoch 070 | Train 0.037793 (data 0.037616, phys 0.037971) | Val 0.066741 (data 0.065481, phys 0.068000)\n",
      "Epoch 071 | Train 0.036567 (data 0.034905, phys 0.038229) | Val 0.067234 (data 0.065983, phys 0.068484)\n",
      "Epoch 072 | Train 0.037752 (data 0.036989, phys 0.038515) | Val 0.066572 (data 0.065321, phys 0.067823)\n",
      "Epoch 073 | Train 0.037110 (data 0.036374, phys 0.037846) | Val 0.066321 (data 0.065089, phys 0.067552)\n",
      "Epoch 074 | Train 0.036940 (data 0.036270, phys 0.037610) | Val 0.066665 (data 0.065424, phys 0.067906)\n",
      "Epoch 075 | Train 0.037916 (data 0.037130, phys 0.038701) | Val 0.066285 (data 0.065049, phys 0.067521)\n",
      "Epoch 076 | Train 0.037814 (data 0.037369, phys 0.038259) | Val 0.065885 (data 0.064655, phys 0.067116)\n",
      "Epoch 077 | Train 0.036998 (data 0.036398, phys 0.037599) | Val 0.066609 (data 0.065358, phys 0.067859)\n",
      "Epoch 078 | Train 0.036849 (data 0.035803, phys 0.037894) | Val 0.066140 (data 0.064909, phys 0.067371)\n",
      "Epoch 079 | Train 0.037337 (data 0.037038, phys 0.037637) | Val 0.066884 (data 0.065650, phys 0.068118)\n",
      "Epoch 080 | Train 0.036942 (data 0.036883, phys 0.037002) | Val 0.066325 (data 0.065084, phys 0.067567)\n",
      "Epoch 081 | Train 0.036836 (data 0.036638, phys 0.037034) | Val 0.066732 (data 0.065474, phys 0.067989)\n",
      "Epoch 082 | Train 0.036504 (data 0.036268, phys 0.036740) | Val 0.066490 (data 0.065270, phys 0.067711)\n",
      "Epoch 083 | Train 0.036986 (data 0.036082, phys 0.037890) | Val 0.066719 (data 0.065460, phys 0.067977)\n",
      "Epoch 084 | Train 0.037607 (data 0.036855, phys 0.038358) | Val 0.066323 (data 0.065081, phys 0.067565)\n",
      "Epoch 085 | Train 0.037376 (data 0.037129, phys 0.037622) | Val 0.066839 (data 0.065582, phys 0.068096)\n",
      "Epoch 086 | Train 0.037497 (data 0.037506, phys 0.037488) | Val 0.066753 (data 0.065490, phys 0.068017)\n",
      "Epoch 087 | Train 0.037369 (data 0.035819, phys 0.038920) | Val 0.065916 (data 0.064689, phys 0.067142)\n",
      "Epoch 088 | Train 0.037148 (data 0.037036, phys 0.037260) | Val 0.066599 (data 0.065345, phys 0.067852)\n",
      "Epoch 089 | Train 0.036891 (data 0.035873, phys 0.037908) | Val 0.066966 (data 0.065712, phys 0.068220)\n",
      "Epoch 090 | Train 0.037618 (data 0.036812, phys 0.038425) | Val 0.066686 (data 0.065422, phys 0.067951)\n",
      "Epoch 091 | Train 0.037166 (data 0.035866, phys 0.038465) | Val 0.066316 (data 0.065072, phys 0.067560)\n",
      "Epoch 092 | Train 0.036647 (data 0.036735, phys 0.036559) | Val 0.066632 (data 0.065371, phys 0.067892)\n",
      "Epoch 093 | Train 0.037362 (data 0.035850, phys 0.038874) | Val 0.066104 (data 0.064864, phys 0.067343)\n",
      "Epoch 094 | Train 0.036962 (data 0.036328, phys 0.037597) | Val 0.067079 (data 0.065812, phys 0.068346)\n",
      "Epoch 095 | Train 0.036869 (data 0.036492, phys 0.037247) | Val 0.066112 (data 0.064880, phys 0.067344)\n",
      "Epoch 096 | Train 0.036321 (data 0.036058, phys 0.036584) | Val 0.067413 (data 0.066146, phys 0.068681)\n",
      "Early stopping at epoch 96 (best val = 0.065885)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 1, λ_data = 0.5, λ_phys = 0.5\n",
      "MAE:  12.8550\n",
      "RMSE: 19.4646\n",
      "NMSE: 0.5939\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 1, lambda_data = 0.7, lambda_phys = 0.3\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149018 (data 0.148364, phys 0.150546) | Val 0.112053 (data 0.110798, phys 0.114981)\n",
      "Epoch 002 | Train 0.076190 (data 0.075353, phys 0.078143) | Val 0.111450 (data 0.110193, phys 0.114384)\n",
      "Epoch 003 | Train 0.071458 (data 0.070905, phys 0.072750) | Val 0.111725 (data 0.110444, phys 0.114713)\n",
      "Epoch 004 | Train 0.069384 (data 0.068408, phys 0.071662) | Val 0.107731 (data 0.106477, phys 0.110658)\n",
      "Epoch 005 | Train 0.064999 (data 0.063527, phys 0.068432) | Val 0.100357 (data 0.099145, phys 0.103185)\n",
      "Epoch 006 | Train 0.056553 (data 0.055506, phys 0.058994) | Val 0.086260 (data 0.085160, phys 0.088826)\n",
      "Epoch 007 | Train 0.045455 (data 0.044300, phys 0.048150) | Val 0.073674 (data 0.072741, phys 0.075849)\n",
      "Epoch 008 | Train 0.041643 (data 0.040886, phys 0.043411) | Val 0.070229 (data 0.069383, phys 0.072205)\n",
      "Epoch 009 | Train 0.039842 (data 0.039366, phys 0.040953) | Val 0.070087 (data 0.069256, phys 0.072026)\n",
      "Epoch 010 | Train 0.040287 (data 0.040023, phys 0.040902) | Val 0.068965 (data 0.068150, phys 0.070868)\n",
      "Epoch 011 | Train 0.040366 (data 0.039980, phys 0.041264) | Val 0.068656 (data 0.067852, phys 0.070531)\n",
      "Epoch 012 | Train 0.040409 (data 0.039986, phys 0.041396) | Val 0.068143 (data 0.067355, phys 0.069983)\n",
      "Epoch 013 | Train 0.040063 (data 0.039885, phys 0.040478) | Val 0.067679 (data 0.066899, phys 0.069499)\n",
      "Epoch 014 | Train 0.039206 (data 0.038400, phys 0.041089) | Val 0.067227 (data 0.066459, phys 0.069019)\n",
      "Epoch 015 | Train 0.038985 (data 0.038315, phys 0.040548) | Val 0.067304 (data 0.066543, phys 0.069080)\n",
      "Epoch 016 | Train 0.040104 (data 0.039853, phys 0.040689) | Val 0.066411 (data 0.065657, phys 0.068169)\n",
      "Epoch 017 | Train 0.039159 (data 0.038782, phys 0.040037) | Val 0.067171 (data 0.066418, phys 0.068930)\n",
      "Epoch 018 | Train 0.038791 (data 0.038296, phys 0.039944) | Val 0.066562 (data 0.065801, phys 0.068338)\n",
      "Epoch 019 | Train 0.038977 (data 0.038748, phys 0.039511) | Val 0.066556 (data 0.065803, phys 0.068312)\n",
      "Epoch 020 | Train 0.038432 (data 0.038183, phys 0.039012) | Val 0.067400 (data 0.066650, phys 0.069151)\n",
      "Epoch 021 | Train 0.038769 (data 0.038808, phys 0.038677) | Val 0.066794 (data 0.066045, phys 0.068543)\n",
      "Epoch 022 | Train 0.038085 (data 0.037421, phys 0.039634) | Val 0.066468 (data 0.065712, phys 0.068232)\n",
      "Epoch 023 | Train 0.038507 (data 0.038571, phys 0.038358) | Val 0.066737 (data 0.065990, phys 0.068480)\n",
      "Epoch 024 | Train 0.038567 (data 0.038437, phys 0.038870) | Val 0.066593 (data 0.065844, phys 0.068343)\n",
      "Epoch 025 | Train 0.038309 (data 0.037855, phys 0.039370) | Val 0.066602 (data 0.065853, phys 0.068349)\n",
      "Epoch 026 | Train 0.037947 (data 0.037680, phys 0.038569) | Val 0.066625 (data 0.065878, phys 0.068367)\n",
      "Epoch 027 | Train 0.038242 (data 0.037808, phys 0.039257) | Val 0.066445 (data 0.065701, phys 0.068182)\n",
      "Epoch 028 | Train 0.038173 (data 0.037658, phys 0.039376) | Val 0.066478 (data 0.065736, phys 0.068208)\n",
      "Epoch 029 | Train 0.038372 (data 0.038108, phys 0.038987) | Val 0.066024 (data 0.065291, phys 0.067734)\n",
      "Epoch 030 | Train 0.037965 (data 0.037416, phys 0.039247) | Val 0.066634 (data 0.065897, phys 0.068353)\n",
      "Epoch 031 | Train 0.038366 (data 0.037982, phys 0.039261) | Val 0.066272 (data 0.065528, phys 0.068006)\n",
      "Epoch 032 | Train 0.038052 (data 0.037669, phys 0.038948) | Val 0.066251 (data 0.065515, phys 0.067970)\n",
      "Epoch 033 | Train 0.037759 (data 0.037272, phys 0.038896) | Val 0.067132 (data 0.066372, phys 0.068905)\n",
      "Epoch 034 | Train 0.038657 (data 0.038011, phys 0.040164) | Val 0.066133 (data 0.065399, phys 0.067847)\n",
      "Epoch 035 | Train 0.038031 (data 0.037610, phys 0.039014) | Val 0.066868 (data 0.066112, phys 0.068633)\n",
      "Epoch 036 | Train 0.037598 (data 0.037357, phys 0.038160) | Val 0.066298 (data 0.065554, phys 0.068034)\n",
      "Epoch 037 | Train 0.037662 (data 0.037013, phys 0.039174) | Val 0.066326 (data 0.065582, phys 0.068060)\n",
      "Epoch 038 | Train 0.037637 (data 0.037041, phys 0.039029) | Val 0.066690 (data 0.065937, phys 0.068446)\n",
      "Epoch 039 | Train 0.038272 (data 0.038198, phys 0.038446) | Val 0.066651 (data 0.065919, phys 0.068359)\n",
      "Epoch 040 | Train 0.037740 (data 0.037421, phys 0.038484) | Val 0.066718 (data 0.065977, phys 0.068446)\n",
      "Epoch 041 | Train 0.037124 (data 0.036827, phys 0.037818) | Val 0.066052 (data 0.065322, phys 0.067755)\n",
      "Epoch 042 | Train 0.037411 (data 0.036995, phys 0.038382) | Val 0.066282 (data 0.065539, phys 0.068015)\n",
      "Epoch 043 | Train 0.037221 (data 0.036560, phys 0.038762) | Val 0.066673 (data 0.065930, phys 0.068406)\n",
      "Epoch 044 | Train 0.037286 (data 0.036945, phys 0.038081) | Val 0.066051 (data 0.065313, phys 0.067771)\n",
      "Epoch 045 | Train 0.036780 (data 0.036193, phys 0.038151) | Val 0.066381 (data 0.065647, phys 0.068093)\n",
      "Epoch 046 | Train 0.037879 (data 0.037419, phys 0.038953) | Val 0.065774 (data 0.065048, phys 0.067468)\n",
      "Epoch 047 | Train 0.036518 (data 0.036009, phys 0.037705) | Val 0.066947 (data 0.066210, phys 0.068667)\n",
      "Epoch 048 | Train 0.037336 (data 0.036765, phys 0.038668) | Val 0.066297 (data 0.065556, phys 0.068028)\n",
      "Epoch 049 | Train 0.037370 (data 0.036752, phys 0.038812) | Val 0.066398 (data 0.065653, phys 0.068139)\n",
      "Epoch 050 | Train 0.037471 (data 0.036996, phys 0.038578) | Val 0.066731 (data 0.065988, phys 0.068465)\n",
      "Epoch 051 | Train 0.038074 (data 0.037932, phys 0.038406) | Val 0.065974 (data 0.065236, phys 0.067698)\n",
      "Epoch 052 | Train 0.037514 (data 0.037339, phys 0.037922) | Val 0.066476 (data 0.065736, phys 0.068202)\n",
      "Epoch 053 | Train 0.037687 (data 0.037586, phys 0.037922) | Val 0.066687 (data 0.065935, phys 0.068441)\n",
      "Epoch 054 | Train 0.037966 (data 0.037805, phys 0.038341) | Val 0.066024 (data 0.065282, phys 0.067754)\n",
      "Epoch 055 | Train 0.037570 (data 0.037069, phys 0.038739) | Val 0.066624 (data 0.065882, phys 0.068357)\n",
      "Epoch 056 | Train 0.038109 (data 0.037581, phys 0.039340) | Val 0.066542 (data 0.065793, phys 0.068290)\n",
      "Epoch 057 | Train 0.036562 (data 0.035732, phys 0.038499) | Val 0.066067 (data 0.065328, phys 0.067792)\n",
      "Epoch 058 | Train 0.037755 (data 0.037691, phys 0.037906) | Val 0.066013 (data 0.065269, phys 0.067748)\n",
      "Epoch 059 | Train 0.037341 (data 0.037001, phys 0.038135) | Val 0.066462 (data 0.065702, phys 0.068234)\n",
      "Epoch 060 | Train 0.036887 (data 0.036282, phys 0.038300) | Val 0.066813 (data 0.066063, phys 0.068562)\n",
      "Epoch 061 | Train 0.036773 (data 0.036581, phys 0.037219) | Val 0.066512 (data 0.065766, phys 0.068253)\n",
      "Epoch 062 | Train 0.037906 (data 0.037604, phys 0.038610) | Val 0.066128 (data 0.065379, phys 0.067877)\n",
      "Epoch 063 | Train 0.037055 (data 0.036709, phys 0.037862) | Val 0.066161 (data 0.065411, phys 0.067911)\n",
      "Epoch 064 | Train 0.036691 (data 0.036169, phys 0.037910) | Val 0.066278 (data 0.065533, phys 0.068016)\n",
      "Epoch 065 | Train 0.037642 (data 0.037616, phys 0.037705) | Val 0.065569 (data 0.064831, phys 0.067290)\n",
      "Epoch 066 | Train 0.037293 (data 0.036957, phys 0.038079) | Val 0.065574 (data 0.064839, phys 0.067288)\n",
      "Epoch 067 | Train 0.037107 (data 0.036931, phys 0.037519) | Val 0.066200 (data 0.065452, phys 0.067947)\n",
      "Epoch 068 | Train 0.037165 (data 0.036795, phys 0.038029) | Val 0.066138 (data 0.065394, phys 0.067873)\n",
      "Epoch 069 | Train 0.036297 (data 0.036120, phys 0.036708) | Val 0.066038 (data 0.065294, phys 0.067774)\n",
      "Epoch 070 | Train 0.037791 (data 0.037702, phys 0.037998) | Val 0.066529 (data 0.065762, phys 0.068318)\n",
      "Epoch 071 | Train 0.035960 (data 0.034975, phys 0.038258) | Val 0.066450 (data 0.065702, phys 0.068194)\n",
      "Epoch 072 | Train 0.037297 (data 0.036869, phys 0.038295) | Val 0.066522 (data 0.065760, phys 0.068302)\n",
      "Epoch 073 | Train 0.036833 (data 0.036425, phys 0.037784) | Val 0.065975 (data 0.065229, phys 0.067715)\n",
      "Epoch 074 | Train 0.036628 (data 0.036207, phys 0.037611) | Val 0.066312 (data 0.065560, phys 0.068065)\n",
      "Epoch 075 | Train 0.037721 (data 0.037281, phys 0.038747) | Val 0.065726 (data 0.064983, phys 0.067459)\n",
      "Epoch 076 | Train 0.037556 (data 0.037268, phys 0.038226) | Val 0.065761 (data 0.065010, phys 0.067512)\n",
      "Epoch 077 | Train 0.037051 (data 0.036758, phys 0.037736) | Val 0.065793 (data 0.065044, phys 0.067540)\n",
      "Epoch 078 | Train 0.036313 (data 0.035704, phys 0.037734) | Val 0.065753 (data 0.065010, phys 0.067488)\n",
      "Epoch 079 | Train 0.037296 (data 0.037130, phys 0.037682) | Val 0.066392 (data 0.065648, phys 0.068127)\n",
      "Epoch 080 | Train 0.036821 (data 0.036775, phys 0.036926) | Val 0.065661 (data 0.064917, phys 0.067396)\n",
      "Epoch 081 | Train 0.036804 (data 0.036693, phys 0.037065) | Val 0.066098 (data 0.065343, phys 0.067861)\n",
      "Epoch 082 | Train 0.036619 (data 0.036477, phys 0.036949) | Val 0.066152 (data 0.065407, phys 0.067892)\n",
      "Epoch 083 | Train 0.036727 (data 0.036213, phys 0.037928) | Val 0.066043 (data 0.065289, phys 0.067803)\n",
      "Epoch 084 | Train 0.037195 (data 0.036683, phys 0.038391) | Val 0.065908 (data 0.065155, phys 0.067664)\n",
      "Epoch 085 | Train 0.037131 (data 0.036996, phys 0.037445) | Val 0.066210 (data 0.065454, phys 0.067975)\n",
      "Early stopping at epoch 85 (best val = 0.065569)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 1, λ_data = 0.7, λ_phys = 0.3\n",
      "MAE:  12.8602\n",
      "RMSE: 19.4922\n",
      "NMSE: 0.5956\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 1, lambda_data = 1.0, lambda_phys = 0.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.148911 (data 0.148911, phys 0.151119) | Val 0.110767 (data 0.110767, phys 0.114940)\n",
      "Epoch 002 | Train 0.075491 (data 0.075491, phys 0.078291) | Val 0.110194 (data 0.110194, phys 0.114383)\n",
      "Epoch 003 | Train 0.070901 (data 0.070901, phys 0.072764) | Val 0.110600 (data 0.110600, phys 0.114876)\n",
      "Epoch 004 | Train 0.068401 (data 0.068401, phys 0.071647) | Val 0.106309 (data 0.106309, phys 0.110484)\n",
      "Epoch 005 | Train 0.063404 (data 0.063404, phys 0.068285) | Val 0.098929 (data 0.098929, phys 0.102968)\n",
      "Epoch 006 | Train 0.055256 (data 0.055256, phys 0.058742) | Val 0.084793 (data 0.084793, phys 0.088447)\n",
      "Epoch 007 | Train 0.044186 (data 0.044186, phys 0.048152) | Val 0.073324 (data 0.073324, phys 0.076459)\n",
      "Epoch 008 | Train 0.041015 (data 0.041015, phys 0.043657) | Val 0.069505 (data 0.069505, phys 0.072371)\n",
      "Epoch 009 | Train 0.039557 (data 0.039557, phys 0.040952) | Val 0.069557 (data 0.069557, phys 0.072345)\n",
      "Epoch 010 | Train 0.040025 (data 0.040025, phys 0.041081) | Val 0.068109 (data 0.068109, phys 0.070869)\n",
      "Epoch 011 | Train 0.040097 (data 0.040097, phys 0.041339) | Val 0.068091 (data 0.068091, phys 0.070782)\n",
      "Epoch 012 | Train 0.039596 (data 0.039596, phys 0.041567) | Val 0.067251 (data 0.067251, phys 0.069908)\n",
      "Epoch 013 | Train 0.039862 (data 0.039862, phys 0.040700) | Val 0.067653 (data 0.067653, phys 0.070310)\n",
      "Epoch 014 | Train 0.038284 (data 0.038284, phys 0.041380) | Val 0.066924 (data 0.066924, phys 0.069533)\n",
      "Epoch 015 | Train 0.038608 (data 0.038608, phys 0.040822) | Val 0.066568 (data 0.066568, phys 0.069140)\n",
      "Epoch 016 | Train 0.039819 (data 0.039819, phys 0.040705) | Val 0.065854 (data 0.065854, phys 0.068383)\n",
      "Epoch 017 | Train 0.039343 (data 0.039343, phys 0.040473) | Val 0.067140 (data 0.067140, phys 0.069707)\n",
      "Epoch 018 | Train 0.038218 (data 0.038218, phys 0.040098) | Val 0.066097 (data 0.066097, phys 0.068680)\n",
      "Epoch 019 | Train 0.038876 (data 0.038876, phys 0.039677) | Val 0.065940 (data 0.065940, phys 0.068474)\n",
      "Epoch 020 | Train 0.038057 (data 0.038057, phys 0.039010) | Val 0.067474 (data 0.067474, phys 0.070010)\n",
      "Epoch 021 | Train 0.039033 (data 0.039033, phys 0.039151) | Val 0.066323 (data 0.066323, phys 0.068863)\n",
      "Epoch 022 | Train 0.037662 (data 0.037662, phys 0.039848) | Val 0.066103 (data 0.066103, phys 0.068686)\n",
      "Epoch 023 | Train 0.038597 (data 0.038597, phys 0.038716) | Val 0.066046 (data 0.066046, phys 0.068573)\n",
      "Epoch 024 | Train 0.038721 (data 0.038721, phys 0.039283) | Val 0.066119 (data 0.066119, phys 0.068671)\n",
      "Epoch 025 | Train 0.038059 (data 0.038059, phys 0.039376) | Val 0.066182 (data 0.066182, phys 0.068737)\n",
      "Epoch 026 | Train 0.037789 (data 0.037789, phys 0.038748) | Val 0.066100 (data 0.066100, phys 0.068647)\n",
      "Epoch 027 | Train 0.037721 (data 0.037721, phys 0.039309) | Val 0.066038 (data 0.066038, phys 0.068582)\n",
      "Epoch 028 | Train 0.037569 (data 0.037569, phys 0.039649) | Val 0.065659 (data 0.065659, phys 0.068170)\n",
      "Epoch 029 | Train 0.037717 (data 0.037717, phys 0.038645) | Val 0.065253 (data 0.065253, phys 0.067725)\n",
      "Epoch 030 | Train 0.037487 (data 0.037487, phys 0.039414) | Val 0.065426 (data 0.065426, phys 0.067888)\n",
      "Epoch 031 | Train 0.038066 (data 0.038066, phys 0.039435) | Val 0.065498 (data 0.065498, phys 0.067974)\n",
      "Epoch 032 | Train 0.037752 (data 0.037752, phys 0.039022) | Val 0.065770 (data 0.065770, phys 0.068286)\n",
      "Epoch 033 | Train 0.037342 (data 0.037342, phys 0.039194) | Val 0.066998 (data 0.066998, phys 0.069594)\n",
      "Epoch 034 | Train 0.038060 (data 0.038060, phys 0.040119) | Val 0.065527 (data 0.065527, phys 0.068020)\n",
      "Epoch 035 | Train 0.037681 (data 0.037681, phys 0.038941) | Val 0.066480 (data 0.066480, phys 0.069062)\n",
      "Epoch 036 | Train 0.037748 (data 0.037748, phys 0.038419) | Val 0.066088 (data 0.066088, phys 0.068655)\n",
      "Epoch 037 | Train 0.037226 (data 0.037226, phys 0.039214) | Val 0.065761 (data 0.065761, phys 0.068305)\n",
      "Epoch 038 | Train 0.036828 (data 0.036828, phys 0.039182) | Val 0.066447 (data 0.066447, phys 0.069006)\n",
      "Epoch 039 | Train 0.038333 (data 0.038333, phys 0.038571) | Val 0.066486 (data 0.066486, phys 0.068899)\n",
      "Epoch 040 | Train 0.037948 (data 0.037948, phys 0.038876) | Val 0.065768 (data 0.065768, phys 0.068287)\n",
      "Epoch 041 | Train 0.036952 (data 0.036952, phys 0.037712) | Val 0.065174 (data 0.065174, phys 0.067631)\n",
      "Epoch 042 | Train 0.036995 (data 0.036995, phys 0.038389) | Val 0.065485 (data 0.065485, phys 0.067967)\n",
      "Epoch 043 | Train 0.036508 (data 0.036508, phys 0.038683) | Val 0.065885 (data 0.065885, phys 0.068394)\n",
      "Epoch 044 | Train 0.037559 (data 0.037559, phys 0.038435) | Val 0.065255 (data 0.065255, phys 0.067743)\n",
      "Epoch 045 | Train 0.036353 (data 0.036353, phys 0.038264) | Val 0.065647 (data 0.065647, phys 0.068117)\n",
      "Epoch 046 | Train 0.037242 (data 0.037242, phys 0.038804) | Val 0.064885 (data 0.064885, phys 0.067292)\n",
      "Epoch 047 | Train 0.035953 (data 0.035953, phys 0.037856) | Val 0.066185 (data 0.066185, phys 0.068659)\n",
      "Epoch 048 | Train 0.036851 (data 0.036851, phys 0.038535) | Val 0.065529 (data 0.065529, phys 0.068024)\n",
      "Epoch 049 | Train 0.037040 (data 0.037040, phys 0.038879) | Val 0.065628 (data 0.065628, phys 0.068109)\n",
      "Epoch 050 | Train 0.037063 (data 0.037063, phys 0.038874) | Val 0.065822 (data 0.065822, phys 0.068300)\n",
      "Epoch 051 | Train 0.038159 (data 0.038159, phys 0.038648) | Val 0.065148 (data 0.065148, phys 0.067616)\n",
      "Epoch 052 | Train 0.037271 (data 0.037271, phys 0.037458) | Val 0.065343 (data 0.065343, phys 0.067794)\n",
      "Epoch 053 | Train 0.037583 (data 0.037583, phys 0.038267) | Val 0.066166 (data 0.066166, phys 0.068691)\n",
      "Epoch 054 | Train 0.037914 (data 0.037914, phys 0.038335) | Val 0.064940 (data 0.064940, phys 0.067404)\n",
      "Epoch 055 | Train 0.037105 (data 0.037105, phys 0.039063) | Val 0.065662 (data 0.065662, phys 0.068138)\n",
      "Epoch 056 | Train 0.037565 (data 0.037565, phys 0.039137) | Val 0.066152 (data 0.066152, phys 0.068694)\n",
      "Epoch 057 | Train 0.035694 (data 0.035694, phys 0.038523) | Val 0.065451 (data 0.065451, phys 0.067940)\n",
      "Epoch 058 | Train 0.037208 (data 0.037208, phys 0.038002) | Val 0.065301 (data 0.065301, phys 0.067763)\n",
      "Epoch 059 | Train 0.036989 (data 0.036989, phys 0.038248) | Val 0.065755 (data 0.065755, phys 0.068286)\n",
      "Epoch 060 | Train 0.036583 (data 0.036583, phys 0.038113) | Val 0.066713 (data 0.066713, phys 0.069235)\n",
      "Epoch 061 | Train 0.036480 (data 0.036480, phys 0.037488) | Val 0.065280 (data 0.065280, phys 0.067738)\n",
      "Epoch 062 | Train 0.038160 (data 0.038160, phys 0.038733) | Val 0.065246 (data 0.065246, phys 0.067749)\n",
      "Epoch 063 | Train 0.036745 (data 0.036745, phys 0.038437) | Val 0.065707 (data 0.065707, phys 0.068234)\n",
      "Epoch 064 | Train 0.036398 (data 0.036398, phys 0.038001) | Val 0.066169 (data 0.066169, phys 0.068695)\n",
      "Epoch 065 | Train 0.037700 (data 0.037700, phys 0.037716) | Val 0.064965 (data 0.064965, phys 0.067450)\n",
      "Epoch 066 | Train 0.037078 (data 0.037078, phys 0.038117) | Val 0.064848 (data 0.064848, phys 0.067325)\n",
      "Epoch 067 | Train 0.036933 (data 0.036933, phys 0.037323) | Val 0.065591 (data 0.065591, phys 0.068094)\n",
      "Epoch 068 | Train 0.036718 (data 0.036718, phys 0.038238) | Val 0.065056 (data 0.065056, phys 0.067537)\n",
      "Epoch 069 | Train 0.036318 (data 0.036318, phys 0.036906) | Val 0.065234 (data 0.065234, phys 0.067734)\n",
      "Epoch 070 | Train 0.037831 (data 0.037831, phys 0.038285) | Val 0.065753 (data 0.065753, phys 0.068329)\n",
      "Epoch 071 | Train 0.035184 (data 0.035184, phys 0.038517) | Val 0.066139 (data 0.066139, phys 0.068639)\n",
      "Epoch 072 | Train 0.037029 (data 0.037029, phys 0.037997) | Val 0.065978 (data 0.065978, phys 0.068541)\n",
      "Epoch 073 | Train 0.036510 (data 0.036510, phys 0.037943) | Val 0.065377 (data 0.065377, phys 0.067890)\n",
      "Epoch 074 | Train 0.036408 (data 0.036408, phys 0.037504) | Val 0.065664 (data 0.065664, phys 0.068169)\n",
      "Epoch 075 | Train 0.037443 (data 0.037443, phys 0.038707) | Val 0.065049 (data 0.065049, phys 0.067524)\n",
      "Epoch 076 | Train 0.036820 (data 0.036820, phys 0.038218) | Val 0.065660 (data 0.065660, phys 0.068216)\n",
      "Epoch 077 | Train 0.037199 (data 0.037199, phys 0.037980) | Val 0.065179 (data 0.065179, phys 0.067689)\n",
      "Epoch 078 | Train 0.035545 (data 0.035545, phys 0.037942) | Val 0.065023 (data 0.065023, phys 0.067485)\n",
      "Epoch 079 | Train 0.036958 (data 0.036958, phys 0.037680) | Val 0.066172 (data 0.066172, phys 0.068657)\n",
      "Epoch 080 | Train 0.036968 (data 0.036968, phys 0.036872) | Val 0.065216 (data 0.065216, phys 0.067739)\n",
      "Epoch 081 | Train 0.036684 (data 0.036684, phys 0.037121) | Val 0.065094 (data 0.065094, phys 0.067603)\n",
      "Epoch 082 | Train 0.036444 (data 0.036444, phys 0.037292) | Val 0.065732 (data 0.065732, phys 0.068183)\n",
      "Epoch 083 | Train 0.036315 (data 0.036315, phys 0.038132) | Val 0.065108 (data 0.065108, phys 0.067602)\n",
      "Epoch 084 | Train 0.036409 (data 0.036409, phys 0.038080) | Val 0.065652 (data 0.065652, phys 0.068182)\n",
      "Epoch 085 | Train 0.036557 (data 0.036557, phys 0.036949) | Val 0.065953 (data 0.065953, phys 0.068486)\n",
      "Epoch 086 | Train 0.037449 (data 0.037449, phys 0.037356) | Val 0.065688 (data 0.065688, phys 0.068245)\n",
      "Early stopping at epoch 86 (best val = 0.064848)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 1, λ_data = 1.0, λ_phys = 0.0\n",
      "MAE:  12.7642\n",
      "RMSE: 19.4974\n",
      "NMSE: 0.5959\n",
      "\n",
      "============================================================\n",
      "Preparing and training LSTM+Physics for LAG = 7\n",
      "============================================================\n",
      "\n",
      "--- Supervised Data (Head) ---\n",
      "            Daily_Mean_Ozone  Daily_AQI_Value  AQI_Targeted_Value_LAG_7  \\\n",
      "DATE                                                                      \n",
      "2022-01-01          0.025000        23.000000                 15.666667   \n",
      "2022-01-02          0.032333        30.333333                 24.333333   \n",
      "2022-01-03          0.029667        27.666667                 22.000000   \n",
      "2022-01-04          0.036000        33.333333                 26.666667   \n",
      "2022-01-05          0.033000        30.666667                 29.666667   \n",
      "\n",
      "            OZONE_Targeted_Value_LAG_7  \n",
      "DATE                                    \n",
      "2022-01-01                    0.016667  \n",
      "2022-01-02                    0.026333  \n",
      "2022-01-03                    0.023667  \n",
      "2022-01-04                    0.029000  \n",
      "2022-01-05                    0.032000  \n",
      "Shape: (1084, 4)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- First 10 Samples: True vs Physics AQI (Target Day) ---\n",
      "Sample 01: True=15.667, Physics=15.432, Diff=0.235\n",
      "Sample 02: True=24.333, Physics=24.383, Diff=0.049\n",
      "Sample 03: True=22.000, Physics=21.914, Diff=0.086\n",
      "Sample 04: True=26.667, Physics=26.852, Diff=0.185\n",
      "Sample 05: True=29.667, Physics=29.630, Diff=0.037\n",
      "Sample 06: True=28.667, Physics=28.704, Diff=0.037\n",
      "Sample 07: True=41.333, Physics=41.049, Diff=0.284\n",
      "Sample 08: True=26.667, Physics=26.543, Diff=0.123\n",
      "Sample 09: True=29.000, Physics=29.012, Diff=0.012\n",
      "Sample 10: True=28.667, Physics=28.704, Diff=0.037\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 7, lambda_data = 0.0, lambda_phys = 1.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.150126 (data 0.148297, phys 0.150126) | Val 0.115540 (data 0.111400, phys 0.115540)\n",
      "Epoch 002 | Train 0.078473 (data 0.072809, phys 0.078473) | Val 0.115604 (data 0.111402, phys 0.115604)\n",
      "Epoch 003 | Train 0.071899 (data 0.069978, phys 0.071899) | Val 0.116717 (data 0.112436, phys 0.116717)\n",
      "Epoch 004 | Train 0.070596 (data 0.069714, phys 0.070596) | Val 0.116236 (data 0.111971, phys 0.116236)\n",
      "Epoch 005 | Train 0.069055 (data 0.067594, phys 0.069055) | Val 0.115846 (data 0.111590, phys 0.115846)\n",
      "Epoch 006 | Train 0.069971 (data 0.067166, phys 0.069971) | Val 0.114785 (data 0.110563, phys 0.114785)\n",
      "Epoch 007 | Train 0.066455 (data 0.066670, phys 0.066455) | Val 0.113852 (data 0.109672, phys 0.113852)\n",
      "Epoch 008 | Train 0.063202 (data 0.059933, phys 0.063202) | Val 0.113329 (data 0.109230, phys 0.113329)\n",
      "Epoch 009 | Train 0.058375 (data 0.057905, phys 0.058375) | Val 0.112674 (data 0.108708, phys 0.112674)\n",
      "Epoch 010 | Train 0.058162 (data 0.054541, phys 0.058162) | Val 0.114093 (data 0.110192, phys 0.114093)\n",
      "Epoch 011 | Train 0.057566 (data 0.054154, phys 0.057566) | Val 0.114006 (data 0.110153, phys 0.114006)\n",
      "Epoch 012 | Train 0.056090 (data 0.052664, phys 0.056090) | Val 0.115246 (data 0.111382, phys 0.115246)\n",
      "Epoch 013 | Train 0.055055 (data 0.054199, phys 0.055055) | Val 0.115428 (data 0.111567, phys 0.115428)\n",
      "Epoch 014 | Train 0.058226 (data 0.054080, phys 0.058226) | Val 0.114567 (data 0.110729, phys 0.114567)\n",
      "Epoch 015 | Train 0.055605 (data 0.053749, phys 0.055605) | Val 0.114286 (data 0.110460, phys 0.114286)\n",
      "Epoch 016 | Train 0.056781 (data 0.054644, phys 0.056781) | Val 0.114881 (data 0.111046, phys 0.114881)\n",
      "Epoch 017 | Train 0.055195 (data 0.054983, phys 0.055195) | Val 0.115616 (data 0.111777, phys 0.115616)\n",
      "Epoch 018 | Train 0.055572 (data 0.055299, phys 0.055572) | Val 0.115363 (data 0.111542, phys 0.115363)\n",
      "Epoch 019 | Train 0.056624 (data 0.053483, phys 0.056624) | Val 0.115655 (data 0.111826, phys 0.115655)\n",
      "Epoch 020 | Train 0.056197 (data 0.053610, phys 0.056197) | Val 0.115376 (data 0.111545, phys 0.115376)\n",
      "Epoch 021 | Train 0.054259 (data 0.053143, phys 0.054259) | Val 0.115678 (data 0.111835, phys 0.115678)\n",
      "Epoch 022 | Train 0.056970 (data 0.052419, phys 0.056970) | Val 0.116331 (data 0.112484, phys 0.116331)\n",
      "Epoch 023 | Train 0.056172 (data 0.053673, phys 0.056172) | Val 0.114922 (data 0.111092, phys 0.114922)\n",
      "Epoch 024 | Train 0.056407 (data 0.054207, phys 0.056407) | Val 0.115864 (data 0.112034, phys 0.115864)\n",
      "Epoch 025 | Train 0.056437 (data 0.052915, phys 0.056437) | Val 0.116047 (data 0.112199, phys 0.116047)\n",
      "Epoch 026 | Train 0.056133 (data 0.054428, phys 0.056133) | Val 0.115559 (data 0.111725, phys 0.115559)\n",
      "Epoch 027 | Train 0.056229 (data 0.055437, phys 0.056229) | Val 0.115726 (data 0.111892, phys 0.115726)\n",
      "Epoch 028 | Train 0.055202 (data 0.053295, phys 0.055202) | Val 0.116120 (data 0.112275, phys 0.116120)\n",
      "Epoch 029 | Train 0.056119 (data 0.053704, phys 0.056119) | Val 0.116520 (data 0.112672, phys 0.116520)\n",
      "Early stopping at epoch 29 (best val = 0.112674)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 7, λ_data = 0.0, λ_phys = 1.0\n",
      "MAE:  16.6970\n",
      "RMSE: 25.2380\n",
      "NMSE: 0.9939\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 7, lambda_data = 0.3, lambda_phys = 0.7\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149692 (data 0.148425, phys 0.150235) | Val 0.114301 (data 0.111406, phys 0.115542)\n",
      "Epoch 002 | Train 0.076814 (data 0.072807, phys 0.078531) | Val 0.114344 (data 0.111402, phys 0.115605)\n",
      "Epoch 003 | Train 0.071244 (data 0.069965, phys 0.071793) | Val 0.115564 (data 0.112563, phys 0.116850)\n",
      "Epoch 004 | Train 0.070429 (data 0.069814, phys 0.070692) | Val 0.114853 (data 0.111871, phys 0.116131)\n",
      "Epoch 005 | Train 0.068447 (data 0.067422, phys 0.068887) | Val 0.114537 (data 0.111557, phys 0.115814)\n",
      "Epoch 006 | Train 0.068853 (data 0.066914, phys 0.069684) | Val 0.113448 (data 0.110493, phys 0.114714)\n",
      "Epoch 007 | Train 0.065715 (data 0.065849, phys 0.065657) | Val 0.112237 (data 0.109325, phys 0.113485)\n",
      "Epoch 008 | Train 0.061281 (data 0.059163, phys 0.062188) | Val 0.111866 (data 0.109017, phys 0.113087)\n",
      "Epoch 009 | Train 0.057506 (data 0.057288, phys 0.057600) | Val 0.111800 (data 0.109029, phys 0.112988)\n",
      "Epoch 010 | Train 0.056925 (data 0.054355, phys 0.058026) | Val 0.112709 (data 0.109980, phys 0.113879)\n",
      "Epoch 011 | Train 0.056379 (data 0.053998, phys 0.057399) | Val 0.113104 (data 0.110396, phys 0.114265)\n",
      "Epoch 012 | Train 0.055078 (data 0.052803, phys 0.056054) | Val 0.113537 (data 0.110832, phys 0.114697)\n",
      "Epoch 013 | Train 0.054837 (data 0.054289, phys 0.055072) | Val 0.113996 (data 0.111291, phys 0.115156)\n",
      "Epoch 014 | Train 0.057028 (data 0.054151, phys 0.058261) | Val 0.113576 (data 0.110881, phys 0.114731)\n",
      "Epoch 015 | Train 0.055171 (data 0.053859, phys 0.055732) | Val 0.113133 (data 0.110445, phys 0.114285)\n",
      "Epoch 016 | Train 0.055883 (data 0.054318, phys 0.056554) | Val 0.113722 (data 0.111030, phys 0.114876)\n",
      "Epoch 017 | Train 0.055108 (data 0.054833, phys 0.055225) | Val 0.114156 (data 0.111460, phys 0.115312)\n",
      "Epoch 018 | Train 0.055461 (data 0.055172, phys 0.055585) | Val 0.113863 (data 0.111178, phys 0.115014)\n",
      "Epoch 019 | Train 0.055791 (data 0.053465, phys 0.056787) | Val 0.114238 (data 0.111546, phys 0.115391)\n",
      "Epoch 020 | Train 0.055522 (data 0.053745, phys 0.056284) | Val 0.114097 (data 0.111407, phys 0.115250)\n",
      "Epoch 021 | Train 0.053845 (data 0.053000, phys 0.054207) | Val 0.114218 (data 0.111525, phys 0.115372)\n",
      "Epoch 022 | Train 0.055543 (data 0.052509, phys 0.056843) | Val 0.114577 (data 0.111880, phys 0.115733)\n",
      "Epoch 023 | Train 0.055424 (data 0.053894, phys 0.056080) | Val 0.113925 (data 0.111234, phys 0.115078)\n",
      "Epoch 024 | Train 0.055728 (data 0.054213, phys 0.056377) | Val 0.114573 (data 0.111886, phys 0.115725)\n",
      "Epoch 025 | Train 0.055275 (data 0.052728, phys 0.056366) | Val 0.114642 (data 0.111944, phys 0.115798)\n",
      "Epoch 026 | Train 0.055684 (data 0.054330, phys 0.056264) | Val 0.114280 (data 0.111589, phys 0.115433)\n",
      "Epoch 027 | Train 0.055862 (data 0.055384, phys 0.056067) | Val 0.114449 (data 0.111762, phys 0.115600)\n",
      "Epoch 028 | Train 0.054583 (data 0.053379, phys 0.055100) | Val 0.114728 (data 0.112036, phys 0.115881)\n",
      "Epoch 029 | Train 0.055342 (data 0.053546, phys 0.056112) | Val 0.115055 (data 0.112359, phys 0.116211)\n",
      "Early stopping at epoch 29 (best val = 0.111800)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 7, λ_data = 0.3, λ_phys = 0.7\n",
      "MAE:  16.6655\n",
      "RMSE: 25.2851\n",
      "NMSE: 0.9976\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 7, lambda_data = 0.5, lambda_phys = 0.5\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149242 (data 0.148338, phys 0.150146) | Val 0.113474 (data 0.111406, phys 0.115542)\n",
      "Epoch 002 | Train 0.075704 (data 0.072827, phys 0.078580) | Val 0.113482 (data 0.111382, phys 0.115582)\n",
      "Epoch 003 | Train 0.070984 (data 0.070087, phys 0.071881) | Val 0.114654 (data 0.112511, phys 0.116796)\n",
      "Epoch 004 | Train 0.070360 (data 0.069887, phys 0.070832) | Val 0.113895 (data 0.111767, phys 0.116022)\n",
      "Epoch 005 | Train 0.068180 (data 0.067415, phys 0.068944) | Val 0.113680 (data 0.111552, phys 0.115809)\n",
      "Epoch 006 | Train 0.068335 (data 0.066945, phys 0.069724) | Val 0.112632 (data 0.110521, phys 0.114743)\n",
      "Epoch 007 | Train 0.065843 (data 0.065888, phys 0.065798) | Val 0.111226 (data 0.109150, phys 0.113302)\n",
      "Epoch 008 | Train 0.060836 (data 0.059338, phys 0.062333) | Val 0.111153 (data 0.109115, phys 0.113191)\n",
      "Epoch 009 | Train 0.057614 (data 0.057410, phys 0.057818) | Val 0.111043 (data 0.109059, phys 0.113026)\n",
      "Epoch 010 | Train 0.056241 (data 0.054361, phys 0.058121) | Val 0.111981 (data 0.110029, phys 0.113932)\n",
      "Epoch 011 | Train 0.055740 (data 0.053998, phys 0.057483) | Val 0.112473 (data 0.110536, phys 0.114410)\n",
      "Epoch 012 | Train 0.054436 (data 0.052751, phys 0.056121) | Val 0.112824 (data 0.110891, phys 0.114756)\n",
      "Epoch 013 | Train 0.054690 (data 0.054337, phys 0.055044) | Val 0.113121 (data 0.111189, phys 0.115052)\n",
      "Epoch 014 | Train 0.056178 (data 0.054104, phys 0.058253) | Val 0.112989 (data 0.111062, phys 0.114916)\n",
      "Epoch 015 | Train 0.054759 (data 0.053863, phys 0.055656) | Val 0.112548 (data 0.110626, phys 0.114470)\n",
      "Epoch 016 | Train 0.055463 (data 0.054401, phys 0.056526) | Val 0.113206 (data 0.111281, phys 0.115130)\n",
      "Epoch 017 | Train 0.054960 (data 0.054766, phys 0.055155) | Val 0.113431 (data 0.111505, phys 0.115358)\n",
      "Epoch 018 | Train 0.055429 (data 0.055221, phys 0.055637) | Val 0.113131 (data 0.111211, phys 0.115051)\n",
      "Epoch 019 | Train 0.055124 (data 0.053475, phys 0.056774) | Val 0.113605 (data 0.111680, phys 0.115530)\n",
      "Epoch 020 | Train 0.055024 (data 0.053800, phys 0.056247) | Val 0.113637 (data 0.111713, phys 0.115560)\n",
      "Epoch 021 | Train 0.053693 (data 0.053159, phys 0.054226) | Val 0.113584 (data 0.111661, phys 0.115506)\n",
      "Epoch 022 | Train 0.054747 (data 0.052560, phys 0.056935) | Val 0.113649 (data 0.111724, phys 0.115574)\n",
      "Epoch 023 | Train 0.054906 (data 0.053738, phys 0.056075) | Val 0.113728 (data 0.111804, phys 0.115652)\n",
      "Epoch 024 | Train 0.055177 (data 0.054096, phys 0.056258) | Val 0.114082 (data 0.112160, phys 0.116003)\n",
      "Epoch 025 | Train 0.054429 (data 0.052616, phys 0.056242) | Val 0.113959 (data 0.112033, phys 0.115885)\n",
      "Epoch 026 | Train 0.055429 (data 0.054486, phys 0.056372) | Val 0.113711 (data 0.111791, phys 0.115632)\n",
      "Epoch 027 | Train 0.055676 (data 0.055340, phys 0.056013) | Val 0.113840 (data 0.111921, phys 0.115759)\n",
      "Epoch 028 | Train 0.054267 (data 0.053424, phys 0.055110) | Val 0.114078 (data 0.112156, phys 0.116000)\n",
      "Epoch 029 | Train 0.054754 (data 0.053500, phys 0.056008) | Val 0.114484 (data 0.112557, phys 0.116410)\n",
      "Early stopping at epoch 29 (best val = 0.111043)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 7, λ_data = 0.5, λ_phys = 0.5\n",
      "MAE:  16.6616\n",
      "RMSE: 25.2858\n",
      "NMSE: 0.9977\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 7, lambda_data = 0.7, lambda_phys = 0.3\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.148710 (data 0.148165, phys 0.149980) | Val 0.112611 (data 0.111366, phys 0.115516)\n",
      "Epoch 002 | Train 0.074469 (data 0.072743, phys 0.078494) | Val 0.112664 (data 0.111404, phys 0.115606)\n",
      "Epoch 003 | Train 0.070426 (data 0.069883, phys 0.071693) | Val 0.114166 (data 0.112876, phys 0.117176)\n",
      "Epoch 004 | Train 0.070347 (data 0.070107, phys 0.070905) | Val 0.112902 (data 0.111628, phys 0.115876)\n",
      "Epoch 005 | Train 0.067970 (data 0.067507, phys 0.069051) | Val 0.112916 (data 0.111637, phys 0.115898)\n",
      "Epoch 006 | Train 0.067736 (data 0.066910, phys 0.069662) | Val 0.111943 (data 0.110674, phys 0.114903)\n",
      "Epoch 007 | Train 0.065855 (data 0.065912, phys 0.065722) | Val 0.110493 (data 0.109246, phys 0.113403)\n",
      "Epoch 008 | Train 0.060312 (data 0.059423, phys 0.062386) | Val 0.110431 (data 0.109205, phys 0.113289)\n",
      "Epoch 009 | Train 0.057639 (data 0.057558, phys 0.057829) | Val 0.110411 (data 0.109219, phys 0.113193)\n",
      "Epoch 010 | Train 0.055481 (data 0.054364, phys 0.058088) | Val 0.111289 (data 0.110118, phys 0.114021)\n",
      "Epoch 011 | Train 0.055040 (data 0.053956, phys 0.057569) | Val 0.111946 (data 0.110783, phys 0.114659)\n",
      "Epoch 012 | Train 0.053656 (data 0.052611, phys 0.056092) | Val 0.112125 (data 0.110966, phys 0.114831)\n",
      "Epoch 013 | Train 0.054480 (data 0.054251, phys 0.055013) | Val 0.112744 (data 0.111585, phys 0.115449)\n",
      "Epoch 014 | Train 0.055137 (data 0.053900, phys 0.058023) | Val 0.112636 (data 0.111479, phys 0.115336)\n",
      "Epoch 015 | Train 0.054191 (data 0.053593, phys 0.055586) | Val 0.112232 (data 0.111078, phys 0.114924)\n",
      "Epoch 016 | Train 0.054968 (data 0.054353, phys 0.056402) | Val 0.112755 (data 0.111600, phys 0.115448)\n",
      "Epoch 017 | Train 0.054804 (data 0.054731, phys 0.054972) | Val 0.112772 (data 0.111615, phys 0.115470)\n",
      "Epoch 018 | Train 0.055319 (data 0.055141, phys 0.055734) | Val 0.112562 (data 0.111408, phys 0.115253)\n",
      "Epoch 019 | Train 0.054395 (data 0.053424, phys 0.056661) | Val 0.112926 (data 0.111770, phys 0.115623)\n",
      "Epoch 020 | Train 0.054506 (data 0.053775, phys 0.056212) | Val 0.113136 (data 0.111980, phys 0.115832)\n",
      "Epoch 021 | Train 0.053441 (data 0.053143, phys 0.054138) | Val 0.112858 (data 0.111706, phys 0.115545)\n",
      "Epoch 022 | Train 0.053894 (data 0.052579, phys 0.056962) | Val 0.112771 (data 0.111617, phys 0.115464)\n",
      "Epoch 023 | Train 0.054307 (data 0.053578, phys 0.056007) | Val 0.113305 (data 0.112150, phys 0.116000)\n",
      "Epoch 024 | Train 0.054658 (data 0.053953, phys 0.056305) | Val 0.113496 (data 0.112342, phys 0.116187)\n",
      "Epoch 025 | Train 0.053601 (data 0.052489, phys 0.056195) | Val 0.113143 (data 0.111988, phys 0.115838)\n",
      "Epoch 026 | Train 0.054821 (data 0.054253, phys 0.056145) | Val 0.113109 (data 0.111956, phys 0.115799)\n",
      "Epoch 027 | Train 0.055504 (data 0.055271, phys 0.056047) | Val 0.113220 (data 0.112069, phys 0.115906)\n",
      "Epoch 028 | Train 0.053857 (data 0.053365, phys 0.055004) | Val 0.113064 (data 0.111914, phys 0.115750)\n",
      "Epoch 029 | Train 0.054161 (data 0.053398, phys 0.055940) | Val 0.113517 (data 0.112362, phys 0.116212)\n",
      "Early stopping at epoch 29 (best val = 0.110411)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 7, λ_data = 0.7, λ_phys = 0.3\n",
      "MAE:  16.6410\n",
      "RMSE: 25.3056\n",
      "NMSE: 0.9992\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 7, lambda_data = 1.0, lambda_phys = 0.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.148350 (data 0.148350, phys 0.150178) | Val 0.111371 (data 0.111371, phys 0.115518)\n",
      "Epoch 002 | Train 0.072813 (data 0.072813, phys 0.078620) | Val 0.111389 (data 0.111389, phys 0.115589)\n",
      "Epoch 003 | Train 0.069871 (data 0.069871, phys 0.071745) | Val 0.113011 (data 0.113011, phys 0.117316)\n",
      "Epoch 004 | Train 0.070222 (data 0.070222, phys 0.070784) | Val 0.111682 (data 0.111682, phys 0.115933)\n",
      "Epoch 005 | Train 0.067469 (data 0.067469, phys 0.068986) | Val 0.111737 (data 0.111737, phys 0.116002)\n",
      "Epoch 006 | Train 0.067108 (data 0.067108, phys 0.069854) | Val 0.110510 (data 0.110510, phys 0.114731)\n",
      "Epoch 007 | Train 0.065800 (data 0.065800, phys 0.065738) | Val 0.109043 (data 0.109043, phys 0.113191)\n",
      "Epoch 008 | Train 0.059201 (data 0.059201, phys 0.062130) | Val 0.109317 (data 0.109317, phys 0.113395)\n",
      "Epoch 009 | Train 0.057399 (data 0.057399, phys 0.057598) | Val 0.109471 (data 0.109471, phys 0.113449)\n",
      "Epoch 010 | Train 0.054364 (data 0.054364, phys 0.058071) | Val 0.110090 (data 0.110090, phys 0.113998)\n",
      "Epoch 011 | Train 0.054012 (data 0.054012, phys 0.057534) | Val 0.110587 (data 0.110587, phys 0.114471)\n",
      "Epoch 012 | Train 0.052756 (data 0.052756, phys 0.056103) | Val 0.110527 (data 0.110527, phys 0.114397)\n",
      "Epoch 013 | Train 0.054347 (data 0.054347, phys 0.055104) | Val 0.111322 (data 0.111322, phys 0.115195)\n",
      "Epoch 014 | Train 0.053896 (data 0.053896, phys 0.058004) | Val 0.111660 (data 0.111660, phys 0.115532)\n",
      "Epoch 015 | Train 0.053570 (data 0.053570, phys 0.055638) | Val 0.111255 (data 0.111255, phys 0.115116)\n",
      "Epoch 016 | Train 0.054415 (data 0.054415, phys 0.056371) | Val 0.111692 (data 0.111692, phys 0.115549)\n",
      "Epoch 017 | Train 0.054664 (data 0.054664, phys 0.054949) | Val 0.111588 (data 0.111588, phys 0.115457)\n",
      "Epoch 018 | Train 0.055273 (data 0.055273, phys 0.055767) | Val 0.111177 (data 0.111177, phys 0.115038)\n",
      "Epoch 019 | Train 0.053551 (data 0.053551, phys 0.056761) | Val 0.111449 (data 0.111449, phys 0.115314)\n",
      "Epoch 020 | Train 0.053789 (data 0.053789, phys 0.056333) | Val 0.112023 (data 0.112023, phys 0.115888)\n",
      "Epoch 021 | Train 0.053161 (data 0.053161, phys 0.054031) | Val 0.111564 (data 0.111564, phys 0.115409)\n",
      "Epoch 022 | Train 0.052512 (data 0.052512, phys 0.056960) | Val 0.111267 (data 0.111267, phys 0.115119)\n",
      "Epoch 023 | Train 0.053591 (data 0.053591, phys 0.056083) | Val 0.112833 (data 0.112833, phys 0.116701)\n",
      "Epoch 024 | Train 0.054146 (data 0.054146, phys 0.056461) | Val 0.112515 (data 0.112515, phys 0.116372)\n",
      "Epoch 025 | Train 0.052356 (data 0.052356, phys 0.056243) | Val 0.111779 (data 0.111779, phys 0.115634)\n",
      "Epoch 026 | Train 0.054343 (data 0.054343, phys 0.056168) | Val 0.111883 (data 0.111883, phys 0.115735)\n",
      "Epoch 027 | Train 0.055309 (data 0.055309, phys 0.056109) | Val 0.112069 (data 0.112069, phys 0.115918)\n",
      "Early stopping at epoch 27 (best val = 0.109043)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 7, λ_data = 1.0, λ_phys = 0.0\n",
      "MAE:  16.7570\n",
      "RMSE: 25.2099\n",
      "NMSE: 0.9917\n",
      "\n",
      "============================================================\n",
      "Preparing and training LSTM+Physics for LAG = 14\n",
      "============================================================\n",
      "\n",
      "--- Supervised Data (Head) ---\n",
      "            Daily_Mean_Ozone  Daily_AQI_Value  AQI_Targeted_Value_LAG_14  \\\n",
      "DATE                                                                       \n",
      "2022-01-01          0.025000        23.000000                  26.666667   \n",
      "2022-01-02          0.032333        30.333333                  29.000000   \n",
      "2022-01-03          0.029667        27.666667                  28.666667   \n",
      "2022-01-04          0.036000        33.333333                  40.666667   \n",
      "2022-01-05          0.033000        30.666667                  23.333333   \n",
      "\n",
      "            OZONE_Targeted_Value_LAG_14  \n",
      "DATE                                     \n",
      "2022-01-01                     0.028667  \n",
      "2022-01-02                     0.031333  \n",
      "2022-01-03                     0.031000  \n",
      "2022-01-04                     0.044000  \n",
      "2022-01-05                     0.025333  \n",
      "Shape: (1077, 4)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- First 10 Samples: True vs Physics AQI (Target Day) ---\n",
      "Sample 01: True=26.667, Physics=26.543, Diff=0.123\n",
      "Sample 02: True=29.000, Physics=29.012, Diff=0.012\n",
      "Sample 03: True=28.667, Physics=28.704, Diff=0.037\n",
      "Sample 04: True=40.667, Physics=40.741, Diff=0.074\n",
      "Sample 05: True=23.333, Physics=23.457, Diff=0.123\n",
      "Sample 06: True=26.000, Physics=25.926, Diff=0.074\n",
      "Sample 07: True=26.500, Physics=26.389, Diff=0.111\n",
      "Sample 08: True=25.000, Physics=25.000, Diff=0.000\n",
      "Sample 09: True=33.500, Physics=33.333, Diff=0.167\n",
      "Sample 10: True=18.000, Physics=18.056, Diff=0.056\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 14, lambda_data = 0.0, lambda_phys = 1.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.153411 (data 0.151432, phys 0.153411) | Val 0.116153 (data 0.112046, phys 0.116153)\n",
      "Epoch 002 | Train 0.079690 (data 0.075294, phys 0.079690) | Val 0.116145 (data 0.111911, phys 0.116145)\n",
      "Epoch 003 | Train 0.074377 (data 0.072509, phys 0.074377) | Val 0.116976 (data 0.112679, phys 0.116976)\n",
      "Epoch 004 | Train 0.074484 (data 0.071544, phys 0.074484) | Val 0.116263 (data 0.111979, phys 0.116263)\n",
      "Epoch 005 | Train 0.072102 (data 0.069575, phys 0.072102) | Val 0.115545 (data 0.111260, phys 0.115545)\n",
      "Epoch 006 | Train 0.072051 (data 0.068794, phys 0.072051) | Val 0.114044 (data 0.109765, phys 0.114044)\n",
      "Epoch 007 | Train 0.071457 (data 0.067068, phys 0.071457) | Val 0.111107 (data 0.106873, phys 0.111107)\n",
      "Epoch 008 | Train 0.066941 (data 0.064798, phys 0.066941) | Val 0.108771 (data 0.104481, phys 0.108771)\n",
      "Epoch 009 | Train 0.064970 (data 0.062068, phys 0.064970) | Val 0.104923 (data 0.100711, phys 0.104923)\n",
      "Epoch 010 | Train 0.063214 (data 0.060836, phys 0.063214) | Val 0.103293 (data 0.099096, phys 0.103293)\n",
      "Epoch 011 | Train 0.062717 (data 0.060111, phys 0.062717) | Val 0.102366 (data 0.098207, phys 0.102366)\n",
      "Epoch 012 | Train 0.060930 (data 0.059110, phys 0.060930) | Val 0.102256 (data 0.098107, phys 0.102256)\n",
      "Epoch 013 | Train 0.061921 (data 0.060624, phys 0.061921) | Val 0.102305 (data 0.098141, phys 0.102305)\n",
      "Epoch 014 | Train 0.061131 (data 0.058827, phys 0.061131) | Val 0.102144 (data 0.097994, phys 0.102144)\n",
      "Epoch 015 | Train 0.060328 (data 0.060479, phys 0.060328) | Val 0.102191 (data 0.098032, phys 0.102191)\n",
      "Epoch 016 | Train 0.061249 (data 0.059667, phys 0.061249) | Val 0.102536 (data 0.098352, phys 0.102536)\n",
      "Epoch 017 | Train 0.059937 (data 0.060563, phys 0.059937) | Val 0.102231 (data 0.098077, phys 0.102231)\n",
      "Epoch 018 | Train 0.061233 (data 0.057775, phys 0.061233) | Val 0.102430 (data 0.098260, phys 0.102430)\n",
      "Epoch 019 | Train 0.061651 (data 0.059123, phys 0.061651) | Val 0.102336 (data 0.098184, phys 0.102336)\n",
      "Epoch 020 | Train 0.061296 (data 0.059957, phys 0.061296) | Val 0.102297 (data 0.098146, phys 0.102297)\n",
      "Epoch 021 | Train 0.061445 (data 0.059907, phys 0.061445) | Val 0.102295 (data 0.098149, phys 0.102295)\n",
      "Epoch 022 | Train 0.059911 (data 0.059299, phys 0.059911) | Val 0.102806 (data 0.098612, phys 0.102806)\n",
      "Epoch 023 | Train 0.059877 (data 0.058561, phys 0.059877) | Val 0.102620 (data 0.098442, phys 0.102620)\n",
      "Epoch 024 | Train 0.060341 (data 0.059971, phys 0.060341) | Val 0.102636 (data 0.098459, phys 0.102636)\n",
      "Epoch 025 | Train 0.060914 (data 0.058641, phys 0.060914) | Val 0.102547 (data 0.098383, phys 0.102547)\n",
      "Epoch 026 | Train 0.059741 (data 0.058844, phys 0.059741) | Val 0.102678 (data 0.098502, phys 0.102678)\n",
      "Epoch 027 | Train 0.061037 (data 0.059217, phys 0.061037) | Val 0.102533 (data 0.098370, phys 0.102533)\n",
      "Epoch 028 | Train 0.060231 (data 0.058877, phys 0.060231) | Val 0.102491 (data 0.098334, phys 0.102491)\n",
      "Epoch 029 | Train 0.061412 (data 0.058669, phys 0.061412) | Val 0.102415 (data 0.098277, phys 0.102415)\n",
      "Epoch 030 | Train 0.060639 (data 0.058003, phys 0.060639) | Val 0.102644 (data 0.098475, phys 0.102644)\n",
      "Epoch 031 | Train 0.060463 (data 0.057897, phys 0.060463) | Val 0.102496 (data 0.098342, phys 0.102496)\n",
      "Epoch 032 | Train 0.060823 (data 0.057867, phys 0.060823) | Val 0.102488 (data 0.098340, phys 0.102488)\n",
      "Epoch 033 | Train 0.060010 (data 0.058628, phys 0.060010) | Val 0.102624 (data 0.098448, phys 0.102624)\n",
      "Epoch 034 | Train 0.061484 (data 0.057983, phys 0.061484) | Val 0.102402 (data 0.098263, phys 0.102402)\n",
      "Early stopping at epoch 34 (best val = 0.102144)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 14, λ_data = 0.0, λ_phys = 1.0\n",
      "MAE:  16.4360\n",
      "RMSE: 23.9733\n",
      "NMSE: 0.8927\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 14, lambda_data = 0.3, lambda_phys = 0.7\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.152901 (data 0.151520, phys 0.153492) | Val 0.114957 (data 0.112086, phys 0.116188)\n",
      "Epoch 002 | Train 0.078370 (data 0.075302, phys 0.079685) | Val 0.114963 (data 0.111993, phys 0.116236)\n",
      "Epoch 003 | Train 0.073803 (data 0.072621, phys 0.074310) | Val 0.115453 (data 0.112451, phys 0.116739)\n",
      "Epoch 004 | Train 0.073556 (data 0.071390, phys 0.074485) | Val 0.114907 (data 0.111907, phys 0.116193)\n",
      "Epoch 005 | Train 0.071396 (data 0.069586, phys 0.072172) | Val 0.114015 (data 0.111018, phys 0.115300)\n",
      "Epoch 006 | Train 0.070984 (data 0.068674, phys 0.071974) | Val 0.112513 (data 0.109516, phys 0.113798)\n",
      "Epoch 007 | Train 0.069487 (data 0.066301, phys 0.070853) | Val 0.109772 (data 0.106788, phys 0.111050)\n",
      "Epoch 008 | Train 0.065749 (data 0.064233, phys 0.066399) | Val 0.106829 (data 0.103837, phys 0.108111)\n",
      "Epoch 009 | Train 0.063760 (data 0.061714, phys 0.064637) | Val 0.103396 (data 0.100453, phys 0.104657)\n",
      "Epoch 010 | Train 0.062372 (data 0.060747, phys 0.063068) | Val 0.101960 (data 0.099027, phys 0.103218)\n",
      "Epoch 011 | Train 0.061837 (data 0.060194, phys 0.062541) | Val 0.101102 (data 0.098192, phys 0.102349)\n",
      "Epoch 012 | Train 0.060366 (data 0.059138, phys 0.060892) | Val 0.101063 (data 0.098155, phys 0.102309)\n",
      "Epoch 013 | Train 0.061505 (data 0.060375, phys 0.061990) | Val 0.101106 (data 0.098194, phys 0.102353)\n",
      "Epoch 014 | Train 0.060349 (data 0.058737, phys 0.061040) | Val 0.101080 (data 0.098171, phys 0.102327)\n",
      "Epoch 015 | Train 0.060408 (data 0.060490, phys 0.060373) | Val 0.101077 (data 0.098162, phys 0.102326)\n",
      "Epoch 016 | Train 0.060754 (data 0.059577, phys 0.061259) | Val 0.101173 (data 0.098254, phys 0.102424)\n",
      "Epoch 017 | Train 0.060213 (data 0.060635, phys 0.060033) | Val 0.101051 (data 0.098144, phys 0.102297)\n",
      "Epoch 018 | Train 0.060206 (data 0.057720, phys 0.061272) | Val 0.101247 (data 0.098328, phys 0.102499)\n",
      "Epoch 019 | Train 0.061018 (data 0.059262, phys 0.061770) | Val 0.101092 (data 0.098188, phys 0.102336)\n",
      "Epoch 020 | Train 0.060898 (data 0.059934, phys 0.061311) | Val 0.101040 (data 0.098140, phys 0.102283)\n",
      "Epoch 021 | Train 0.060999 (data 0.059965, phys 0.061443) | Val 0.101062 (data 0.098158, phys 0.102307)\n",
      "Epoch 022 | Train 0.059738 (data 0.059356, phys 0.059902) | Val 0.101339 (data 0.098411, phys 0.102593)\n",
      "Epoch 023 | Train 0.059457 (data 0.058626, phys 0.059813) | Val 0.101184 (data 0.098270, phys 0.102433)\n",
      "Epoch 024 | Train 0.060272 (data 0.060103, phys 0.060345) | Val 0.101263 (data 0.098343, phys 0.102515)\n",
      "Epoch 025 | Train 0.060220 (data 0.058489, phys 0.060962) | Val 0.101145 (data 0.098236, phys 0.102392)\n",
      "Epoch 026 | Train 0.059369 (data 0.058741, phys 0.059639) | Val 0.101310 (data 0.098392, phys 0.102560)\n",
      "Epoch 027 | Train 0.060509 (data 0.059041, phys 0.061138) | Val 0.101205 (data 0.098292, phys 0.102453)\n",
      "Epoch 028 | Train 0.059881 (data 0.058788, phys 0.060349) | Val 0.101200 (data 0.098288, phys 0.102447)\n",
      "Epoch 029 | Train 0.060466 (data 0.058348, phys 0.061373) | Val 0.101156 (data 0.098253, phys 0.102401)\n",
      "Epoch 030 | Train 0.059913 (data 0.058055, phys 0.060709) | Val 0.101190 (data 0.098281, phys 0.102437)\n",
      "Epoch 031 | Train 0.059823 (data 0.057916, phys 0.060640) | Val 0.101183 (data 0.098274, phys 0.102429)\n",
      "Epoch 032 | Train 0.059998 (data 0.057921, phys 0.060888) | Val 0.101192 (data 0.098281, phys 0.102440)\n",
      "Epoch 033 | Train 0.059588 (data 0.058558, phys 0.060030) | Val 0.101276 (data 0.098356, phys 0.102527)\n",
      "Epoch 034 | Train 0.060310 (data 0.058023, phys 0.061291) | Val 0.101136 (data 0.098233, phys 0.102380)\n",
      "Epoch 035 | Train 0.059880 (data 0.058550, phys 0.060450) | Val 0.101232 (data 0.098322, phys 0.102479)\n",
      "Epoch 036 | Train 0.059372 (data 0.058309, phys 0.059828) | Val 0.101312 (data 0.098398, phys 0.102561)\n",
      "Epoch 037 | Train 0.061083 (data 0.060631, phys 0.061276) | Val 0.101329 (data 0.098411, phys 0.102580)\n",
      "Epoch 038 | Train 0.060280 (data 0.059010, phys 0.060825) | Val 0.101197 (data 0.098288, phys 0.102444)\n",
      "Epoch 039 | Train 0.059677 (data 0.057335, phys 0.060681) | Val 0.101326 (data 0.098405, phys 0.102577)\n",
      "Epoch 040 | Train 0.059471 (data 0.058869, phys 0.059729) | Val 0.101157 (data 0.098251, phys 0.102403)\n",
      "Early stopping at epoch 40 (best val = 0.101040)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 14, λ_data = 0.3, λ_phys = 0.7\n",
      "MAE:  16.4991\n",
      "RMSE: 23.9886\n",
      "NMSE: 0.8938\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 14, lambda_data = 0.5, lambda_phys = 0.5\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.152217 (data 0.151237, phys 0.153196) | Val 0.114062 (data 0.112007, phys 0.116116)\n",
      "Epoch 002 | Train 0.077413 (data 0.075209, phys 0.079617) | Val 0.114145 (data 0.112023, phys 0.116267)\n",
      "Epoch 003 | Train 0.073339 (data 0.072481, phys 0.074198) | Val 0.114717 (data 0.112570, phys 0.116864)\n",
      "Epoch 004 | Train 0.072832 (data 0.071281, phys 0.074382) | Val 0.114154 (data 0.112009, phys 0.116299)\n",
      "Epoch 005 | Train 0.070871 (data 0.069557, phys 0.072185) | Val 0.113263 (data 0.111120, phys 0.115406)\n",
      "Epoch 006 | Train 0.070422 (data 0.068791, phys 0.072053) | Val 0.111793 (data 0.109650, phys 0.113936)\n",
      "Epoch 007 | Train 0.068686 (data 0.066398, phys 0.070975) | Val 0.109199 (data 0.107062, phys 0.111336)\n",
      "Epoch 008 | Train 0.065402 (data 0.064298, phys 0.066505) | Val 0.106030 (data 0.103894, phys 0.108166)\n",
      "Epoch 009 | Train 0.063225 (data 0.061778, phys 0.064672) | Val 0.102660 (data 0.100553, phys 0.104767)\n",
      "Epoch 010 | Train 0.061888 (data 0.060688, phys 0.063089) | Val 0.101135 (data 0.099040, phys 0.103231)\n",
      "Epoch 011 | Train 0.061481 (data 0.060258, phys 0.062704) | Val 0.100376 (data 0.098301, phys 0.102451)\n",
      "Epoch 012 | Train 0.060027 (data 0.059143, phys 0.060910) | Val 0.100258 (data 0.098180, phys 0.102335)\n",
      "Epoch 013 | Train 0.061214 (data 0.060342, phys 0.062086) | Val 0.100159 (data 0.098081, phys 0.102236)\n",
      "Epoch 014 | Train 0.059945 (data 0.058804, phys 0.061086) | Val 0.100278 (data 0.098198, phys 0.102357)\n",
      "Epoch 015 | Train 0.060480 (data 0.060519, phys 0.060441) | Val 0.100251 (data 0.098171, phys 0.102330)\n",
      "Epoch 016 | Train 0.060364 (data 0.059568, phys 0.061160) | Val 0.100285 (data 0.098202, phys 0.102368)\n",
      "Epoch 017 | Train 0.060401 (data 0.060671, phys 0.060132) | Val 0.100211 (data 0.098136, phys 0.102287)\n",
      "Epoch 018 | Train 0.059423 (data 0.057627, phys 0.061218) | Val 0.100394 (data 0.098308, phys 0.102480)\n",
      "Epoch 019 | Train 0.060531 (data 0.059258, phys 0.061805) | Val 0.100209 (data 0.098135, phys 0.102282)\n",
      "Epoch 020 | Train 0.060565 (data 0.059824, phys 0.061306) | Val 0.100179 (data 0.098110, phys 0.102248)\n",
      "Epoch 021 | Train 0.060708 (data 0.059948, phys 0.061469) | Val 0.100234 (data 0.098159, phys 0.102308)\n",
      "Epoch 022 | Train 0.059646 (data 0.059368, phys 0.059925) | Val 0.100416 (data 0.098329, phys 0.102504)\n",
      "Epoch 023 | Train 0.059251 (data 0.058625, phys 0.059877) | Val 0.100264 (data 0.098187, phys 0.102341)\n",
      "Epoch 024 | Train 0.060234 (data 0.060132, phys 0.060336) | Val 0.100489 (data 0.098401, phys 0.102577)\n",
      "Epoch 025 | Train 0.059749 (data 0.058536, phys 0.060961) | Val 0.100328 (data 0.098250, phys 0.102406)\n",
      "Epoch 026 | Train 0.059144 (data 0.058678, phys 0.059610) | Val 0.100440 (data 0.098357, phys 0.102523)\n",
      "Epoch 027 | Train 0.060029 (data 0.059011, phys 0.061046) | Val 0.100431 (data 0.098348, phys 0.102514)\n",
      "Epoch 028 | Train 0.059618 (data 0.058825, phys 0.060412) | Val 0.100413 (data 0.098332, phys 0.102494)\n",
      "Epoch 029 | Train 0.059802 (data 0.058277, phys 0.061328) | Val 0.100390 (data 0.098313, phys 0.102467)\n",
      "Epoch 030 | Train 0.059369 (data 0.058062, phys 0.060675) | Val 0.100393 (data 0.098315, phys 0.102470)\n",
      "Epoch 031 | Train 0.059322 (data 0.057937, phys 0.060706) | Val 0.100407 (data 0.098329, phys 0.102485)\n",
      "Epoch 032 | Train 0.059446 (data 0.057933, phys 0.060959) | Val 0.100468 (data 0.098388, phys 0.102549)\n",
      "Epoch 033 | Train 0.059284 (data 0.058562, phys 0.060005) | Val 0.100475 (data 0.098392, phys 0.102558)\n",
      "Early stopping at epoch 33 (best val = 0.100159)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 14, λ_data = 0.5, λ_phys = 0.5\n",
      "MAE:  16.4206\n",
      "RMSE: 23.9859\n",
      "NMSE: 0.8936\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 14, lambda_data = 0.7, lambda_phys = 0.3\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.151820 (data 0.151231, phys 0.153194) | Val 0.113248 (data 0.112015, phys 0.116124)\n",
      "Epoch 002 | Train 0.076499 (data 0.075181, phys 0.079575) | Val 0.113342 (data 0.112067, phys 0.116316)\n",
      "Epoch 003 | Train 0.072948 (data 0.072432, phys 0.074154) | Val 0.113914 (data 0.112625, phys 0.116921)\n",
      "Epoch 004 | Train 0.072186 (data 0.071258, phys 0.074350) | Val 0.113307 (data 0.112020, phys 0.116311)\n",
      "Epoch 005 | Train 0.070360 (data 0.069575, phys 0.072193) | Val 0.112492 (data 0.111205, phys 0.115496)\n",
      "Epoch 006 | Train 0.069805 (data 0.068829, phys 0.072084) | Val 0.110952 (data 0.109666, phys 0.113953)\n",
      "Epoch 007 | Train 0.067742 (data 0.066353, phys 0.070983) | Val 0.108493 (data 0.107208, phys 0.111493)\n",
      "Epoch 008 | Train 0.064955 (data 0.064300, phys 0.066483) | Val 0.105055 (data 0.103774, phys 0.108043)\n",
      "Epoch 009 | Train 0.062628 (data 0.061763, phys 0.064646) | Val 0.101689 (data 0.100424, phys 0.104639)\n",
      "Epoch 010 | Train 0.061362 (data 0.060607, phys 0.063124) | Val 0.100258 (data 0.098999, phys 0.103195)\n",
      "Epoch 011 | Train 0.060952 (data 0.060187, phys 0.062737) | Val 0.099408 (data 0.098162, phys 0.102316)\n",
      "Epoch 012 | Train 0.059823 (data 0.059315, phys 0.061008) | Val 0.099272 (data 0.098026, phys 0.102178)\n",
      "Epoch 013 | Train 0.060915 (data 0.060417, phys 0.062078) | Val 0.099245 (data 0.098000, phys 0.102149)\n",
      "Epoch 014 | Train 0.059458 (data 0.058720, phys 0.061179) | Val 0.099320 (data 0.098073, phys 0.102231)\n",
      "Epoch 015 | Train 0.060575 (data 0.060590, phys 0.060539) | Val 0.099256 (data 0.098010, phys 0.102164)\n",
      "Epoch 016 | Train 0.060019 (data 0.059543, phys 0.061128) | Val 0.099264 (data 0.098017, phys 0.102175)\n",
      "Epoch 017 | Train 0.060594 (data 0.060735, phys 0.060265) | Val 0.099237 (data 0.097993, phys 0.102140)\n",
      "Epoch 018 | Train 0.058629 (data 0.057541, phys 0.061167) | Val 0.099446 (data 0.098195, phys 0.102367)\n",
      "Epoch 019 | Train 0.059991 (data 0.059215, phys 0.061803) | Val 0.099232 (data 0.097989, phys 0.102135)\n",
      "Epoch 020 | Train 0.060184 (data 0.059715, phys 0.061277) | Val 0.099237 (data 0.097997, phys 0.102131)\n",
      "Epoch 021 | Train 0.060393 (data 0.059908, phys 0.061525) | Val 0.099262 (data 0.098018, phys 0.102163)\n",
      "Epoch 022 | Train 0.059527 (data 0.059329, phys 0.059988) | Val 0.099375 (data 0.098125, phys 0.102294)\n",
      "Epoch 023 | Train 0.058969 (data 0.058540, phys 0.059971) | Val 0.099315 (data 0.098069, phys 0.102222)\n",
      "Epoch 024 | Train 0.060205 (data 0.060143, phys 0.060352) | Val 0.099577 (data 0.098323, phys 0.102505)\n",
      "Epoch 025 | Train 0.059259 (data 0.058455, phys 0.061136) | Val 0.099329 (data 0.098082, phys 0.102238)\n",
      "Epoch 026 | Train 0.058905 (data 0.058623, phys 0.059564) | Val 0.099390 (data 0.098142, phys 0.102304)\n",
      "Epoch 027 | Train 0.059407 (data 0.058754, phys 0.060928) | Val 0.099496 (data 0.098244, phys 0.102418)\n",
      "Epoch 028 | Train 0.059109 (data 0.058639, phys 0.060205) | Val 0.099408 (data 0.098159, phys 0.102325)\n",
      "Epoch 029 | Train 0.059174 (data 0.058299, phys 0.061215) | Val 0.099403 (data 0.098154, phys 0.102317)\n",
      "Epoch 030 | Train 0.058756 (data 0.057935, phys 0.060671) | Val 0.099342 (data 0.098096, phys 0.102249)\n",
      "Epoch 031 | Train 0.058695 (data 0.057863, phys 0.060636) | Val 0.099384 (data 0.098136, phys 0.102296)\n",
      "Epoch 032 | Train 0.058728 (data 0.057760, phys 0.060987) | Val 0.099504 (data 0.098253, phys 0.102422)\n",
      "Epoch 033 | Train 0.058926 (data 0.058505, phys 0.059908) | Val 0.099575 (data 0.098322, phys 0.102498)\n",
      "Epoch 034 | Train 0.058989 (data 0.057977, phys 0.061351) | Val 0.099463 (data 0.098214, phys 0.102377)\n",
      "Epoch 035 | Train 0.058971 (data 0.058383, phys 0.060345) | Val 0.099500 (data 0.098249, phys 0.102417)\n",
      "Epoch 036 | Train 0.058623 (data 0.058079, phys 0.059893) | Val 0.099614 (data 0.098361, phys 0.102539)\n",
      "Epoch 037 | Train 0.060673 (data 0.060326, phys 0.061483) | Val 0.099529 (data 0.098278, phys 0.102450)\n",
      "Epoch 038 | Train 0.059635 (data 0.059104, phys 0.060873) | Val 0.099465 (data 0.098216, phys 0.102379)\n",
      "Epoch 039 | Train 0.058274 (data 0.057264, phys 0.060630) | Val 0.099484 (data 0.098232, phys 0.102406)\n",
      "Early stopping at epoch 39 (best val = 0.099232)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 14, λ_data = 0.7, λ_phys = 0.3\n",
      "MAE:  16.4376\n",
      "RMSE: 23.9728\n",
      "NMSE: 0.8926\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 14, lambda_data = 1.0, lambda_phys = 0.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.151744 (data 0.151744, phys 0.153740) | Val 0.112095 (data 0.112095, phys 0.116197)\n",
      "Epoch 002 | Train 0.075350 (data 0.075350, phys 0.079784) | Val 0.112079 (data 0.112079, phys 0.116328)\n",
      "Epoch 003 | Train 0.072326 (data 0.072326, phys 0.074182) | Val 0.112743 (data 0.112743, phys 0.117045)\n",
      "Epoch 004 | Train 0.071209 (data 0.071209, phys 0.074318) | Val 0.112026 (data 0.112026, phys 0.116317)\n",
      "Epoch 005 | Train 0.069642 (data 0.069642, phys 0.072313) | Val 0.111333 (data 0.111333, phys 0.115630)\n",
      "Epoch 006 | Train 0.068951 (data 0.068951, phys 0.072168) | Val 0.109776 (data 0.109776, phys 0.114066)\n",
      "Epoch 007 | Train 0.066433 (data 0.066433, phys 0.071119) | Val 0.107688 (data 0.107688, phys 0.111990)\n",
      "Epoch 008 | Train 0.064522 (data 0.064522, phys 0.066717) | Val 0.103983 (data 0.103983, phys 0.108246)\n",
      "Epoch 009 | Train 0.062130 (data 0.062130, phys 0.064940) | Val 0.100706 (data 0.100706, phys 0.104927)\n",
      "Epoch 010 | Train 0.060761 (data 0.060761, phys 0.063346) | Val 0.099159 (data 0.099159, phys 0.103361)\n",
      "Epoch 011 | Train 0.060255 (data 0.060255, phys 0.062883) | Val 0.098216 (data 0.098216, phys 0.102374)\n",
      "Epoch 012 | Train 0.059206 (data 0.059206, phys 0.060955) | Val 0.098066 (data 0.098066, phys 0.102228)\n",
      "Epoch 013 | Train 0.060496 (data 0.060496, phys 0.062219) | Val 0.097932 (data 0.097932, phys 0.102079)\n",
      "Epoch 014 | Train 0.058697 (data 0.058697, phys 0.061086) | Val 0.098046 (data 0.098046, phys 0.102207)\n",
      "Epoch 015 | Train 0.060639 (data 0.060639, phys 0.060632) | Val 0.097905 (data 0.097905, phys 0.102054)\n",
      "Epoch 016 | Train 0.059577 (data 0.059577, phys 0.061156) | Val 0.097897 (data 0.097897, phys 0.102051)\n",
      "Epoch 017 | Train 0.060744 (data 0.060744, phys 0.060110) | Val 0.097950 (data 0.097950, phys 0.102102)\n",
      "Epoch 018 | Train 0.057543 (data 0.057543, phys 0.061211) | Val 0.098150 (data 0.098150, phys 0.102326)\n",
      "Epoch 019 | Train 0.059111 (data 0.059111, phys 0.061696) | Val 0.097928 (data 0.097928, phys 0.102081)\n",
      "Epoch 020 | Train 0.059710 (data 0.059710, phys 0.061225) | Val 0.097994 (data 0.097994, phys 0.102131)\n",
      "Epoch 021 | Train 0.059884 (data 0.059884, phys 0.061740) | Val 0.098027 (data 0.098027, phys 0.102184)\n",
      "Epoch 022 | Train 0.059400 (data 0.059400, phys 0.059804) | Val 0.098029 (data 0.098029, phys 0.102197)\n",
      "Epoch 023 | Train 0.058375 (data 0.058375, phys 0.059847) | Val 0.097956 (data 0.097956, phys 0.102108)\n",
      "Epoch 024 | Train 0.060058 (data 0.060058, phys 0.060459) | Val 0.098321 (data 0.098321, phys 0.102510)\n",
      "Epoch 025 | Train 0.058600 (data 0.058600, phys 0.061068) | Val 0.098024 (data 0.098024, phys 0.102186)\n",
      "Epoch 026 | Train 0.058643 (data 0.058643, phys 0.059783) | Val 0.098025 (data 0.098025, phys 0.102186)\n",
      "Epoch 027 | Train 0.058878 (data 0.058878, phys 0.060938) | Val 0.098234 (data 0.098234, phys 0.102415)\n",
      "Epoch 028 | Train 0.058673 (data 0.058673, phys 0.060352) | Val 0.098114 (data 0.098114, phys 0.102287)\n",
      "Epoch 029 | Train 0.058336 (data 0.058336, phys 0.061105) | Val 0.098133 (data 0.098133, phys 0.102305)\n",
      "Epoch 030 | Train 0.057900 (data 0.057900, phys 0.060642) | Val 0.098042 (data 0.098042, phys 0.102200)\n",
      "Epoch 031 | Train 0.057944 (data 0.057944, phys 0.060789) | Val 0.098009 (data 0.098009, phys 0.102166)\n",
      "Epoch 032 | Train 0.057907 (data 0.057907, phys 0.061147) | Val 0.098305 (data 0.098305, phys 0.102488)\n",
      "Epoch 033 | Train 0.058672 (data 0.058672, phys 0.059950) | Val 0.098180 (data 0.098180, phys 0.102357)\n",
      "Epoch 034 | Train 0.058070 (data 0.058070, phys 0.061248) | Val 0.098192 (data 0.098192, phys 0.102367)\n",
      "Epoch 035 | Train 0.058365 (data 0.058365, phys 0.060219) | Val 0.098254 (data 0.098254, phys 0.102437)\n",
      "Epoch 036 | Train 0.057980 (data 0.057980, phys 0.059812) | Val 0.098363 (data 0.098363, phys 0.102552)\n",
      "Early stopping at epoch 36 (best val = 0.097897)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 14, λ_data = 1.0, λ_phys = 0.0\n",
      "MAE:  16.3613\n",
      "RMSE: 23.9691\n",
      "NMSE: 0.8924\n",
      "\n",
      "============================================================\n",
      "Preparing and training LSTM+Physics for LAG = 30\n",
      "============================================================\n",
      "\n",
      "--- Supervised Data (Head) ---\n",
      "            Daily_Mean_Ozone  Daily_AQI_Value  AQI_Targeted_Value_LAG_30  \\\n",
      "DATE                                                                       \n",
      "2022-01-01          0.025000        23.000000                  31.333333   \n",
      "2022-01-02          0.032333        30.333333                  33.000000   \n",
      "2022-01-03          0.029667        27.666667                  27.666667   \n",
      "2022-01-04          0.036000        33.333333                  28.666667   \n",
      "2022-01-05          0.033000        30.666667                  34.000000   \n",
      "\n",
      "            OZONE_Targeted_Value_LAG_30  \n",
      "DATE                                     \n",
      "2022-01-01                     0.034000  \n",
      "2022-01-02                     0.035667  \n",
      "2022-01-03                     0.029667  \n",
      "2022-01-04                     0.031000  \n",
      "2022-01-05                     0.037000  \n",
      "Shape: (1061, 4)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- First 10 Samples: True vs Physics AQI (Target Day) ---\n",
      "Sample 01: True=31.333, Physics=31.481, Diff=0.148\n",
      "Sample 02: True=33.000, Physics=33.025, Diff=0.025\n",
      "Sample 03: True=27.667, Physics=27.469, Diff=0.198\n",
      "Sample 04: True=28.667, Physics=28.704, Diff=0.037\n",
      "Sample 05: True=34.000, Physics=34.259, Diff=0.259\n",
      "Sample 06: True=34.000, Physics=33.951, Diff=0.049\n",
      "Sample 07: True=36.333, Physics=36.420, Diff=0.086\n",
      "Sample 08: True=30.333, Physics=30.247, Diff=0.086\n",
      "Sample 09: True=34.333, Physics=34.259, Diff=0.074\n",
      "Sample 10: True=32.333, Physics=32.407, Diff=0.074\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 30, lambda_data = 0.0, lambda_phys = 1.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149611 (data 0.149111, phys 0.149611) | Val 0.116790 (data 0.112668, phys 0.116790)\n",
      "Epoch 002 | Train 0.076543 (data 0.073408, phys 0.076543) | Val 0.116741 (data 0.112513, phys 0.116741)\n",
      "Epoch 003 | Train 0.074329 (data 0.072844, phys 0.074329) | Val 0.117724 (data 0.113419, phys 0.117724)\n",
      "Epoch 004 | Train 0.074811 (data 0.070427, phys 0.074811) | Val 0.117067 (data 0.112798, phys 0.117067)\n",
      "Epoch 005 | Train 0.074097 (data 0.071628, phys 0.074097) | Val 0.117082 (data 0.112806, phys 0.117082)\n",
      "Epoch 006 | Train 0.074517 (data 0.069459, phys 0.074517) | Val 0.116940 (data 0.112667, phys 0.116940)\n",
      "Epoch 007 | Train 0.072607 (data 0.070598, phys 0.072607) | Val 0.117170 (data 0.112873, phys 0.117170)\n",
      "Epoch 008 | Train 0.073540 (data 0.070852, phys 0.073540) | Val 0.116638 (data 0.112359, phys 0.116638)\n",
      "Epoch 009 | Train 0.072944 (data 0.069077, phys 0.072944) | Val 0.115930 (data 0.111679, phys 0.115930)\n",
      "Epoch 010 | Train 0.072249 (data 0.070640, phys 0.072249) | Val 0.115713 (data 0.111451, phys 0.115713)\n",
      "Epoch 011 | Train 0.071207 (data 0.067846, phys 0.071207) | Val 0.114979 (data 0.110752, phys 0.114979)\n",
      "Epoch 012 | Train 0.071256 (data 0.067666, phys 0.071256) | Val 0.114442 (data 0.110252, phys 0.114442)\n",
      "Epoch 013 | Train 0.068619 (data 0.065552, phys 0.068619) | Val 0.114540 (data 0.110339, phys 0.114540)\n",
      "Epoch 014 | Train 0.067428 (data 0.065930, phys 0.067428) | Val 0.114263 (data 0.110098, phys 0.114263)\n",
      "Epoch 015 | Train 0.069044 (data 0.065535, phys 0.069044) | Val 0.114301 (data 0.110140, phys 0.114301)\n",
      "Epoch 016 | Train 0.069619 (data 0.065369, phys 0.069619) | Val 0.114111 (data 0.109976, phys 0.114111)\n",
      "Epoch 017 | Train 0.067822 (data 0.064947, phys 0.067822) | Val 0.114228 (data 0.110078, phys 0.114228)\n",
      "Epoch 018 | Train 0.069473 (data 0.066059, phys 0.069473) | Val 0.114034 (data 0.109897, phys 0.114034)\n",
      "Epoch 019 | Train 0.068164 (data 0.066146, phys 0.068164) | Val 0.114201 (data 0.110049, phys 0.114201)\n",
      "Epoch 020 | Train 0.068174 (data 0.067298, phys 0.068174) | Val 0.114037 (data 0.109901, phys 0.114037)\n",
      "Epoch 021 | Train 0.066957 (data 0.065157, phys 0.066957) | Val 0.114085 (data 0.109940, phys 0.114085)\n",
      "Epoch 022 | Train 0.068171 (data 0.064677, phys 0.068171) | Val 0.113913 (data 0.109785, phys 0.113913)\n",
      "Epoch 023 | Train 0.068066 (data 0.064378, phys 0.068066) | Val 0.114019 (data 0.109871, phys 0.114019)\n",
      "Epoch 024 | Train 0.067643 (data 0.065087, phys 0.067643) | Val 0.113950 (data 0.109805, phys 0.113950)\n",
      "Epoch 025 | Train 0.066405 (data 0.065016, phys 0.066405) | Val 0.113950 (data 0.109804, phys 0.113950)\n",
      "Epoch 026 | Train 0.068235 (data 0.065314, phys 0.068235) | Val 0.113970 (data 0.109821, phys 0.113970)\n",
      "Epoch 027 | Train 0.067474 (data 0.065006, phys 0.067474) | Val 0.113877 (data 0.109742, phys 0.113877)\n",
      "Epoch 028 | Train 0.067705 (data 0.065168, phys 0.067705) | Val 0.113847 (data 0.109712, phys 0.113847)\n",
      "Epoch 029 | Train 0.068076 (data 0.065446, phys 0.068076) | Val 0.113695 (data 0.109580, phys 0.113695)\n",
      "Epoch 030 | Train 0.068203 (data 0.064659, phys 0.068203) | Val 0.113734 (data 0.109602, phys 0.113734)\n",
      "Epoch 031 | Train 0.066616 (data 0.064648, phys 0.066616) | Val 0.113970 (data 0.109811, phys 0.113970)\n",
      "Epoch 032 | Train 0.067225 (data 0.065962, phys 0.067225) | Val 0.113669 (data 0.109538, phys 0.113669)\n",
      "Epoch 033 | Train 0.066882 (data 0.065533, phys 0.066882) | Val 0.113740 (data 0.109599, phys 0.113740)\n",
      "Epoch 034 | Train 0.066541 (data 0.064564, phys 0.066541) | Val 0.113696 (data 0.109560, phys 0.113696)\n",
      "Epoch 035 | Train 0.067137 (data 0.063105, phys 0.067137) | Val 0.113709 (data 0.109570, phys 0.113709)\n",
      "Epoch 036 | Train 0.068346 (data 0.063053, phys 0.068346) | Val 0.113640 (data 0.109499, phys 0.113640)\n",
      "Epoch 037 | Train 0.066736 (data 0.064227, phys 0.066736) | Val 0.113795 (data 0.109640, phys 0.113795)\n",
      "Epoch 038 | Train 0.067746 (data 0.063435, phys 0.067746) | Val 0.113577 (data 0.109446, phys 0.113577)\n",
      "Epoch 039 | Train 0.066940 (data 0.064039, phys 0.066940) | Val 0.113688 (data 0.109547, phys 0.113688)\n",
      "Epoch 040 | Train 0.066095 (data 0.064617, phys 0.066095) | Val 0.113618 (data 0.109486, phys 0.113618)\n",
      "Epoch 041 | Train 0.066536 (data 0.064385, phys 0.066536) | Val 0.113611 (data 0.109480, phys 0.113611)\n",
      "Epoch 042 | Train 0.066893 (data 0.064057, phys 0.066893) | Val 0.113775 (data 0.109627, phys 0.113775)\n",
      "Epoch 043 | Train 0.067195 (data 0.064067, phys 0.067195) | Val 0.113633 (data 0.109497, phys 0.113633)\n",
      "Epoch 044 | Train 0.066942 (data 0.064710, phys 0.066942) | Val 0.113569 (data 0.109440, phys 0.113569)\n",
      "Epoch 045 | Train 0.067645 (data 0.064084, phys 0.067645) | Val 0.113579 (data 0.109443, phys 0.113579)\n",
      "Epoch 046 | Train 0.067283 (data 0.063513, phys 0.067283) | Val 0.113498 (data 0.109368, phys 0.113498)\n",
      "Epoch 047 | Train 0.066881 (data 0.065194, phys 0.066881) | Val 0.113582 (data 0.109444, phys 0.113582)\n",
      "Epoch 048 | Train 0.067009 (data 0.063822, phys 0.067009) | Val 0.113515 (data 0.109385, phys 0.113515)\n",
      "Epoch 049 | Train 0.067493 (data 0.064723, phys 0.067493) | Val 0.113551 (data 0.109414, phys 0.113551)\n",
      "Epoch 050 | Train 0.069427 (data 0.063749, phys 0.069427) | Val 0.113421 (data 0.109297, phys 0.113421)\n",
      "Epoch 051 | Train 0.066429 (data 0.063795, phys 0.066429) | Val 0.113676 (data 0.109526, phys 0.113676)\n",
      "Epoch 052 | Train 0.066583 (data 0.062790, phys 0.066583) | Val 0.113484 (data 0.109354, phys 0.113484)\n",
      "Epoch 053 | Train 0.067871 (data 0.064095, phys 0.067871) | Val 0.113522 (data 0.109387, phys 0.113522)\n",
      "Epoch 054 | Train 0.066193 (data 0.063818, phys 0.066193) | Val 0.113675 (data 0.109522, phys 0.113675)\n",
      "Epoch 055 | Train 0.066674 (data 0.063705, phys 0.066674) | Val 0.113532 (data 0.109391, phys 0.113532)\n",
      "Epoch 056 | Train 0.066309 (data 0.063543, phys 0.066309) | Val 0.113438 (data 0.109306, phys 0.113438)\n",
      "Epoch 057 | Train 0.066831 (data 0.063318, phys 0.066831) | Val 0.113543 (data 0.109403, phys 0.113543)\n",
      "Epoch 058 | Train 0.065451 (data 0.064195, phys 0.065451) | Val 0.113550 (data 0.109405, phys 0.113550)\n",
      "Epoch 059 | Train 0.066278 (data 0.062192, phys 0.066278) | Val 0.113430 (data 0.109298, phys 0.113430)\n",
      "Epoch 060 | Train 0.066078 (data 0.063621, phys 0.066078) | Val 0.113574 (data 0.109427, phys 0.113574)\n",
      "Epoch 061 | Train 0.066221 (data 0.063320, phys 0.066221) | Val 0.113508 (data 0.109364, phys 0.113508)\n",
      "Epoch 062 | Train 0.065318 (data 0.065197, phys 0.065318) | Val 0.113393 (data 0.109264, phys 0.113393)\n",
      "Epoch 063 | Train 0.067175 (data 0.062812, phys 0.067175) | Val 0.113545 (data 0.109401, phys 0.113545)\n",
      "Epoch 064 | Train 0.067033 (data 0.063510, phys 0.067033) | Val 0.113377 (data 0.109247, phys 0.113377)\n",
      "Epoch 065 | Train 0.065424 (data 0.063397, phys 0.065424) | Val 0.113653 (data 0.109501, phys 0.113653)\n",
      "Epoch 066 | Train 0.065470 (data 0.063112, phys 0.065470) | Val 0.113776 (data 0.109618, phys 0.113776)\n",
      "Epoch 067 | Train 0.066337 (data 0.063899, phys 0.066337) | Val 0.113419 (data 0.109290, phys 0.113419)\n",
      "Epoch 068 | Train 0.066835 (data 0.063851, phys 0.066835) | Val 0.113430 (data 0.109298, phys 0.113430)\n",
      "Epoch 069 | Train 0.065472 (data 0.064031, phys 0.065472) | Val 0.113568 (data 0.109426, phys 0.113568)\n",
      "Epoch 070 | Train 0.066136 (data 0.064078, phys 0.066136) | Val 0.113387 (data 0.109264, phys 0.113387)\n",
      "Epoch 071 | Train 0.066647 (data 0.063435, phys 0.066647) | Val 0.113566 (data 0.109422, phys 0.113566)\n",
      "Epoch 072 | Train 0.064795 (data 0.063255, phys 0.064795) | Val 0.113502 (data 0.109363, phys 0.113502)\n",
      "Epoch 073 | Train 0.065341 (data 0.062681, phys 0.065341) | Val 0.113532 (data 0.109386, phys 0.113532)\n",
      "Epoch 074 | Train 0.066356 (data 0.062725, phys 0.066356) | Val 0.113448 (data 0.109311, phys 0.113448)\n",
      "Epoch 075 | Train 0.066150 (data 0.064251, phys 0.066150) | Val 0.113524 (data 0.109382, phys 0.113524)\n",
      "Epoch 076 | Train 0.065410 (data 0.063038, phys 0.065410) | Val 0.113467 (data 0.109331, phys 0.113467)\n",
      "Epoch 077 | Train 0.066902 (data 0.063254, phys 0.066902) | Val 0.113516 (data 0.109373, phys 0.113516)\n",
      "Epoch 078 | Train 0.066837 (data 0.063138, phys 0.066837) | Val 0.113372 (data 0.109245, phys 0.113372)\n",
      "Epoch 079 | Train 0.065211 (data 0.062157, phys 0.065211) | Val 0.113467 (data 0.109331, phys 0.113467)\n",
      "Epoch 080 | Train 0.065656 (data 0.062903, phys 0.065656) | Val 0.113542 (data 0.109400, phys 0.113542)\n",
      "Epoch 081 | Train 0.065578 (data 0.063524, phys 0.065578) | Val 0.113408 (data 0.109269, phys 0.113408)\n",
      "Epoch 082 | Train 0.065818 (data 0.063396, phys 0.065818) | Val 0.113432 (data 0.109286, phys 0.113432)\n",
      "Epoch 083 | Train 0.066125 (data 0.062345, phys 0.066125) | Val 0.113182 (data 0.109061, phys 0.113182)\n",
      "Epoch 084 | Train 0.065944 (data 0.062444, phys 0.065944) | Val 0.113430 (data 0.109290, phys 0.113430)\n",
      "Epoch 085 | Train 0.065866 (data 0.062168, phys 0.065866) | Val 0.113270 (data 0.109142, phys 0.113270)\n",
      "Epoch 086 | Train 0.064643 (data 0.063421, phys 0.064643) | Val 0.113470 (data 0.109327, phys 0.113470)\n",
      "Epoch 087 | Train 0.066132 (data 0.061857, phys 0.066132) | Val 0.113265 (data 0.109133, phys 0.113265)\n",
      "Epoch 088 | Train 0.066245 (data 0.063022, phys 0.066245) | Val 0.113178 (data 0.109055, phys 0.113178)\n",
      "Epoch 089 | Train 0.064481 (data 0.062393, phys 0.064481) | Val 0.113473 (data 0.109325, phys 0.113473)\n",
      "Epoch 090 | Train 0.064561 (data 0.063260, phys 0.064561) | Val 0.113334 (data 0.109195, phys 0.113334)\n",
      "Epoch 091 | Train 0.065604 (data 0.062920, phys 0.065604) | Val 0.113401 (data 0.109258, phys 0.113401)\n",
      "Epoch 092 | Train 0.065302 (data 0.062625, phys 0.065302) | Val 0.113423 (data 0.109284, phys 0.113423)\n",
      "Epoch 093 | Train 0.065288 (data 0.062452, phys 0.065288) | Val 0.113373 (data 0.109239, phys 0.113373)\n",
      "Epoch 094 | Train 0.064924 (data 0.062157, phys 0.064924) | Val 0.113335 (data 0.109203, phys 0.113335)\n",
      "Epoch 095 | Train 0.064784 (data 0.062933, phys 0.064784) | Val 0.113459 (data 0.109319, phys 0.113459)\n",
      "Epoch 096 | Train 0.065628 (data 0.064045, phys 0.065628) | Val 0.113239 (data 0.109113, phys 0.113239)\n",
      "Epoch 097 | Train 0.064635 (data 0.061466, phys 0.064635) | Val 0.113349 (data 0.109210, phys 0.113349)\n",
      "Epoch 098 | Train 0.065803 (data 0.062314, phys 0.065803) | Val 0.113194 (data 0.109067, phys 0.113194)\n",
      "Epoch 099 | Train 0.065207 (data 0.062681, phys 0.065207) | Val 0.113325 (data 0.109184, phys 0.113325)\n",
      "Epoch 100 | Train 0.065123 (data 0.063203, phys 0.065123) | Val 0.113384 (data 0.109240, phys 0.113384)\n",
      "Epoch 101 | Train 0.065784 (data 0.063127, phys 0.065784) | Val 0.113333 (data 0.109191, phys 0.113333)\n",
      "Epoch 102 | Train 0.065904 (data 0.062906, phys 0.065904) | Val 0.113145 (data 0.109017, phys 0.113145)\n",
      "Epoch 103 | Train 0.065070 (data 0.062777, phys 0.065070) | Val 0.113422 (data 0.109275, phys 0.113422)\n",
      "Epoch 104 | Train 0.065164 (data 0.062876, phys 0.065164) | Val 0.113276 (data 0.109142, phys 0.113276)\n",
      "Epoch 105 | Train 0.065811 (data 0.062263, phys 0.065811) | Val 0.113381 (data 0.109238, phys 0.113381)\n",
      "Epoch 106 | Train 0.064601 (data 0.062191, phys 0.064601) | Val 0.113317 (data 0.109176, phys 0.113317)\n",
      "Epoch 107 | Train 0.064696 (data 0.062495, phys 0.064696) | Val 0.113312 (data 0.109172, phys 0.113312)\n",
      "Epoch 108 | Train 0.064726 (data 0.062814, phys 0.064726) | Val 0.113344 (data 0.109201, phys 0.113344)\n",
      "Epoch 109 | Train 0.064986 (data 0.063899, phys 0.064986) | Val 0.113469 (data 0.109317, phys 0.113469)\n",
      "Epoch 110 | Train 0.065684 (data 0.063082, phys 0.065684) | Val 0.113296 (data 0.109154, phys 0.113296)\n",
      "Epoch 111 | Train 0.064524 (data 0.061794, phys 0.064524) | Val 0.113449 (data 0.109296, phys 0.113449)\n",
      "Epoch 112 | Train 0.065204 (data 0.062922, phys 0.065204) | Val 0.113385 (data 0.109238, phys 0.113385)\n",
      "Epoch 113 | Train 0.065538 (data 0.062692, phys 0.065538) | Val 0.113355 (data 0.109209, phys 0.113355)\n",
      "Epoch 114 | Train 0.065293 (data 0.061687, phys 0.065293) | Val 0.113155 (data 0.109020, phys 0.113155)\n",
      "Epoch 115 | Train 0.065347 (data 0.062381, phys 0.065347) | Val 0.113196 (data 0.109057, phys 0.113196)\n",
      "Epoch 116 | Train 0.065516 (data 0.063620, phys 0.065516) | Val 0.113263 (data 0.109121, phys 0.113263)\n",
      "Epoch 117 | Train 0.065307 (data 0.062336, phys 0.065307) | Val 0.113418 (data 0.109265, phys 0.113418)\n",
      "Epoch 118 | Train 0.065290 (data 0.062647, phys 0.065290) | Val 0.113213 (data 0.109074, phys 0.113213)\n",
      "Epoch 119 | Train 0.065048 (data 0.062645, phys 0.065048) | Val 0.113330 (data 0.109184, phys 0.113330)\n",
      "Epoch 120 | Train 0.064685 (data 0.062208, phys 0.064685) | Val 0.113512 (data 0.109354, phys 0.113512)\n",
      "Epoch 121 | Train 0.064771 (data 0.061331, phys 0.064771) | Val 0.113353 (data 0.109203, phys 0.113353)\n",
      "Epoch 122 | Train 0.065332 (data 0.062216, phys 0.065332) | Val 0.113250 (data 0.109107, phys 0.113250)\n",
      "Early stopping at epoch 122 (best val = 0.113145)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 30, λ_data = 0.0, λ_phys = 1.0\n",
      "MAE:  17.7256\n",
      "RMSE: 25.3531\n",
      "NMSE: 0.9856\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 30, lambda_data = 0.3, lambda_phys = 0.7\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149712 (data 0.149337, phys 0.149873) | Val 0.115660 (data 0.112782, phys 0.116893)\n",
      "Epoch 002 | Train 0.075645 (data 0.073600, phys 0.076522) | Val 0.115494 (data 0.112532, phys 0.116764)\n",
      "Epoch 003 | Train 0.073774 (data 0.072702, phys 0.074233) | Val 0.116424 (data 0.113411, phys 0.117716)\n",
      "Epoch 004 | Train 0.073449 (data 0.070343, phys 0.074780) | Val 0.115818 (data 0.112827, phys 0.117099)\n",
      "Epoch 005 | Train 0.073197 (data 0.071473, phys 0.073936) | Val 0.115798 (data 0.112805, phys 0.117081)\n",
      "Epoch 006 | Train 0.072899 (data 0.069365, phys 0.074413) | Val 0.115817 (data 0.112817, phys 0.117103)\n",
      "Epoch 007 | Train 0.071914 (data 0.070463, phys 0.072536) | Val 0.115800 (data 0.112793, phys 0.117088)\n",
      "Epoch 008 | Train 0.072583 (data 0.070819, phys 0.073339) | Val 0.115206 (data 0.112215, phys 0.116488)\n",
      "Epoch 009 | Train 0.071559 (data 0.068867, phys 0.072712) | Val 0.114576 (data 0.111599, phys 0.115851)\n",
      "Epoch 010 | Train 0.071588 (data 0.070419, phys 0.072090) | Val 0.114237 (data 0.111259, phys 0.115514)\n",
      "Epoch 011 | Train 0.070012 (data 0.067647, phys 0.071026) | Val 0.113594 (data 0.110638, phys 0.114861)\n",
      "Epoch 012 | Train 0.069937 (data 0.067419, phys 0.071016) | Val 0.113178 (data 0.110243, phys 0.114436)\n",
      "Epoch 013 | Train 0.067521 (data 0.065286, phys 0.068479) | Val 0.113253 (data 0.110315, phys 0.114513)\n",
      "Epoch 014 | Train 0.066843 (data 0.065877, phys 0.067257) | Val 0.112993 (data 0.110079, phys 0.114243)\n",
      "Epoch 015 | Train 0.067961 (data 0.065466, phys 0.069031) | Val 0.113046 (data 0.110132, phys 0.114295)\n",
      "Epoch 016 | Train 0.068452 (data 0.065562, phys 0.069691) | Val 0.112857 (data 0.109961, phys 0.114098)\n",
      "Epoch 017 | Train 0.066989 (data 0.064996, phys 0.067844) | Val 0.112984 (data 0.110077, phys 0.114230)\n",
      "Epoch 018 | Train 0.068361 (data 0.065986, phys 0.069379) | Val 0.112823 (data 0.109927, phys 0.114064)\n",
      "Epoch 019 | Train 0.067489 (data 0.066260, phys 0.068016) | Val 0.112987 (data 0.110080, phys 0.114233)\n",
      "Epoch 020 | Train 0.067920 (data 0.067383, phys 0.068151) | Val 0.112785 (data 0.109895, phys 0.114023)\n",
      "Epoch 021 | Train 0.066354 (data 0.064980, phys 0.066942) | Val 0.112871 (data 0.109971, phys 0.114114)\n",
      "Epoch 022 | Train 0.067025 (data 0.064698, phys 0.068023) | Val 0.112720 (data 0.109830, phys 0.113959)\n",
      "Epoch 023 | Train 0.066833 (data 0.064259, phys 0.067935) | Val 0.112787 (data 0.109886, phys 0.114030)\n",
      "Epoch 024 | Train 0.066933 (data 0.065145, phys 0.067699) | Val 0.112788 (data 0.109884, phys 0.114032)\n",
      "Epoch 025 | Train 0.065932 (data 0.065003, phys 0.066329) | Val 0.112776 (data 0.109874, phys 0.114019)\n",
      "Epoch 026 | Train 0.067326 (data 0.065289, phys 0.068199) | Val 0.112856 (data 0.109949, phys 0.114102)\n",
      "Epoch 027 | Train 0.066778 (data 0.065020, phys 0.067532) | Val 0.112689 (data 0.109796, phys 0.113929)\n",
      "Epoch 028 | Train 0.066888 (data 0.065280, phys 0.067577) | Val 0.112729 (data 0.109830, phys 0.113972)\n",
      "Epoch 029 | Train 0.067212 (data 0.065366, phys 0.068003) | Val 0.112508 (data 0.109626, phys 0.113743)\n",
      "Epoch 030 | Train 0.067100 (data 0.064755, phys 0.068105) | Val 0.112546 (data 0.109655, phys 0.113785)\n",
      "Epoch 031 | Train 0.065998 (data 0.064657, phys 0.066573) | Val 0.112654 (data 0.109750, phys 0.113898)\n",
      "Epoch 032 | Train 0.066774 (data 0.065838, phys 0.067175) | Val 0.112486 (data 0.109593, phys 0.113726)\n",
      "Epoch 033 | Train 0.066409 (data 0.065464, phys 0.066814) | Val 0.112541 (data 0.109642, phys 0.113784)\n",
      "Epoch 034 | Train 0.065964 (data 0.064566, phys 0.066563) | Val 0.112479 (data 0.109583, phys 0.113719)\n",
      "Epoch 035 | Train 0.065888 (data 0.063056, phys 0.067102) | Val 0.112519 (data 0.109618, phys 0.113762)\n",
      "Epoch 036 | Train 0.066799 (data 0.063093, phys 0.068388) | Val 0.112370 (data 0.109472, phys 0.113612)\n",
      "Epoch 037 | Train 0.065966 (data 0.064201, phys 0.066722) | Val 0.112538 (data 0.109630, phys 0.113784)\n",
      "Epoch 038 | Train 0.066531 (data 0.063399, phys 0.067873) | Val 0.112388 (data 0.109492, phys 0.113629)\n",
      "Epoch 039 | Train 0.066045 (data 0.064059, phys 0.066896) | Val 0.112441 (data 0.109541, phys 0.113683)\n",
      "Epoch 040 | Train 0.065554 (data 0.064523, phys 0.065996) | Val 0.112366 (data 0.109472, phys 0.113606)\n",
      "Epoch 041 | Train 0.065871 (data 0.064435, phys 0.066486) | Val 0.112341 (data 0.109449, phys 0.113581)\n",
      "Epoch 042 | Train 0.065928 (data 0.063997, phys 0.066756) | Val 0.112445 (data 0.109543, phys 0.113688)\n",
      "Epoch 043 | Train 0.066200 (data 0.064033, phys 0.067128) | Val 0.112305 (data 0.109413, phys 0.113544)\n",
      "Epoch 044 | Train 0.066227 (data 0.064586, phys 0.066930) | Val 0.112315 (data 0.109424, phys 0.113553)\n",
      "Epoch 045 | Train 0.066533 (data 0.064116, phys 0.067569) | Val 0.112375 (data 0.109478, phys 0.113616)\n",
      "Epoch 046 | Train 0.066071 (data 0.063431, phys 0.067203) | Val 0.112282 (data 0.109391, phys 0.113521)\n",
      "Epoch 047 | Train 0.066392 (data 0.065162, phys 0.066919) | Val 0.112335 (data 0.109439, phys 0.113576)\n",
      "Epoch 048 | Train 0.066088 (data 0.063834, phys 0.067053) | Val 0.112311 (data 0.109416, phys 0.113552)\n",
      "Epoch 049 | Train 0.066673 (data 0.064726, phys 0.067508) | Val 0.112271 (data 0.109377, phys 0.113512)\n",
      "Epoch 050 | Train 0.067670 (data 0.063614, phys 0.069408) | Val 0.112216 (data 0.109324, phys 0.113455)\n",
      "Epoch 051 | Train 0.065618 (data 0.063743, phys 0.066422) | Val 0.112383 (data 0.109482, phys 0.113626)\n",
      "Epoch 052 | Train 0.065414 (data 0.062749, phys 0.066557) | Val 0.112297 (data 0.109402, phys 0.113538)\n",
      "Epoch 053 | Train 0.066645 (data 0.064073, phys 0.067748) | Val 0.112281 (data 0.109386, phys 0.113521)\n",
      "Epoch 054 | Train 0.065406 (data 0.063805, phys 0.066092) | Val 0.112384 (data 0.109482, phys 0.113628)\n",
      "Epoch 055 | Train 0.065734 (data 0.063588, phys 0.066654) | Val 0.112272 (data 0.109375, phys 0.113514)\n",
      "Epoch 056 | Train 0.065563 (data 0.063562, phys 0.066420) | Val 0.112166 (data 0.109276, phys 0.113405)\n",
      "Epoch 057 | Train 0.065800 (data 0.063293, phys 0.066874) | Val 0.112281 (data 0.109383, phys 0.113522)\n",
      "Epoch 058 | Train 0.065043 (data 0.064121, phys 0.065439) | Val 0.112282 (data 0.109384, phys 0.113524)\n",
      "Epoch 059 | Train 0.065056 (data 0.062216, phys 0.066273) | Val 0.112238 (data 0.109344, phys 0.113479)\n",
      "Epoch 060 | Train 0.065355 (data 0.063683, phys 0.066072) | Val 0.112299 (data 0.109399, phys 0.113543)\n",
      "Epoch 061 | Train 0.065301 (data 0.063419, phys 0.066107) | Val 0.112279 (data 0.109378, phys 0.113523)\n",
      "Epoch 062 | Train 0.065301 (data 0.065325, phys 0.065291) | Val 0.112146 (data 0.109255, phys 0.113385)\n",
      "Epoch 063 | Train 0.065803 (data 0.062836, phys 0.067075) | Val 0.112266 (data 0.109367, phys 0.113508)\n",
      "Epoch 064 | Train 0.066026 (data 0.063517, phys 0.067101) | Val 0.112104 (data 0.109215, phys 0.113342)\n",
      "Epoch 065 | Train 0.064757 (data 0.063316, phys 0.065375) | Val 0.112282 (data 0.109382, phys 0.113525)\n",
      "Epoch 066 | Train 0.064824 (data 0.063243, phys 0.065502) | Val 0.112483 (data 0.109574, phys 0.113729)\n",
      "Epoch 067 | Train 0.065603 (data 0.063918, phys 0.066325) | Val 0.112131 (data 0.109242, phys 0.113370)\n",
      "Epoch 068 | Train 0.065946 (data 0.063903, phys 0.066822) | Val 0.112162 (data 0.109270, phys 0.113401)\n",
      "Epoch 069 | Train 0.064995 (data 0.064036, phys 0.065406) | Val 0.112290 (data 0.109392, phys 0.113532)\n",
      "Epoch 070 | Train 0.065483 (data 0.064084, phys 0.066082) | Val 0.112086 (data 0.109201, phys 0.113322)\n",
      "Epoch 071 | Train 0.065648 (data 0.063428, phys 0.066600) | Val 0.112258 (data 0.109359, phys 0.113500)\n",
      "Epoch 072 | Train 0.064364 (data 0.063267, phys 0.064835) | Val 0.112245 (data 0.109346, phys 0.113487)\n",
      "Epoch 073 | Train 0.064476 (data 0.062626, phys 0.065269) | Val 0.112219 (data 0.109320, phys 0.113462)\n",
      "Epoch 074 | Train 0.065288 (data 0.062751, phys 0.066376) | Val 0.112195 (data 0.109299, phys 0.113436)\n",
      "Epoch 075 | Train 0.065600 (data 0.064269, phys 0.066170) | Val 0.112260 (data 0.109362, phys 0.113501)\n",
      "Epoch 076 | Train 0.064661 (data 0.063085, phys 0.065336) | Val 0.112215 (data 0.109321, phys 0.113456)\n",
      "Epoch 077 | Train 0.065755 (data 0.063237, phys 0.066835) | Val 0.112329 (data 0.109426, phys 0.113573)\n",
      "Epoch 078 | Train 0.065693 (data 0.063107, phys 0.066801) | Val 0.112147 (data 0.109257, phys 0.113386)\n",
      "Epoch 079 | Train 0.064248 (data 0.062128, phys 0.065157) | Val 0.112304 (data 0.109405, phys 0.113546)\n",
      "Epoch 080 | Train 0.064766 (data 0.062924, phys 0.065556) | Val 0.112305 (data 0.109407, phys 0.113548)\n",
      "Epoch 081 | Train 0.064867 (data 0.063499, phys 0.065453) | Val 0.112275 (data 0.109377, phys 0.113517)\n",
      "Epoch 082 | Train 0.065130 (data 0.063414, phys 0.065865) | Val 0.112268 (data 0.109369, phys 0.113511)\n",
      "Epoch 083 | Train 0.064408 (data 0.061777, phys 0.065536) | Val 0.112173 (data 0.109281, phys 0.113412)\n",
      "Epoch 084 | Train 0.064767 (data 0.062298, phys 0.065825) | Val 0.112259 (data 0.109361, phys 0.113501)\n",
      "Epoch 085 | Train 0.064670 (data 0.062124, phys 0.065762) | Val 0.112130 (data 0.109236, phys 0.113370)\n",
      "Epoch 086 | Train 0.064230 (data 0.063376, phys 0.064597) | Val 0.112227 (data 0.109328, phys 0.113470)\n",
      "Epoch 087 | Train 0.064764 (data 0.061686, phys 0.066083) | Val 0.112220 (data 0.109321, phys 0.113463)\n",
      "Epoch 088 | Train 0.065239 (data 0.063022, phys 0.066189) | Val 0.112099 (data 0.109207, phys 0.113338)\n",
      "Epoch 089 | Train 0.063903 (data 0.062448, phys 0.064527) | Val 0.112325 (data 0.109420, phys 0.113570)\n",
      "Epoch 090 | Train 0.064173 (data 0.063297, phys 0.064549) | Val 0.112161 (data 0.109264, phys 0.113403)\n",
      "Early stopping at epoch 90 (best val = 0.112086)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 30, λ_data = 0.3, λ_phys = 0.7\n",
      "MAE:  17.8042\n",
      "RMSE: 25.3755\n",
      "NMSE: 0.9874\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 30, lambda_data = 0.5, lambda_phys = 0.5\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149342 (data 0.149097, phys 0.149586) | Val 0.114754 (data 0.112695, phys 0.116813)\n",
      "Epoch 002 | Train 0.075009 (data 0.073535, phys 0.076483) | Val 0.114649 (data 0.112533, phys 0.116765)\n",
      "Epoch 003 | Train 0.073430 (data 0.072667, phys 0.074192) | Val 0.115590 (data 0.113437, phys 0.117743)\n",
      "Epoch 004 | Train 0.072605 (data 0.070351, phys 0.074858) | Val 0.114957 (data 0.112821, phys 0.117093)\n",
      "Epoch 005 | Train 0.072565 (data 0.071345, phys 0.073785) | Val 0.115035 (data 0.112894, phys 0.117177)\n",
      "Epoch 006 | Train 0.071872 (data 0.069334, phys 0.074410) | Val 0.115060 (data 0.112914, phys 0.117206)\n",
      "Epoch 007 | Train 0.071476 (data 0.070439, phys 0.072514) | Val 0.114920 (data 0.112773, phys 0.117067)\n",
      "Epoch 008 | Train 0.072102 (data 0.070835, phys 0.073369) | Val 0.114296 (data 0.112160, phys 0.116431)\n",
      "Epoch 009 | Train 0.070783 (data 0.068915, phys 0.072652) | Val 0.113738 (data 0.111610, phys 0.115865)\n",
      "Epoch 010 | Train 0.071240 (data 0.070428, phys 0.072052) | Val 0.113364 (data 0.111238, phys 0.115491)\n",
      "Epoch 011 | Train 0.069336 (data 0.067658, phys 0.071014) | Val 0.112754 (data 0.110642, phys 0.114866)\n",
      "Epoch 012 | Train 0.069186 (data 0.067393, phys 0.070979) | Val 0.112394 (data 0.110294, phys 0.114494)\n",
      "Epoch 013 | Train 0.066873 (data 0.065241, phys 0.068504) | Val 0.112407 (data 0.110307, phys 0.114507)\n",
      "Epoch 014 | Train 0.066562 (data 0.065864, phys 0.067260) | Val 0.112135 (data 0.110052, phys 0.114217)\n",
      "Epoch 015 | Train 0.067268 (data 0.065488, phys 0.069048) | Val 0.112216 (data 0.110133, phys 0.114300)\n",
      "Epoch 016 | Train 0.067379 (data 0.065334, phys 0.069424) | Val 0.112120 (data 0.110044, phys 0.114196)\n",
      "Epoch 017 | Train 0.066397 (data 0.064974, phys 0.067821) | Val 0.112132 (data 0.110056, phys 0.114209)\n",
      "Epoch 018 | Train 0.067704 (data 0.066020, phys 0.069388) | Val 0.112002 (data 0.109933, phys 0.114071)\n",
      "Epoch 019 | Train 0.067196 (data 0.066310, phys 0.068083) | Val 0.112167 (data 0.110090, phys 0.114245)\n",
      "Epoch 020 | Train 0.067818 (data 0.067408, phys 0.068229) | Val 0.111924 (data 0.109861, phys 0.113986)\n",
      "Epoch 021 | Train 0.065997 (data 0.065003, phys 0.066992) | Val 0.112002 (data 0.109930, phys 0.114074)\n",
      "Epoch 022 | Train 0.066343 (data 0.064679, phys 0.068008) | Val 0.111860 (data 0.109795, phys 0.113925)\n",
      "Epoch 023 | Train 0.066049 (data 0.064217, phys 0.067881) | Val 0.111899 (data 0.109829, phys 0.113970)\n",
      "Epoch 024 | Train 0.066470 (data 0.065196, phys 0.067744) | Val 0.111958 (data 0.109882, phys 0.114034)\n",
      "Epoch 025 | Train 0.065700 (data 0.065013, phys 0.066386) | Val 0.111890 (data 0.109818, phys 0.113962)\n",
      "Epoch 026 | Train 0.066728 (data 0.065244, phys 0.068212) | Val 0.112048 (data 0.109969, phys 0.114127)\n",
      "Epoch 027 | Train 0.066293 (data 0.065008, phys 0.067578) | Val 0.111836 (data 0.109769, phys 0.113904)\n",
      "Epoch 028 | Train 0.066409 (data 0.065230, phys 0.067588) | Val 0.111905 (data 0.109831, phys 0.113978)\n",
      "Epoch 029 | Train 0.066687 (data 0.065307, phys 0.068066) | Val 0.111665 (data 0.109605, phys 0.113725)\n",
      "Epoch 030 | Train 0.066454 (data 0.064816, phys 0.068093) | Val 0.111691 (data 0.109626, phys 0.113757)\n",
      "Epoch 031 | Train 0.065631 (data 0.064699, phys 0.066563) | Val 0.111755 (data 0.109683, phys 0.113827)\n",
      "Epoch 032 | Train 0.066506 (data 0.065819, phys 0.067193) | Val 0.111669 (data 0.109601, phys 0.113737)\n",
      "Epoch 033 | Train 0.066150 (data 0.065502, phys 0.066798) | Val 0.111712 (data 0.109641, phys 0.113783)\n",
      "Epoch 034 | Train 0.065598 (data 0.064571, phys 0.066625) | Val 0.111654 (data 0.109585, phys 0.113723)\n",
      "Epoch 035 | Train 0.065100 (data 0.063091, phys 0.067109) | Val 0.111736 (data 0.109662, phys 0.113810)\n",
      "Epoch 036 | Train 0.065741 (data 0.063110, phys 0.068371) | Val 0.111562 (data 0.109492, phys 0.113633)\n",
      "Epoch 037 | Train 0.065490 (data 0.064229, phys 0.066751) | Val 0.111706 (data 0.109629, phys 0.113782)\n",
      "Epoch 038 | Train 0.065694 (data 0.063415, phys 0.067972) | Val 0.111619 (data 0.109548, phys 0.113691)\n",
      "Epoch 039 | Train 0.065490 (data 0.064035, phys 0.066946) | Val 0.111649 (data 0.109576, phys 0.113722)\n",
      "Epoch 040 | Train 0.065314 (data 0.064544, phys 0.066085) | Val 0.111566 (data 0.109497, phys 0.113635)\n",
      "Epoch 041 | Train 0.065461 (data 0.064475, phys 0.066447) | Val 0.111525 (data 0.109456, phys 0.113593)\n",
      "Epoch 042 | Train 0.065396 (data 0.064017, phys 0.066774) | Val 0.111607 (data 0.109533, phys 0.113680)\n",
      "Epoch 043 | Train 0.065567 (data 0.064000, phys 0.067133) | Val 0.111478 (data 0.109412, phys 0.113543)\n",
      "Epoch 044 | Train 0.065797 (data 0.064603, phys 0.066992) | Val 0.111488 (data 0.109421, phys 0.113555)\n",
      "Epoch 045 | Train 0.065860 (data 0.064148, phys 0.067571) | Val 0.111584 (data 0.109511, phys 0.113656)\n",
      "Epoch 046 | Train 0.065324 (data 0.063449, phys 0.067199) | Val 0.111488 (data 0.109421, phys 0.113555)\n",
      "Epoch 047 | Train 0.066078 (data 0.065219, phys 0.066937) | Val 0.111526 (data 0.109456, phys 0.113595)\n",
      "Epoch 048 | Train 0.065474 (data 0.063836, phys 0.067111) | Val 0.111553 (data 0.109482, phys 0.113625)\n",
      "Epoch 049 | Train 0.066158 (data 0.064735, phys 0.067580) | Val 0.111488 (data 0.109418, phys 0.113557)\n",
      "Epoch 050 | Train 0.066543 (data 0.063655, phys 0.069431) | Val 0.111463 (data 0.109394, phys 0.113533)\n",
      "Epoch 051 | Train 0.065199 (data 0.063868, phys 0.066530) | Val 0.111526 (data 0.109454, phys 0.113599)\n",
      "Epoch 052 | Train 0.064705 (data 0.062754, phys 0.066656) | Val 0.111519 (data 0.109447, phys 0.113590)\n",
      "Epoch 053 | Train 0.065905 (data 0.064090, phys 0.067720) | Val 0.111474 (data 0.109404, phys 0.113544)\n",
      "Epoch 054 | Train 0.065006 (data 0.063871, phys 0.066141) | Val 0.111526 (data 0.109453, phys 0.113599)\n",
      "Epoch 055 | Train 0.065148 (data 0.063659, phys 0.066637) | Val 0.111462 (data 0.109391, phys 0.113532)\n",
      "Epoch 056 | Train 0.065082 (data 0.063641, phys 0.066522) | Val 0.111346 (data 0.109280, phys 0.113412)\n",
      "Epoch 057 | Train 0.065122 (data 0.063437, phys 0.066808) | Val 0.111442 (data 0.109371, phys 0.113514)\n",
      "Epoch 058 | Train 0.064840 (data 0.064163, phys 0.065516) | Val 0.111397 (data 0.109327, phys 0.113467)\n",
      "Epoch 059 | Train 0.064360 (data 0.062279, phys 0.066441) | Val 0.111426 (data 0.109355, phys 0.113496)\n",
      "Epoch 060 | Train 0.064989 (data 0.063840, phys 0.066138) | Val 0.111450 (data 0.109377, phys 0.113523)\n",
      "Epoch 061 | Train 0.064816 (data 0.063483, phys 0.066150) | Val 0.111461 (data 0.109387, phys 0.113535)\n",
      "Epoch 062 | Train 0.065408 (data 0.065420, phys 0.065397) | Val 0.111303 (data 0.109237, phys 0.113369)\n",
      "Epoch 063 | Train 0.065015 (data 0.062928, phys 0.067102) | Val 0.111424 (data 0.109352, phys 0.113496)\n",
      "Epoch 064 | Train 0.065422 (data 0.063624, phys 0.067220) | Val 0.111274 (data 0.109208, phys 0.113339)\n",
      "Epoch 065 | Train 0.064449 (data 0.063362, phys 0.065536) | Val 0.111385 (data 0.109314, phys 0.113457)\n",
      "Epoch 066 | Train 0.064303 (data 0.063177, phys 0.065429) | Val 0.111559 (data 0.109482, phys 0.113635)\n",
      "Epoch 067 | Train 0.065193 (data 0.063978, phys 0.066407) | Val 0.111323 (data 0.109256, phys 0.113389)\n",
      "Epoch 068 | Train 0.065401 (data 0.063937, phys 0.066865) | Val 0.111342 (data 0.109275, phys 0.113410)\n",
      "Epoch 069 | Train 0.064768 (data 0.064049, phys 0.065487) | Val 0.111470 (data 0.109397, phys 0.113543)\n",
      "Epoch 070 | Train 0.065144 (data 0.064156, phys 0.066131) | Val 0.111292 (data 0.109228, phys 0.113357)\n",
      "Epoch 071 | Train 0.065086 (data 0.063531, phys 0.066640) | Val 0.111440 (data 0.109367, phys 0.113512)\n",
      "Epoch 072 | Train 0.064080 (data 0.063321, phys 0.064840) | Val 0.111465 (data 0.109391, phys 0.113540)\n",
      "Epoch 073 | Train 0.063960 (data 0.062674, phys 0.065245) | Val 0.111372 (data 0.109300, phys 0.113443)\n",
      "Epoch 074 | Train 0.064624 (data 0.062796, phys 0.066451) | Val 0.111373 (data 0.109302, phys 0.113444)\n",
      "Epoch 075 | Train 0.065268 (data 0.064313, phys 0.066223) | Val 0.111396 (data 0.109325, phys 0.113467)\n",
      "Epoch 076 | Train 0.064230 (data 0.063130, phys 0.065330) | Val 0.111336 (data 0.109268, phys 0.113405)\n",
      "Epoch 077 | Train 0.065055 (data 0.063236, phys 0.066874) | Val 0.111473 (data 0.109398, phys 0.113549)\n",
      "Epoch 078 | Train 0.065029 (data 0.063154, phys 0.066904) | Val 0.111286 (data 0.109219, phys 0.113352)\n",
      "Epoch 079 | Train 0.063649 (data 0.062141, phys 0.065156) | Val 0.111453 (data 0.109380, phys 0.113526)\n",
      "Epoch 080 | Train 0.064273 (data 0.062928, phys 0.065619) | Val 0.111407 (data 0.109336, phys 0.113479)\n",
      "Epoch 081 | Train 0.064517 (data 0.063548, phys 0.065486) | Val 0.111392 (data 0.109321, phys 0.113462)\n",
      "Epoch 082 | Train 0.064702 (data 0.063493, phys 0.065912) | Val 0.111398 (data 0.109326, phys 0.113470)\n",
      "Epoch 083 | Train 0.063717 (data 0.061812, phys 0.065623) | Val 0.111280 (data 0.109211, phys 0.113348)\n",
      "Epoch 084 | Train 0.064147 (data 0.062328, phys 0.065965) | Val 0.111341 (data 0.109271, phys 0.113410)\n",
      "Early stopping at epoch 84 (best val = 0.111274)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 30, λ_data = 0.5, λ_phys = 0.5\n",
      "MAE:  17.7970\n",
      "RMSE: 25.3737\n",
      "NMSE: 0.9872\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 30, lambda_data = 0.7, lambda_phys = 0.3\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149296 (data 0.149155, phys 0.149627) | Val 0.113970 (data 0.112735, phys 0.116850)\n",
      "Epoch 002 | Train 0.074469 (data 0.073590, phys 0.076520) | Val 0.113817 (data 0.112547, phys 0.116781)\n",
      "Epoch 003 | Train 0.073084 (data 0.072624, phys 0.074157) | Val 0.114731 (data 0.113439, phys 0.117746)\n",
      "Epoch 004 | Train 0.071767 (data 0.070415, phys 0.074919) | Val 0.114106 (data 0.112824, phys 0.117097)\n",
      "Epoch 005 | Train 0.071980 (data 0.071248, phys 0.073687) | Val 0.114236 (data 0.112950, phys 0.117237)\n",
      "Epoch 006 | Train 0.070824 (data 0.069283, phys 0.074420) | Val 0.114318 (data 0.113028, phys 0.117328)\n",
      "Epoch 007 | Train 0.071044 (data 0.070428, phys 0.072482) | Val 0.114032 (data 0.112744, phys 0.117038)\n",
      "Epoch 008 | Train 0.071567 (data 0.070798, phys 0.073362) | Val 0.113376 (data 0.112095, phys 0.116363)\n",
      "Epoch 009 | Train 0.069964 (data 0.068857, phys 0.072548) | Val 0.112884 (data 0.111607, phys 0.115864)\n",
      "Epoch 010 | Train 0.070844 (data 0.070368, phys 0.071953) | Val 0.112441 (data 0.111166, phys 0.115416)\n",
      "Epoch 011 | Train 0.068573 (data 0.067556, phys 0.070945) | Val 0.111852 (data 0.110586, phys 0.114807)\n",
      "Epoch 012 | Train 0.068370 (data 0.067306, phys 0.070854) | Val 0.111575 (data 0.110314, phys 0.114518)\n",
      "Epoch 013 | Train 0.066143 (data 0.065164, phys 0.068426) | Val 0.111565 (data 0.110305, phys 0.114505)\n",
      "Epoch 014 | Train 0.066270 (data 0.065854, phys 0.067240) | Val 0.111275 (data 0.110026, phys 0.114190)\n",
      "Epoch 015 | Train 0.066472 (data 0.065404, phys 0.068965) | Val 0.111374 (data 0.110124, phys 0.114291)\n",
      "Epoch 016 | Train 0.066710 (data 0.065482, phys 0.069576) | Val 0.111290 (data 0.110044, phys 0.114196)\n",
      "Epoch 017 | Train 0.065803 (data 0.064944, phys 0.067805) | Val 0.111308 (data 0.110061, phys 0.114216)\n",
      "Epoch 018 | Train 0.067036 (data 0.066036, phys 0.069369) | Val 0.111174 (data 0.109932, phys 0.114071)\n",
      "Epoch 019 | Train 0.066821 (data 0.066266, phys 0.068115) | Val 0.111342 (data 0.110095, phys 0.114250)\n",
      "Epoch 020 | Train 0.067644 (data 0.067366, phys 0.068293) | Val 0.111063 (data 0.109827, phys 0.113947)\n",
      "Epoch 021 | Train 0.065704 (data 0.065104, phys 0.067105) | Val 0.111240 (data 0.109993, phys 0.114149)\n",
      "Epoch 022 | Train 0.065797 (data 0.064767, phys 0.068202) | Val 0.111015 (data 0.109776, phys 0.113907)\n",
      "Epoch 023 | Train 0.065396 (data 0.064282, phys 0.067996) | Val 0.111029 (data 0.109789, phys 0.113923)\n",
      "Epoch 024 | Train 0.065974 (data 0.065211, phys 0.067755) | Val 0.111167 (data 0.109921, phys 0.114074)\n",
      "Epoch 025 | Train 0.065434 (data 0.065015, phys 0.066412) | Val 0.111061 (data 0.109819, phys 0.113958)\n",
      "Epoch 026 | Train 0.066093 (data 0.065185, phys 0.068210) | Val 0.111297 (data 0.110048, phys 0.114210)\n",
      "Epoch 027 | Train 0.065819 (data 0.065058, phys 0.067593) | Val 0.111008 (data 0.109768, phys 0.113902)\n",
      "Epoch 028 | Train 0.065940 (data 0.065219, phys 0.067622) | Val 0.111114 (data 0.109869, phys 0.114018)\n",
      "Epoch 029 | Train 0.066086 (data 0.065258, phys 0.068018) | Val 0.110859 (data 0.109623, phys 0.113744)\n",
      "Epoch 030 | Train 0.065787 (data 0.064807, phys 0.068072) | Val 0.110877 (data 0.109639, phys 0.113767)\n",
      "Epoch 031 | Train 0.065256 (data 0.064710, phys 0.066530) | Val 0.110881 (data 0.109641, phys 0.113775)\n",
      "Epoch 032 | Train 0.066177 (data 0.065760, phys 0.067152) | Val 0.110889 (data 0.109648, phys 0.113784)\n",
      "Epoch 033 | Train 0.065836 (data 0.065443, phys 0.066754) | Val 0.110928 (data 0.109686, phys 0.113827)\n",
      "Epoch 034 | Train 0.065146 (data 0.064530, phys 0.066586) | Val 0.110856 (data 0.109616, phys 0.113752)\n",
      "Epoch 035 | Train 0.064283 (data 0.063034, phys 0.067198) | Val 0.110958 (data 0.109713, phys 0.113861)\n",
      "Epoch 036 | Train 0.064601 (data 0.063026, phys 0.068275) | Val 0.110773 (data 0.109532, phys 0.113669)\n",
      "Epoch 037 | Train 0.064966 (data 0.064212, phys 0.066727) | Val 0.110884 (data 0.109639, phys 0.113788)\n",
      "Epoch 038 | Train 0.064814 (data 0.063420, phys 0.068069) | Val 0.110873 (data 0.109629, phys 0.113775)\n",
      "Epoch 039 | Train 0.064853 (data 0.063954, phys 0.066951) | Val 0.110834 (data 0.109590, phys 0.113735)\n",
      "Epoch 040 | Train 0.064959 (data 0.064469, phys 0.066101) | Val 0.110743 (data 0.109502, phys 0.113639)\n",
      "Epoch 041 | Train 0.065026 (data 0.064456, phys 0.066356) | Val 0.110713 (data 0.109473, phys 0.113609)\n",
      "Epoch 042 | Train 0.064787 (data 0.063969, phys 0.066696) | Val 0.110777 (data 0.109533, phys 0.113677)\n",
      "Epoch 043 | Train 0.064916 (data 0.063937, phys 0.067200) | Val 0.110619 (data 0.109381, phys 0.113507)\n",
      "Epoch 044 | Train 0.065223 (data 0.064452, phys 0.067023) | Val 0.110688 (data 0.109448, phys 0.113581)\n",
      "Epoch 045 | Train 0.065150 (data 0.064076, phys 0.067656) | Val 0.110786 (data 0.109543, phys 0.113688)\n",
      "Epoch 046 | Train 0.064539 (data 0.063391, phys 0.067219) | Val 0.110641 (data 0.109402, phys 0.113533)\n",
      "Epoch 047 | Train 0.065658 (data 0.065147, phys 0.066850) | Val 0.110703 (data 0.109462, phys 0.113599)\n",
      "Epoch 048 | Train 0.064742 (data 0.063708, phys 0.067155) | Val 0.110760 (data 0.109517, phys 0.113661)\n",
      "Epoch 049 | Train 0.065539 (data 0.064666, phys 0.067576) | Val 0.110624 (data 0.109384, phys 0.113518)\n",
      "Epoch 050 | Train 0.065290 (data 0.063559, phys 0.069329) | Val 0.110658 (data 0.109416, phys 0.113556)\n",
      "Epoch 051 | Train 0.064723 (data 0.063963, phys 0.066496) | Val 0.110659 (data 0.109418, phys 0.113555)\n",
      "Epoch 052 | Train 0.063969 (data 0.062774, phys 0.066755) | Val 0.110726 (data 0.109482, phys 0.113626)\n",
      "Epoch 053 | Train 0.065068 (data 0.064032, phys 0.067485) | Val 0.110606 (data 0.109365, phys 0.113501)\n",
      "Epoch 054 | Train 0.064509 (data 0.063814, phys 0.066130) | Val 0.110599 (data 0.109359, phys 0.113494)\n",
      "Epoch 055 | Train 0.064552 (data 0.063663, phys 0.066629) | Val 0.110559 (data 0.109319, phys 0.113451)\n",
      "Epoch 056 | Train 0.064401 (data 0.063525, phys 0.066445) | Val 0.110467 (data 0.109230, phys 0.113355)\n",
      "Epoch 057 | Train 0.064392 (data 0.063376, phys 0.066764) | Val 0.110618 (data 0.109377, phys 0.113515)\n",
      "Epoch 058 | Train 0.064469 (data 0.064045, phys 0.065459) | Val 0.110487 (data 0.109248, phys 0.113379)\n",
      "Epoch 059 | Train 0.063572 (data 0.062331, phys 0.066465) | Val 0.110579 (data 0.109338, phys 0.113475)\n",
      "Epoch 060 | Train 0.064430 (data 0.063717, phys 0.066093) | Val 0.110557 (data 0.109315, phys 0.113454)\n",
      "Epoch 061 | Train 0.064274 (data 0.063513, phys 0.066049) | Val 0.110589 (data 0.109346, phys 0.113490)\n",
      "Epoch 062 | Train 0.065313 (data 0.065317, phys 0.065304) | Val 0.110457 (data 0.109218, phys 0.113347)\n",
      "Epoch 063 | Train 0.064116 (data 0.062869, phys 0.067026) | Val 0.110579 (data 0.109337, phys 0.113476)\n",
      "Epoch 064 | Train 0.064731 (data 0.063675, phys 0.067194) | Val 0.110402 (data 0.109165, phys 0.113289)\n",
      "Epoch 065 | Train 0.064031 (data 0.063392, phys 0.065525) | Val 0.110481 (data 0.109241, phys 0.113373)\n",
      "Epoch 066 | Train 0.063859 (data 0.063214, phys 0.065365) | Val 0.110669 (data 0.109425, phys 0.113570)\n",
      "Epoch 067 | Train 0.064723 (data 0.064006, phys 0.066397) | Val 0.110464 (data 0.109226, phys 0.113354)\n",
      "Epoch 068 | Train 0.064788 (data 0.063912, phys 0.066832) | Val 0.110483 (data 0.109244, phys 0.113373)\n",
      "Epoch 069 | Train 0.064493 (data 0.064067, phys 0.065489) | Val 0.110616 (data 0.109374, phys 0.113515)\n",
      "Epoch 070 | Train 0.064704 (data 0.064110, phys 0.066090) | Val 0.110438 (data 0.109201, phys 0.113326)\n",
      "Epoch 071 | Train 0.064406 (data 0.063455, phys 0.066627) | Val 0.110566 (data 0.109324, phys 0.113463)\n",
      "Epoch 072 | Train 0.063754 (data 0.063306, phys 0.064800) | Val 0.110636 (data 0.109392, phys 0.113539)\n",
      "Epoch 073 | Train 0.063420 (data 0.062652, phys 0.065213) | Val 0.110476 (data 0.109236, phys 0.113370)\n",
      "Epoch 074 | Train 0.063875 (data 0.062748, phys 0.066506) | Val 0.110542 (data 0.109300, phys 0.113439)\n",
      "Epoch 075 | Train 0.064953 (data 0.064413, phys 0.066215) | Val 0.110543 (data 0.109302, phys 0.113438)\n",
      "Epoch 076 | Train 0.063736 (data 0.063075, phys 0.065281) | Val 0.110492 (data 0.109253, phys 0.113385)\n",
      "Epoch 077 | Train 0.064261 (data 0.063194, phys 0.066749) | Val 0.110677 (data 0.109432, phys 0.113581)\n",
      "Epoch 078 | Train 0.064219 (data 0.063083, phys 0.066870) | Val 0.110459 (data 0.109220, phys 0.113350)\n",
      "Epoch 079 | Train 0.062981 (data 0.062066, phys 0.065117) | Val 0.110630 (data 0.109387, phys 0.113532)\n",
      "Epoch 080 | Train 0.063659 (data 0.062856, phys 0.065534) | Val 0.110515 (data 0.109273, phys 0.113411)\n",
      "Epoch 081 | Train 0.064107 (data 0.063520, phys 0.065475) | Val 0.110472 (data 0.109231, phys 0.113367)\n",
      "Epoch 082 | Train 0.064226 (data 0.063508, phys 0.065900) | Val 0.110514 (data 0.109273, phys 0.113412)\n",
      "Epoch 083 | Train 0.063002 (data 0.061870, phys 0.065643) | Val 0.110499 (data 0.109257, phys 0.113395)\n",
      "Epoch 084 | Train 0.063391 (data 0.062261, phys 0.066028) | Val 0.110457 (data 0.109217, phys 0.113351)\n",
      "Early stopping at epoch 84 (best val = 0.110402)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 30, λ_data = 0.7, λ_phys = 0.3\n",
      "MAE:  17.7830\n",
      "RMSE: 25.3708\n",
      "NMSE: 0.9870\n",
      "\n",
      "------------------------------------------------------------\n",
      "Training LSTM+Physics | LAG = 30, lambda_data = 1.0, lambda_phys = 0.0\n",
      "------------------------------------------------------------\n",
      "Epoch 001 | Train 0.149916 (data 0.149916, phys 0.150466) | Val 0.113143 (data 0.113143, phys 0.117225)\n",
      "Epoch 002 | Train 0.073954 (data 0.073954, phys 0.076725) | Val 0.112649 (data 0.112649, phys 0.116896)\n",
      "Epoch 003 | Train 0.072633 (data 0.072633, phys 0.074046) | Val 0.113396 (data 0.113396, phys 0.117701)\n",
      "Epoch 004 | Train 0.070446 (data 0.070446, phys 0.074953) | Val 0.112859 (data 0.112859, phys 0.117135)\n",
      "Epoch 005 | Train 0.071316 (data 0.071316, phys 0.073803) | Val 0.112827 (data 0.112827, phys 0.117107)\n",
      "Epoch 006 | Train 0.069299 (data 0.069299, phys 0.074501) | Val 0.113236 (data 0.113236, phys 0.117548)\n",
      "Epoch 007 | Train 0.070388 (data 0.070388, phys 0.072400) | Val 0.112691 (data 0.112691, phys 0.116983)\n",
      "Epoch 008 | Train 0.070842 (data 0.070842, phys 0.073232) | Val 0.112028 (data 0.112028, phys 0.116292)\n",
      "Epoch 009 | Train 0.068823 (data 0.068823, phys 0.072601) | Val 0.111650 (data 0.111650, phys 0.115911)\n",
      "Epoch 010 | Train 0.070407 (data 0.070407, phys 0.071969) | Val 0.111153 (data 0.111153, phys 0.115402)\n",
      "Epoch 011 | Train 0.067502 (data 0.067502, phys 0.070962) | Val 0.110635 (data 0.110635, phys 0.114861)\n",
      "Epoch 012 | Train 0.067248 (data 0.067248, phys 0.070780) | Val 0.110444 (data 0.110444, phys 0.114661)\n",
      "Epoch 013 | Train 0.065106 (data 0.065106, phys 0.068361) | Val 0.110324 (data 0.110324, phys 0.114528)\n",
      "Epoch 014 | Train 0.065917 (data 0.065917, phys 0.067395) | Val 0.110006 (data 0.110006, phys 0.114171)\n",
      "Epoch 015 | Train 0.065392 (data 0.065392, phys 0.068988) | Val 0.110092 (data 0.110092, phys 0.114260)\n",
      "Epoch 016 | Train 0.065592 (data 0.065592, phys 0.069679) | Val 0.110029 (data 0.110029, phys 0.114185)\n",
      "Epoch 017 | Train 0.064984 (data 0.064984, phys 0.067849) | Val 0.110041 (data 0.110041, phys 0.114199)\n",
      "Epoch 018 | Train 0.066034 (data 0.066034, phys 0.069339) | Val 0.109932 (data 0.109932, phys 0.114073)\n",
      "Epoch 019 | Train 0.066299 (data 0.066299, phys 0.068145) | Val 0.110059 (data 0.110059, phys 0.114215)\n",
      "Epoch 020 | Train 0.067397 (data 0.067397, phys 0.068429) | Val 0.109758 (data 0.109758, phys 0.113869)\n",
      "Epoch 021 | Train 0.064988 (data 0.064988, phys 0.066955) | Val 0.109899 (data 0.109899, phys 0.114040)\n",
      "Epoch 022 | Train 0.064612 (data 0.064612, phys 0.067981) | Val 0.109773 (data 0.109773, phys 0.113903)\n",
      "Epoch 023 | Train 0.064270 (data 0.064270, phys 0.067999) | Val 0.109744 (data 0.109744, phys 0.113873)\n",
      "Epoch 024 | Train 0.065124 (data 0.065124, phys 0.067669) | Val 0.109961 (data 0.109961, phys 0.114118)\n",
      "Epoch 025 | Train 0.065056 (data 0.065056, phys 0.066350) | Val 0.109792 (data 0.109792, phys 0.113927)\n",
      "Epoch 026 | Train 0.065203 (data 0.065203, phys 0.068199) | Val 0.110081 (data 0.110081, phys 0.114246)\n",
      "Epoch 027 | Train 0.064996 (data 0.064996, phys 0.067596) | Val 0.109734 (data 0.109734, phys 0.113865)\n",
      "Epoch 028 | Train 0.065269 (data 0.065269, phys 0.067617) | Val 0.109883 (data 0.109883, phys 0.114038)\n",
      "Epoch 029 | Train 0.065345 (data 0.065345, phys 0.068094) | Val 0.109564 (data 0.109564, phys 0.113680)\n",
      "Epoch 030 | Train 0.064738 (data 0.064738, phys 0.068120) | Val 0.109630 (data 0.109630, phys 0.113758)\n",
      "Epoch 031 | Train 0.064754 (data 0.064754, phys 0.066503) | Val 0.109578 (data 0.109578, phys 0.113703)\n",
      "Epoch 032 | Train 0.065744 (data 0.065744, phys 0.067046) | Val 0.109678 (data 0.109678, phys 0.113817)\n",
      "Epoch 033 | Train 0.065512 (data 0.065512, phys 0.066779) | Val 0.109666 (data 0.109666, phys 0.113805)\n",
      "Epoch 034 | Train 0.064576 (data 0.064576, phys 0.066658) | Val 0.109613 (data 0.109613, phys 0.113745)\n",
      "Epoch 035 | Train 0.063127 (data 0.063127, phys 0.067239) | Val 0.109771 (data 0.109771, phys 0.113923)\n",
      "Epoch 036 | Train 0.063052 (data 0.063052, phys 0.068225) | Val 0.109551 (data 0.109551, phys 0.113685)\n",
      "Epoch 037 | Train 0.064272 (data 0.064272, phys 0.066788) | Val 0.109664 (data 0.109664, phys 0.113810)\n",
      "Epoch 038 | Train 0.063391 (data 0.063391, phys 0.068116) | Val 0.109740 (data 0.109740, phys 0.113895)\n",
      "Epoch 039 | Train 0.064018 (data 0.064018, phys 0.066928) | Val 0.109537 (data 0.109537, phys 0.113678)\n",
      "Epoch 040 | Train 0.064454 (data 0.064454, phys 0.066095) | Val 0.109513 (data 0.109513, phys 0.113649)\n",
      "Epoch 041 | Train 0.064489 (data 0.064489, phys 0.066298) | Val 0.109454 (data 0.109454, phys 0.113591)\n",
      "Epoch 042 | Train 0.063974 (data 0.063974, phys 0.066564) | Val 0.109447 (data 0.109447, phys 0.113585)\n",
      "Epoch 043 | Train 0.064116 (data 0.064116, phys 0.067168) | Val 0.109361 (data 0.109361, phys 0.113482)\n",
      "Epoch 044 | Train 0.064436 (data 0.064436, phys 0.067009) | Val 0.109461 (data 0.109461, phys 0.113597)\n",
      "Epoch 045 | Train 0.064081 (data 0.064081, phys 0.067619) | Val 0.109548 (data 0.109548, phys 0.113697)\n",
      "Epoch 046 | Train 0.063377 (data 0.063377, phys 0.067195) | Val 0.109392 (data 0.109392, phys 0.113523)\n",
      "Epoch 047 | Train 0.065228 (data 0.065228, phys 0.067042) | Val 0.109453 (data 0.109453, phys 0.113587)\n",
      "Epoch 048 | Train 0.063768 (data 0.063768, phys 0.067197) | Val 0.109542 (data 0.109542, phys 0.113691)\n",
      "Epoch 049 | Train 0.064837 (data 0.064837, phys 0.067586) | Val 0.109362 (data 0.109362, phys 0.113495)\n",
      "Epoch 050 | Train 0.063638 (data 0.063638, phys 0.069339) | Val 0.109490 (data 0.109490, phys 0.113638)\n",
      "Epoch 051 | Train 0.063965 (data 0.063965, phys 0.066651) | Val 0.109338 (data 0.109338, phys 0.113471)\n",
      "Epoch 052 | Train 0.062894 (data 0.062894, phys 0.066856) | Val 0.109478 (data 0.109478, phys 0.113629)\n",
      "Epoch 053 | Train 0.064215 (data 0.064215, phys 0.067667) | Val 0.109367 (data 0.109367, phys 0.113504)\n",
      "Epoch 054 | Train 0.063887 (data 0.063887, phys 0.066232) | Val 0.109354 (data 0.109354, phys 0.113487)\n",
      "Epoch 055 | Train 0.063561 (data 0.063561, phys 0.066497) | Val 0.109319 (data 0.109319, phys 0.113452)\n",
      "Epoch 056 | Train 0.063573 (data 0.063573, phys 0.066464) | Val 0.109164 (data 0.109164, phys 0.113289)\n",
      "Epoch 057 | Train 0.063301 (data 0.063301, phys 0.066783) | Val 0.109271 (data 0.109271, phys 0.113411)\n",
      "Epoch 058 | Train 0.064081 (data 0.064081, phys 0.065611) | Val 0.109175 (data 0.109175, phys 0.113304)\n",
      "Epoch 059 | Train 0.062437 (data 0.062437, phys 0.066316) | Val 0.109272 (data 0.109272, phys 0.113411)\n",
      "Epoch 060 | Train 0.063820 (data 0.063820, phys 0.065977) | Val 0.109216 (data 0.109216, phys 0.113352)\n",
      "Epoch 061 | Train 0.063712 (data 0.063712, phys 0.066173) | Val 0.109351 (data 0.109351, phys 0.113496)\n",
      "Epoch 062 | Train 0.065479 (data 0.065479, phys 0.065392) | Val 0.109241 (data 0.109241, phys 0.113375)\n",
      "Epoch 063 | Train 0.062938 (data 0.062938, phys 0.067085) | Val 0.109311 (data 0.109311, phys 0.113449)\n",
      "Epoch 064 | Train 0.063643 (data 0.063643, phys 0.067289) | Val 0.109142 (data 0.109142, phys 0.113268)\n",
      "Epoch 065 | Train 0.063314 (data 0.063314, phys 0.065514) | Val 0.109195 (data 0.109195, phys 0.113323)\n",
      "Epoch 066 | Train 0.063519 (data 0.063519, phys 0.065838) | Val 0.109487 (data 0.109487, phys 0.113637)\n",
      "Epoch 067 | Train 0.063877 (data 0.063877, phys 0.066372) | Val 0.109239 (data 0.109239, phys 0.113368)\n",
      "Epoch 068 | Train 0.063934 (data 0.063934, phys 0.066943) | Val 0.109171 (data 0.109171, phys 0.113297)\n",
      "Epoch 069 | Train 0.064218 (data 0.064218, phys 0.065685) | Val 0.109238 (data 0.109238, phys 0.113377)\n",
      "Epoch 070 | Train 0.064137 (data 0.064137, phys 0.066149) | Val 0.109084 (data 0.109084, phys 0.113211)\n",
      "Epoch 071 | Train 0.063621 (data 0.063621, phys 0.066648) | Val 0.109172 (data 0.109172, phys 0.113304)\n",
      "Epoch 072 | Train 0.063340 (data 0.063340, phys 0.064885) | Val 0.109384 (data 0.109384, phys 0.113535)\n",
      "Epoch 073 | Train 0.062503 (data 0.062503, phys 0.065264) | Val 0.109141 (data 0.109141, phys 0.113273)\n",
      "Epoch 074 | Train 0.062938 (data 0.062938, phys 0.066451) | Val 0.109223 (data 0.109223, phys 0.113362)\n",
      "Epoch 075 | Train 0.064412 (data 0.064412, phys 0.066205) | Val 0.109259 (data 0.109259, phys 0.113397)\n",
      "Epoch 076 | Train 0.063071 (data 0.063071, phys 0.065340) | Val 0.109176 (data 0.109176, phys 0.113309)\n",
      "Epoch 077 | Train 0.063257 (data 0.063257, phys 0.066863) | Val 0.109393 (data 0.109393, phys 0.113546)\n",
      "Epoch 078 | Train 0.063146 (data 0.063146, phys 0.066920) | Val 0.109209 (data 0.109209, phys 0.113343)\n",
      "Epoch 079 | Train 0.062087 (data 0.062087, phys 0.065127) | Val 0.109403 (data 0.109403, phys 0.113552)\n",
      "Epoch 080 | Train 0.062925 (data 0.062925, phys 0.065647) | Val 0.109248 (data 0.109248, phys 0.113386)\n",
      "Epoch 081 | Train 0.063573 (data 0.063573, phys 0.065412) | Val 0.109197 (data 0.109197, phys 0.113334)\n",
      "Epoch 082 | Train 0.063458 (data 0.063458, phys 0.065825) | Val 0.109269 (data 0.109269, phys 0.113412)\n",
      "Epoch 083 | Train 0.061988 (data 0.061988, phys 0.065664) | Val 0.109282 (data 0.109282, phys 0.113427)\n",
      "Epoch 084 | Train 0.062226 (data 0.062226, phys 0.065938) | Val 0.109223 (data 0.109223, phys 0.113362)\n",
      "Epoch 085 | Train 0.062076 (data 0.062076, phys 0.065818) | Val 0.109269 (data 0.109269, phys 0.113411)\n",
      "Epoch 086 | Train 0.063587 (data 0.063587, phys 0.064626) | Val 0.109117 (data 0.109117, phys 0.113249)\n",
      "Epoch 087 | Train 0.061602 (data 0.061602, phys 0.066080) | Val 0.109413 (data 0.109413, phys 0.113569)\n",
      "Epoch 088 | Train 0.063222 (data 0.063222, phys 0.066271) | Val 0.109262 (data 0.109262, phys 0.113406)\n",
      "Epoch 089 | Train 0.062420 (data 0.062420, phys 0.064512) | Val 0.109430 (data 0.109430, phys 0.113586)\n",
      "Epoch 090 | Train 0.063209 (data 0.063209, phys 0.064630) | Val 0.109228 (data 0.109228, phys 0.113369)\n",
      "Early stopping at epoch 90 (best val = 0.109084)\n",
      "\n",
      "--- Test Evaluation (Real AQI Units) ---\n",
      "LAG = 30, λ_data = 1.0, λ_phys = 0.0\n",
      "MAE:  17.7549\n",
      "RMSE: 25.3641\n",
      "NMSE: 0.9865\n",
      "\n",
      "===== Final OZONE LSTM+Physics Lambda Sweep Results =====\n",
      "    LAG         Model  lambda_data  lambda_phys        MAE       RMSE  \\\n",
      "0     1  LSTM+Physics          0.0          1.0  12.798557  19.489491   \n",
      "1     1  LSTM+Physics          0.3          0.7  12.785561  19.514766   \n",
      "2     1  LSTM+Physics          0.5          0.5  12.855002  19.464567   \n",
      "3     1  LSTM+Physics          0.7          0.3  12.860205  19.492156   \n",
      "4     1  LSTM+Physics          1.0          0.0  12.764156  19.497447   \n",
      "5     7  LSTM+Physics          0.0          1.0  16.696962  25.237966   \n",
      "6     7  LSTM+Physics          0.3          0.7  16.665496  25.285140   \n",
      "7     7  LSTM+Physics          0.5          0.5  16.661577  25.285822   \n",
      "8     7  LSTM+Physics          0.7          0.3  16.641044  25.305559   \n",
      "9     7  LSTM+Physics          1.0          0.0  16.757017  25.209859   \n",
      "10   14  LSTM+Physics          0.0          1.0  16.436043  23.973287   \n",
      "11   14  LSTM+Physics          0.3          0.7  16.499107  23.988601   \n",
      "12   14  LSTM+Physics          0.5          0.5  16.420643  23.985873   \n",
      "13   14  LSTM+Physics          0.7          0.3  16.437565  23.972766   \n",
      "14   14  LSTM+Physics          1.0          0.0  16.361313  23.969056   \n",
      "15   30  LSTM+Physics          0.0          1.0  17.725621  25.353120   \n",
      "16   30  LSTM+Physics          0.3          0.7  17.804205  25.375545   \n",
      "17   30  LSTM+Physics          0.5          0.5  17.796990  25.373659   \n",
      "18   30  LSTM+Physics          0.7          0.3  17.783010  25.370795   \n",
      "19   30  LSTM+Physics          1.0          0.0  17.754933  25.364064   \n",
      "\n",
      "        NMSE  \n",
      "0   0.595433  \n",
      "1   0.596978  \n",
      "2   0.593911  \n",
      "3   0.595596  \n",
      "4   0.595919  \n",
      "5   0.993905  \n",
      "6   0.997624  \n",
      "7   0.997678  \n",
      "8   0.999236  \n",
      "9   0.991692  \n",
      "10  0.892671  \n",
      "11  0.893812  \n",
      "12  0.893609  \n",
      "13  0.892632  \n",
      "14  0.892356  \n",
      "15  0.985631  \n",
      "16  0.987376  \n",
      "17  0.987229  \n",
      "18  0.987006  \n",
      "19  0.986482  \n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
